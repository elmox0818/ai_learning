{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-END.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXneHWi/IfHUN1iLup/W7a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elmox0818/ai_learning/blob/master/RNN_END.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ-U1i-8NRzb",
        "colab_type": "text"
      },
      "source": [
        "# RNN(リカレントニューラルネットワーク)\n",
        "\n",
        "- 中間層が時系列で繋がっていて、重みやバイアスが持ち越されるため過去の情報を使える\n",
        "- 勾配爆発\n",
        "  - 学習時に層をさかのぼるにつれて勾配が大きくなりすぎる問題。勾配クリッピングなどで対処する。\n",
        "- 勾配消失\n",
        "  - 勾配が小さくなりすぎる問題。LSTMなどが有効。\n",
        "\n",
        "## 勾配クリッピング\n",
        "\n",
        "勾配の大きさに制限をかける。\n",
        "L2ノルムが閾値より高い場合、以下の式で調整する。\n",
        "> L2ノルム = 二乗の総和の平方根\n",
        "\n",
        "$$\n",
        "  勾配 → \\frac{閾値}{L2ノルム}\\times勾配\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FJ0MtP6dLUz",
        "colab_type": "text"
      },
      "source": [
        "## Kerasの基礎\n",
        "\n",
        "### 学習用データの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i75fX_AkNZ3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "aaab650d-2a13-4145-8189-6c3f44b10e4b"
      },
      "source": [
        "%matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace(-np.pi, np.pi).reshape(-1, 1)\n",
        "t = np.sin(x)\n",
        "\n",
        "plt.plot(x, t)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using matplotlib backend: agg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9EwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxdozoqBfiVM",
        "colab_type": "text"
      },
      "source": [
        "## ニューラルネットワークの構築\n",
        "\n",
        "Sequential()によりモデルを作成、addメソッドにより層を追加。\n",
        "Dense()により通常の層を作ることができる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clKhcjaXdcLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "83dfddc6-c6bf-43c8-9eb6-653eb394dc30"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "batch_size = 8  # バッチサイズ\n",
        "n_in = 1  # 入力層のニューロン数\n",
        "n_mid = 20  # 中間層のニューロン数\n",
        "n_out = 1  # 出力層のニューロン数\n",
        "\n",
        "# 入力層、中間層、出力層の３層のニューラルネットワークを構築\n",
        "model = Sequential()\n",
        "model.add(Dense(n_mid, input_shape=(n_in,), activation=\"sigmoid\"))  # 活性化関数にシグモイド関数\n",
        "model.add(Dense(n_out, activation=\"linear\"))  # 活性化関数に恒等関数\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")  # 損失関数に二乗誤差、最適化アルゴリズムにSGDを使用してコンパイル\n",
        "print(model.summary())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 20)                40        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 61\n",
            "Trainable params: 61\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSJ5Oxc0hmH-",
        "colab_type": "text"
      },
      "source": [
        "## 学習\n",
        "\n",
        "fit()メソッドを使う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imo9YEXZg9iG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46c2a532-964f-43ec-a1dc-43d0b154b911"
      },
      "source": [
        "history = model.fit(x, t, batch_size=batch_size, epochs=2000, validation_split=0.1) # 10%のデータを検証用に使う"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 45 samples, validate on 5 samples\n",
            "Epoch 1/2000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.5165 - val_loss: 0.0559\n",
            "Epoch 2/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.4132 - val_loss: 0.0431\n",
            "Epoch 3/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.3718 - val_loss: 0.0574\n",
            "Epoch 4/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.3395 - val_loss: 0.0529\n",
            "Epoch 5/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.3140 - val_loss: 0.0674\n",
            "Epoch 6/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.3021 - val_loss: 0.0720\n",
            "Epoch 7/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.2838 - val_loss: 0.1067\n",
            "Epoch 8/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.2605 - val_loss: 0.1259\n",
            "Epoch 9/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.2499 - val_loss: 0.1665\n",
            "Epoch 10/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.2369 - val_loss: 0.2047\n",
            "Epoch 11/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.2260 - val_loss: 0.2186\n",
            "Epoch 12/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.2156 - val_loss: 0.2282\n",
            "Epoch 13/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.2079 - val_loss: 0.2409\n",
            "Epoch 14/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.1998 - val_loss: 0.2682\n",
            "Epoch 15/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.1930 - val_loss: 0.3050\n",
            "Epoch 16/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1869 - val_loss: 0.3334\n",
            "Epoch 17/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.1834 - val_loss: 0.3558\n",
            "Epoch 18/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.1800 - val_loss: 0.3819\n",
            "Epoch 19/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.1771 - val_loss: 0.4080\n",
            "Epoch 20/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.1739 - val_loss: 0.4220\n",
            "Epoch 21/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1683 - val_loss: 0.4423\n",
            "Epoch 22/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.1662 - val_loss: 0.4690\n",
            "Epoch 23/2000\n",
            "45/45 [==============================] - 0s 186us/step - loss: 0.1659 - val_loss: 0.4829\n",
            "Epoch 24/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.1629 - val_loss: 0.5033\n",
            "Epoch 25/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.1631 - val_loss: 0.5249\n",
            "Epoch 26/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1611 - val_loss: 0.5650\n",
            "Epoch 27/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.1591 - val_loss: 0.5754\n",
            "Epoch 28/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.1578 - val_loss: 0.5795\n",
            "Epoch 29/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.1566 - val_loss: 0.5911\n",
            "Epoch 30/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.1547 - val_loss: 0.5913\n",
            "Epoch 31/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.1564 - val_loss: 0.5969\n",
            "Epoch 32/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.1547 - val_loss: 0.6283\n",
            "Epoch 33/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.1542 - val_loss: 0.6452\n",
            "Epoch 34/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.1541 - val_loss: 0.6157\n",
            "Epoch 35/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.1544 - val_loss: 0.6369\n",
            "Epoch 36/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.1529 - val_loss: 0.6655\n",
            "Epoch 37/2000\n",
            "45/45 [==============================] - 0s 314us/step - loss: 0.1524 - val_loss: 0.6508\n",
            "Epoch 38/2000\n",
            "45/45 [==============================] - 0s 297us/step - loss: 0.1521 - val_loss: 0.6774\n",
            "Epoch 39/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.1527 - val_loss: 0.6637\n",
            "Epoch 40/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.1499 - val_loss: 0.6806\n",
            "Epoch 41/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1513 - val_loss: 0.6965\n",
            "Epoch 42/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.1498 - val_loss: 0.7061\n",
            "Epoch 43/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.1507 - val_loss: 0.7131\n",
            "Epoch 44/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1503 - val_loss: 0.7020\n",
            "Epoch 45/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.1503 - val_loss: 0.7299\n",
            "Epoch 46/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1519 - val_loss: 0.7471\n",
            "Epoch 47/2000\n",
            "45/45 [==============================] - 0s 287us/step - loss: 0.1493 - val_loss: 0.7326\n",
            "Epoch 48/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.1516 - val_loss: 0.7416\n",
            "Epoch 49/2000\n",
            "45/45 [==============================] - 0s 331us/step - loss: 0.1514 - val_loss: 0.7564\n",
            "Epoch 50/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1508 - val_loss: 0.7217\n",
            "Epoch 51/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.1485 - val_loss: 0.7371\n",
            "Epoch 52/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.1478 - val_loss: 0.7465\n",
            "Epoch 53/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.1501 - val_loss: 0.7672\n",
            "Epoch 54/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.1490 - val_loss: 0.7959\n",
            "Epoch 55/2000\n",
            "45/45 [==============================] - 0s 278us/step - loss: 0.1487 - val_loss: 0.7641\n",
            "Epoch 56/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.1488 - val_loss: 0.7424\n",
            "Epoch 57/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.1485 - val_loss: 0.7512\n",
            "Epoch 58/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.1477 - val_loss: 0.7423\n",
            "Epoch 59/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.1499 - val_loss: 0.7341\n",
            "Epoch 60/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.1470 - val_loss: 0.7735\n",
            "Epoch 61/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.1507 - val_loss: 0.7568\n",
            "Epoch 62/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.1473 - val_loss: 0.7426\n",
            "Epoch 63/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1475 - val_loss: 0.7478\n",
            "Epoch 64/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1481 - val_loss: 0.7690\n",
            "Epoch 65/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.1481 - val_loss: 0.7749\n",
            "Epoch 66/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1487 - val_loss: 0.8084\n",
            "Epoch 67/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.1480 - val_loss: 0.7778\n",
            "Epoch 68/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1474 - val_loss: 0.7755\n",
            "Epoch 69/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.1487 - val_loss: 0.7766\n",
            "Epoch 70/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.1472 - val_loss: 0.7603\n",
            "Epoch 71/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.1473 - val_loss: 0.7781\n",
            "Epoch 72/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.1469 - val_loss: 0.7771\n",
            "Epoch 73/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1465 - val_loss: 0.7929\n",
            "Epoch 74/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.1503 - val_loss: 0.7907\n",
            "Epoch 75/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.1485 - val_loss: 0.8352\n",
            "Epoch 76/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.1460 - val_loss: 0.8077\n",
            "Epoch 77/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.1505 - val_loss: 0.7964\n",
            "Epoch 78/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.1489 - val_loss: 0.7453\n",
            "Epoch 79/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.1471 - val_loss: 0.7537\n",
            "Epoch 80/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.1473 - val_loss: 0.7877\n",
            "Epoch 81/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.1473 - val_loss: 0.8020\n",
            "Epoch 82/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.1477 - val_loss: 0.8049\n",
            "Epoch 83/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.1467 - val_loss: 0.7966\n",
            "Epoch 84/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.1448 - val_loss: 0.7894\n",
            "Epoch 85/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.1468 - val_loss: 0.7533\n",
            "Epoch 86/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1459 - val_loss: 0.7691\n",
            "Epoch 87/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1478 - val_loss: 0.8220\n",
            "Epoch 88/2000\n",
            "45/45 [==============================] - 0s 188us/step - loss: 0.1457 - val_loss: 0.7957\n",
            "Epoch 89/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.1475 - val_loss: 0.7915\n",
            "Epoch 90/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.1453 - val_loss: 0.7539\n",
            "Epoch 91/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.1451 - val_loss: 0.7883\n",
            "Epoch 92/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.1468 - val_loss: 0.8079\n",
            "Epoch 93/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.1480 - val_loss: 0.7749\n",
            "Epoch 94/2000\n",
            "45/45 [==============================] - 0s 340us/step - loss: 0.1450 - val_loss: 0.7891\n",
            "Epoch 95/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.1463 - val_loss: 0.7677\n",
            "Epoch 96/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.1462 - val_loss: 0.7700\n",
            "Epoch 97/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.1455 - val_loss: 0.8061\n",
            "Epoch 98/2000\n",
            "45/45 [==============================] - 0s 297us/step - loss: 0.1445 - val_loss: 0.7879\n",
            "Epoch 99/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.1434 - val_loss: 0.8099\n",
            "Epoch 100/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1438 - val_loss: 0.8117\n",
            "Epoch 101/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.1436 - val_loss: 0.7903\n",
            "Epoch 102/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.1441 - val_loss: 0.8027\n",
            "Epoch 103/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.1438 - val_loss: 0.7822\n",
            "Epoch 104/2000\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.1445 - val_loss: 0.7650\n",
            "Epoch 105/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.1437 - val_loss: 0.7368\n",
            "Epoch 106/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.1447 - val_loss: 0.7451\n",
            "Epoch 107/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.1431 - val_loss: 0.7556\n",
            "Epoch 108/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.1440 - val_loss: 0.8094\n",
            "Epoch 109/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.1437 - val_loss: 0.7638\n",
            "Epoch 110/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.1420 - val_loss: 0.7524\n",
            "Epoch 111/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1424 - val_loss: 0.7569\n",
            "Epoch 112/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.1426 - val_loss: 0.7740\n",
            "Epoch 113/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.1418 - val_loss: 0.7843\n",
            "Epoch 114/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1440 - val_loss: 0.8204\n",
            "Epoch 115/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.1444 - val_loss: 0.7834\n",
            "Epoch 116/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.1424 - val_loss: 0.7490\n",
            "Epoch 117/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.1424 - val_loss: 0.7493\n",
            "Epoch 118/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.1430 - val_loss: 0.7169\n",
            "Epoch 119/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.1427 - val_loss: 0.7230\n",
            "Epoch 120/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.1422 - val_loss: 0.7655\n",
            "Epoch 121/2000\n",
            "45/45 [==============================] - 0s 291us/step - loss: 0.1411 - val_loss: 0.7798\n",
            "Epoch 122/2000\n",
            "45/45 [==============================] - 0s 304us/step - loss: 0.1420 - val_loss: 0.7935\n",
            "Epoch 123/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.1410 - val_loss: 0.7998\n",
            "Epoch 124/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.1422 - val_loss: 0.8023\n",
            "Epoch 125/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.1407 - val_loss: 0.7904\n",
            "Epoch 126/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.1402 - val_loss: 0.7806\n",
            "Epoch 127/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1404 - val_loss: 0.8219\n",
            "Epoch 128/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.1402 - val_loss: 0.8026\n",
            "Epoch 129/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.1415 - val_loss: 0.7917\n",
            "Epoch 130/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.1395 - val_loss: 0.7680\n",
            "Epoch 131/2000\n",
            "45/45 [==============================] - 0s 285us/step - loss: 0.1408 - val_loss: 0.7908\n",
            "Epoch 132/2000\n",
            "45/45 [==============================] - 0s 286us/step - loss: 0.1398 - val_loss: 0.7767\n",
            "Epoch 133/2000\n",
            "45/45 [==============================] - 0s 323us/step - loss: 0.1398 - val_loss: 0.7915\n",
            "Epoch 134/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.1401 - val_loss: 0.8099\n",
            "Epoch 135/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1395 - val_loss: 0.7823\n",
            "Epoch 136/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.1396 - val_loss: 0.7920\n",
            "Epoch 137/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.1412 - val_loss: 0.7705\n",
            "Epoch 138/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.1410 - val_loss: 0.7442\n",
            "Epoch 139/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.1406 - val_loss: 0.8120\n",
            "Epoch 140/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.1390 - val_loss: 0.8046\n",
            "Epoch 141/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1389 - val_loss: 0.7929\n",
            "Epoch 142/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.1401 - val_loss: 0.7484\n",
            "Epoch 143/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.1391 - val_loss: 0.7378\n",
            "Epoch 144/2000\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.1384 - val_loss: 0.7519\n",
            "Epoch 145/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.1416 - val_loss: 0.7680\n",
            "Epoch 146/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.1381 - val_loss: 0.7591\n",
            "Epoch 147/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1385 - val_loss: 0.7605\n",
            "Epoch 148/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.1379 - val_loss: 0.7729\n",
            "Epoch 149/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.1389 - val_loss: 0.8012\n",
            "Epoch 150/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.1374 - val_loss: 0.7707\n",
            "Epoch 151/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1371 - val_loss: 0.7314\n",
            "Epoch 152/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.1391 - val_loss: 0.7337\n",
            "Epoch 153/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.1380 - val_loss: 0.7318\n",
            "Epoch 154/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.1372 - val_loss: 0.7739\n",
            "Epoch 155/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1377 - val_loss: 0.7895\n",
            "Epoch 156/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.1375 - val_loss: 0.7558\n",
            "Epoch 157/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1397 - val_loss: 0.7396\n",
            "Epoch 158/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1371 - val_loss: 0.7338\n",
            "Epoch 159/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.1358 - val_loss: 0.7588\n",
            "Epoch 160/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.1368 - val_loss: 0.7632\n",
            "Epoch 161/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.1367 - val_loss: 0.7816\n",
            "Epoch 162/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1359 - val_loss: 0.7600\n",
            "Epoch 163/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.1356 - val_loss: 0.7786\n",
            "Epoch 164/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.1362 - val_loss: 0.7323\n",
            "Epoch 165/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.1360 - val_loss: 0.7631\n",
            "Epoch 166/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.1356 - val_loss: 0.7915\n",
            "Epoch 167/2000\n",
            "45/45 [==============================] - 0s 283us/step - loss: 0.1380 - val_loss: 0.7880\n",
            "Epoch 168/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.1348 - val_loss: 0.7774\n",
            "Epoch 169/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.1346 - val_loss: 0.7862\n",
            "Epoch 170/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.1347 - val_loss: 0.7673\n",
            "Epoch 171/2000\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.1356 - val_loss: 0.7620\n",
            "Epoch 172/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.1379 - val_loss: 0.7507\n",
            "Epoch 173/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.1341 - val_loss: 0.7774\n",
            "Epoch 174/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.1356 - val_loss: 0.8095\n",
            "Epoch 175/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.1364 - val_loss: 0.7697\n",
            "Epoch 176/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.1356 - val_loss: 0.7899\n",
            "Epoch 177/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.1333 - val_loss: 0.7732\n",
            "Epoch 178/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.1335 - val_loss: 0.7640\n",
            "Epoch 179/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.1344 - val_loss: 0.7963\n",
            "Epoch 180/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.1336 - val_loss: 0.7770\n",
            "Epoch 181/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.1336 - val_loss: 0.7806\n",
            "Epoch 182/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.1336 - val_loss: 0.8082\n",
            "Epoch 183/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.1327 - val_loss: 0.7773\n",
            "Epoch 184/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.1366 - val_loss: 0.7613\n",
            "Epoch 185/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.1344 - val_loss: 0.7443\n",
            "Epoch 186/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.1339 - val_loss: 0.7229\n",
            "Epoch 187/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.1329 - val_loss: 0.7186\n",
            "Epoch 188/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.1347 - val_loss: 0.7243\n",
            "Epoch 189/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1320 - val_loss: 0.7339\n",
            "Epoch 190/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.1332 - val_loss: 0.7830\n",
            "Epoch 191/2000\n",
            "45/45 [==============================] - 0s 492us/step - loss: 0.1342 - val_loss: 0.7387\n",
            "Epoch 192/2000\n",
            "45/45 [==============================] - 0s 281us/step - loss: 0.1334 - val_loss: 0.7496\n",
            "Epoch 193/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.1323 - val_loss: 0.7159\n",
            "Epoch 194/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.1317 - val_loss: 0.7207\n",
            "Epoch 195/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.1340 - val_loss: 0.7373\n",
            "Epoch 196/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.1325 - val_loss: 0.7589\n",
            "Epoch 197/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.1332 - val_loss: 0.7599\n",
            "Epoch 198/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.1305 - val_loss: 0.7870\n",
            "Epoch 199/2000\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.1307 - val_loss: 0.7832\n",
            "Epoch 200/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.1330 - val_loss: 0.7759\n",
            "Epoch 201/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1301 - val_loss: 0.7548\n",
            "Epoch 202/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.1297 - val_loss: 0.7447\n",
            "Epoch 203/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.1294 - val_loss: 0.7444\n",
            "Epoch 204/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.1303 - val_loss: 0.7315\n",
            "Epoch 205/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.1322 - val_loss: 0.7503\n",
            "Epoch 206/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.1306 - val_loss: 0.7655\n",
            "Epoch 207/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.1292 - val_loss: 0.7726\n",
            "Epoch 208/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.1300 - val_loss: 0.7531\n",
            "Epoch 209/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.1309 - val_loss: 0.7678\n",
            "Epoch 210/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.1293 - val_loss: 0.7946\n",
            "Epoch 211/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.1280 - val_loss: 0.7720\n",
            "Epoch 212/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.1285 - val_loss: 0.7582\n",
            "Epoch 213/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.1288 - val_loss: 0.7610\n",
            "Epoch 214/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.1276 - val_loss: 0.7441\n",
            "Epoch 215/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.1287 - val_loss: 0.7592\n",
            "Epoch 216/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.1291 - val_loss: 0.7477\n",
            "Epoch 217/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1274 - val_loss: 0.7476\n",
            "Epoch 218/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.1277 - val_loss: 0.7435\n",
            "Epoch 219/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1277 - val_loss: 0.7460\n",
            "Epoch 220/2000\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.1270 - val_loss: 0.7415\n",
            "Epoch 221/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.1283 - val_loss: 0.7494\n",
            "Epoch 222/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.1283 - val_loss: 0.7658\n",
            "Epoch 223/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.1274 - val_loss: 0.7794\n",
            "Epoch 224/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.1271 - val_loss: 0.7784\n",
            "Epoch 225/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.1265 - val_loss: 0.7531\n",
            "Epoch 226/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.1262 - val_loss: 0.7420\n",
            "Epoch 227/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.1277 - val_loss: 0.7406\n",
            "Epoch 228/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.1257 - val_loss: 0.7326\n",
            "Epoch 229/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.1260 - val_loss: 0.7573\n",
            "Epoch 230/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.1271 - val_loss: 0.7220\n",
            "Epoch 231/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.1250 - val_loss: 0.7540\n",
            "Epoch 232/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.1264 - val_loss: 0.7770\n",
            "Epoch 233/2000\n",
            "45/45 [==============================] - 0s 290us/step - loss: 0.1251 - val_loss: 0.7450\n",
            "Epoch 234/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.1273 - val_loss: 0.7658\n",
            "Epoch 235/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.1260 - val_loss: 0.7638\n",
            "Epoch 236/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.1246 - val_loss: 0.7715\n",
            "Epoch 237/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.1253 - val_loss: 0.7599\n",
            "Epoch 238/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.1240 - val_loss: 0.7479\n",
            "Epoch 239/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.1240 - val_loss: 0.7486\n",
            "Epoch 240/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.1243 - val_loss: 0.7698\n",
            "Epoch 241/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.1243 - val_loss: 0.7387\n",
            "Epoch 242/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.1238 - val_loss: 0.7699\n",
            "Epoch 243/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.1235 - val_loss: 0.7790\n",
            "Epoch 244/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.1236 - val_loss: 0.7463\n",
            "Epoch 245/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.1246 - val_loss: 0.7610\n",
            "Epoch 246/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.1254 - val_loss: 0.7300\n",
            "Epoch 247/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.1234 - val_loss: 0.7623\n",
            "Epoch 248/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.1220 - val_loss: 0.7642\n",
            "Epoch 249/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.1227 - val_loss: 0.7587\n",
            "Epoch 250/2000\n",
            "45/45 [==============================] - 0s 300us/step - loss: 0.1225 - val_loss: 0.7437\n",
            "Epoch 251/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.1225 - val_loss: 0.7364\n",
            "Epoch 252/2000\n",
            "45/45 [==============================] - 0s 278us/step - loss: 0.1218 - val_loss: 0.7618\n",
            "Epoch 253/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.1252 - val_loss: 0.7805\n",
            "Epoch 254/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.1222 - val_loss: 0.7731\n",
            "Epoch 255/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.1222 - val_loss: 0.7548\n",
            "Epoch 256/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.1222 - val_loss: 0.7459\n",
            "Epoch 257/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1218 - val_loss: 0.7115\n",
            "Epoch 258/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.1205 - val_loss: 0.7175\n",
            "Epoch 259/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.1211 - val_loss: 0.7306\n",
            "Epoch 260/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.1215 - val_loss: 0.7476\n",
            "Epoch 261/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.1201 - val_loss: 0.7506\n",
            "Epoch 262/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.1211 - val_loss: 0.7528\n",
            "Epoch 263/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.1198 - val_loss: 0.7591\n",
            "Epoch 264/2000\n",
            "45/45 [==============================] - 0s 364us/step - loss: 0.1202 - val_loss: 0.7711\n",
            "Epoch 265/2000\n",
            "45/45 [==============================] - 0s 333us/step - loss: 0.1197 - val_loss: 0.7495\n",
            "Epoch 266/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.1204 - val_loss: 0.7444\n",
            "Epoch 267/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.1202 - val_loss: 0.7598\n",
            "Epoch 268/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.1197 - val_loss: 0.7710\n",
            "Epoch 269/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.1215 - val_loss: 0.7559\n",
            "Epoch 270/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.1196 - val_loss: 0.7310\n",
            "Epoch 271/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.1181 - val_loss: 0.7292\n",
            "Epoch 272/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.1189 - val_loss: 0.7405\n",
            "Epoch 273/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1178 - val_loss: 0.7247\n",
            "Epoch 274/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.1177 - val_loss: 0.7284\n",
            "Epoch 275/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.1186 - val_loss: 0.7599\n",
            "Epoch 276/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.1193 - val_loss: 0.7322\n",
            "Epoch 277/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.1174 - val_loss: 0.7106\n",
            "Epoch 278/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.1178 - val_loss: 0.6983\n",
            "Epoch 279/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1187 - val_loss: 0.6963\n",
            "Epoch 280/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.1172 - val_loss: 0.6983\n",
            "Epoch 281/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1170 - val_loss: 0.7220\n",
            "Epoch 282/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.1178 - val_loss: 0.7174\n",
            "Epoch 283/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.1162 - val_loss: 0.7016\n",
            "Epoch 284/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.1159 - val_loss: 0.7016\n",
            "Epoch 285/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.1155 - val_loss: 0.7219\n",
            "Epoch 286/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.1167 - val_loss: 0.7020\n",
            "Epoch 287/2000\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.1154 - val_loss: 0.7159\n",
            "Epoch 288/2000\n",
            "45/45 [==============================] - 0s 293us/step - loss: 0.1154 - val_loss: 0.7245\n",
            "Epoch 289/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.1156 - val_loss: 0.7257\n",
            "Epoch 290/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.1154 - val_loss: 0.7278\n",
            "Epoch 291/2000\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.1150 - val_loss: 0.7008\n",
            "Epoch 292/2000\n",
            "45/45 [==============================] - 0s 322us/step - loss: 0.1140 - val_loss: 0.7170\n",
            "Epoch 293/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.1163 - val_loss: 0.7439\n",
            "Epoch 294/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.1147 - val_loss: 0.7373\n",
            "Epoch 295/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.1146 - val_loss: 0.7360\n",
            "Epoch 296/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.1169 - val_loss: 0.7480\n",
            "Epoch 297/2000\n",
            "45/45 [==============================] - 0s 300us/step - loss: 0.1139 - val_loss: 0.7238\n",
            "Epoch 298/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.1153 - val_loss: 0.7079\n",
            "Epoch 299/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.1129 - val_loss: 0.7200\n",
            "Epoch 300/2000\n",
            "45/45 [==============================] - 0s 289us/step - loss: 0.1132 - val_loss: 0.7532\n",
            "Epoch 301/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.1138 - val_loss: 0.7337\n",
            "Epoch 302/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.1123 - val_loss: 0.7206\n",
            "Epoch 303/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.1142 - val_loss: 0.7231\n",
            "Epoch 304/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.1126 - val_loss: 0.7382\n",
            "Epoch 305/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.1131 - val_loss: 0.7308\n",
            "Epoch 306/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.1137 - val_loss: 0.7275\n",
            "Epoch 307/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.1123 - val_loss: 0.7141\n",
            "Epoch 308/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.1118 - val_loss: 0.7157\n",
            "Epoch 309/2000\n",
            "45/45 [==============================] - 0s 282us/step - loss: 0.1130 - val_loss: 0.7302\n",
            "Epoch 310/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1118 - val_loss: 0.7313\n",
            "Epoch 311/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.1109 - val_loss: 0.7213\n",
            "Epoch 312/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.1114 - val_loss: 0.6941\n",
            "Epoch 313/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.1111 - val_loss: 0.7240\n",
            "Epoch 314/2000\n",
            "45/45 [==============================] - 0s 282us/step - loss: 0.1109 - val_loss: 0.6944\n",
            "Epoch 315/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.1117 - val_loss: 0.7168\n",
            "Epoch 316/2000\n",
            "45/45 [==============================] - 0s 280us/step - loss: 0.1110 - val_loss: 0.7103\n",
            "Epoch 317/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.1117 - val_loss: 0.7114\n",
            "Epoch 318/2000\n",
            "45/45 [==============================] - 0s 301us/step - loss: 0.1111 - val_loss: 0.7485\n",
            "Epoch 319/2000\n",
            "45/45 [==============================] - 0s 398us/step - loss: 0.1096 - val_loss: 0.7386\n",
            "Epoch 320/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.1091 - val_loss: 0.7206\n",
            "Epoch 321/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.1089 - val_loss: 0.7297\n",
            "Epoch 322/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.1106 - val_loss: 0.7185\n",
            "Epoch 323/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1092 - val_loss: 0.7073\n",
            "Epoch 324/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.1089 - val_loss: 0.6944\n",
            "Epoch 325/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.1109 - val_loss: 0.7344\n",
            "Epoch 326/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.1086 - val_loss: 0.7165\n",
            "Epoch 327/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.1084 - val_loss: 0.7105\n",
            "Epoch 328/2000\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.1077 - val_loss: 0.7079\n",
            "Epoch 329/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.1085 - val_loss: 0.7280\n",
            "Epoch 330/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.1079 - val_loss: 0.7347\n",
            "Epoch 331/2000\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.1118 - val_loss: 0.7042\n",
            "Epoch 332/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.1074 - val_loss: 0.7171\n",
            "Epoch 333/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1070 - val_loss: 0.7268\n",
            "Epoch 334/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.1072 - val_loss: 0.7224\n",
            "Epoch 335/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.1065 - val_loss: 0.7059\n",
            "Epoch 336/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.1062 - val_loss: 0.6882\n",
            "Epoch 337/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.1064 - val_loss: 0.6747\n",
            "Epoch 338/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1057 - val_loss: 0.6867\n",
            "Epoch 339/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1062 - val_loss: 0.7150\n",
            "Epoch 340/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.1057 - val_loss: 0.7226\n",
            "Epoch 341/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.1056 - val_loss: 0.7095\n",
            "Epoch 342/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.1062 - val_loss: 0.7259\n",
            "Epoch 343/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.1048 - val_loss: 0.7009\n",
            "Epoch 344/2000\n",
            "45/45 [==============================] - 0s 294us/step - loss: 0.1043 - val_loss: 0.6843\n",
            "Epoch 345/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.1047 - val_loss: 0.6835\n",
            "Epoch 346/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.1044 - val_loss: 0.6739\n",
            "Epoch 347/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.1043 - val_loss: 0.6703\n",
            "Epoch 348/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.1036 - val_loss: 0.6648\n",
            "Epoch 349/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.1047 - val_loss: 0.6760\n",
            "Epoch 350/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.1052 - val_loss: 0.6898\n",
            "Epoch 351/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.1047 - val_loss: 0.6910\n",
            "Epoch 352/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.1031 - val_loss: 0.6986\n",
            "Epoch 353/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.1027 - val_loss: 0.6918\n",
            "Epoch 354/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.1059 - val_loss: 0.6854\n",
            "Epoch 355/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.1028 - val_loss: 0.6991\n",
            "Epoch 356/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.1024 - val_loss: 0.6683\n",
            "Epoch 357/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.1038 - val_loss: 0.6341\n",
            "Epoch 358/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1045 - val_loss: 0.6485\n",
            "Epoch 359/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1021 - val_loss: 0.6897\n",
            "Epoch 360/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1035 - val_loss: 0.7053\n",
            "Epoch 361/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.1035 - val_loss: 0.6981\n",
            "Epoch 362/2000\n",
            "45/45 [==============================] - 0s 331us/step - loss: 0.1009 - val_loss: 0.6905\n",
            "Epoch 363/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.1007 - val_loss: 0.6984\n",
            "Epoch 364/2000\n",
            "45/45 [==============================] - 0s 309us/step - loss: 0.1026 - val_loss: 0.6989\n",
            "Epoch 365/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.1003 - val_loss: 0.6761\n",
            "Epoch 366/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.1005 - val_loss: 0.6682\n",
            "Epoch 367/2000\n",
            "45/45 [==============================] - 0s 283us/step - loss: 0.1010 - val_loss: 0.6957\n",
            "Epoch 368/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0999 - val_loss: 0.6776\n",
            "Epoch 369/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.1001 - val_loss: 0.6629\n",
            "Epoch 370/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0991 - val_loss: 0.6900\n",
            "Epoch 371/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0993 - val_loss: 0.6901\n",
            "Epoch 372/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0984 - val_loss: 0.6780\n",
            "Epoch 373/2000\n",
            "45/45 [==============================] - 0s 278us/step - loss: 0.0989 - val_loss: 0.7072\n",
            "Epoch 374/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.1004 - val_loss: 0.6952\n",
            "Epoch 375/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0985 - val_loss: 0.6833\n",
            "Epoch 376/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0980 - val_loss: 0.6615\n",
            "Epoch 377/2000\n",
            "45/45 [==============================] - 0s 342us/step - loss: 0.0980 - val_loss: 0.6585\n",
            "Epoch 378/2000\n",
            "45/45 [==============================] - 0s 308us/step - loss: 0.0980 - val_loss: 0.6734\n",
            "Epoch 379/2000\n",
            "45/45 [==============================] - 0s 292us/step - loss: 0.0981 - val_loss: 0.6589\n",
            "Epoch 380/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0969 - val_loss: 0.6684\n",
            "Epoch 381/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0975 - val_loss: 0.6905\n",
            "Epoch 382/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0971 - val_loss: 0.6951\n",
            "Epoch 383/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0965 - val_loss: 0.6718\n",
            "Epoch 384/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0990 - val_loss: 0.6619\n",
            "Epoch 385/2000\n",
            "45/45 [==============================] - 0s 291us/step - loss: 0.0969 - val_loss: 0.6678\n",
            "Epoch 386/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0961 - val_loss: 0.6579\n",
            "Epoch 387/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0964 - val_loss: 0.6746\n",
            "Epoch 388/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0961 - val_loss: 0.6681\n",
            "Epoch 389/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0958 - val_loss: 0.6471\n",
            "Epoch 390/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0956 - val_loss: 0.6471\n",
            "Epoch 391/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0957 - val_loss: 0.6773\n",
            "Epoch 392/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0962 - val_loss: 0.6980\n",
            "Epoch 393/2000\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0962 - val_loss: 0.6901\n",
            "Epoch 394/2000\n",
            "45/45 [==============================] - 0s 352us/step - loss: 0.0946 - val_loss: 0.6839\n",
            "Epoch 395/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0957 - val_loss: 0.6499\n",
            "Epoch 396/2000\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.0949 - val_loss: 0.6636\n",
            "Epoch 397/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0943 - val_loss: 0.6520\n",
            "Epoch 398/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0942 - val_loss: 0.6445\n",
            "Epoch 399/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0953 - val_loss: 0.6250\n",
            "Epoch 400/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0938 - val_loss: 0.6367\n",
            "Epoch 401/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0939 - val_loss: 0.6646\n",
            "Epoch 402/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0926 - val_loss: 0.6606\n",
            "Epoch 403/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0934 - val_loss: 0.6524\n",
            "Epoch 404/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0935 - val_loss: 0.6694\n",
            "Epoch 405/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0928 - val_loss: 0.6561\n",
            "Epoch 406/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0930 - val_loss: 0.6548\n",
            "Epoch 407/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0920 - val_loss: 0.6567\n",
            "Epoch 408/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0918 - val_loss: 0.6592\n",
            "Epoch 409/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0921 - val_loss: 0.6514\n",
            "Epoch 410/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0925 - val_loss: 0.6432\n",
            "Epoch 411/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0931 - val_loss: 0.6615\n",
            "Epoch 412/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0919 - val_loss: 0.6676\n",
            "Epoch 413/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.0918 - val_loss: 0.6568\n",
            "Epoch 414/2000\n",
            "45/45 [==============================] - 0s 303us/step - loss: 0.0927 - val_loss: 0.6568\n",
            "Epoch 415/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0919 - val_loss: 0.6897\n",
            "Epoch 416/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0913 - val_loss: 0.6466\n",
            "Epoch 417/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0897 - val_loss: 0.6501\n",
            "Epoch 418/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0911 - val_loss: 0.6543\n",
            "Epoch 419/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0901 - val_loss: 0.6555\n",
            "Epoch 420/2000\n",
            "45/45 [==============================] - 0s 312us/step - loss: 0.0896 - val_loss: 0.6567\n",
            "Epoch 421/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0908 - val_loss: 0.6703\n",
            "Epoch 422/2000\n",
            "45/45 [==============================] - 0s 281us/step - loss: 0.0903 - val_loss: 0.6539\n",
            "Epoch 423/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0891 - val_loss: 0.6421\n",
            "Epoch 424/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0894 - val_loss: 0.6696\n",
            "Epoch 425/2000\n",
            "45/45 [==============================] - 0s 305us/step - loss: 0.0898 - val_loss: 0.6605\n",
            "Epoch 426/2000\n",
            "45/45 [==============================] - 0s 315us/step - loss: 0.0892 - val_loss: 0.6312\n",
            "Epoch 427/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0883 - val_loss: 0.6175\n",
            "Epoch 428/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0890 - val_loss: 0.6548\n",
            "Epoch 429/2000\n",
            "45/45 [==============================] - 0s 320us/step - loss: 0.0880 - val_loss: 0.6634\n",
            "Epoch 430/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0876 - val_loss: 0.6489\n",
            "Epoch 431/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0879 - val_loss: 0.6460\n",
            "Epoch 432/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0871 - val_loss: 0.6440\n",
            "Epoch 433/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0875 - val_loss: 0.6171\n",
            "Epoch 434/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0867 - val_loss: 0.6257\n",
            "Epoch 435/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0869 - val_loss: 0.6543\n",
            "Epoch 436/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0875 - val_loss: 0.6271\n",
            "Epoch 437/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0870 - val_loss: 0.6098\n",
            "Epoch 438/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0855 - val_loss: 0.6104\n",
            "Epoch 439/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0861 - val_loss: 0.6118\n",
            "Epoch 440/2000\n",
            "45/45 [==============================] - 0s 302us/step - loss: 0.0857 - val_loss: 0.6279\n",
            "Epoch 441/2000\n",
            "45/45 [==============================] - 0s 290us/step - loss: 0.0862 - val_loss: 0.6315\n",
            "Epoch 442/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0846 - val_loss: 0.6272\n",
            "Epoch 443/2000\n",
            "45/45 [==============================] - 0s 287us/step - loss: 0.0853 - val_loss: 0.6476\n",
            "Epoch 444/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0848 - val_loss: 0.6378\n",
            "Epoch 445/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0851 - val_loss: 0.6268\n",
            "Epoch 446/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0847 - val_loss: 0.6644\n",
            "Epoch 447/2000\n",
            "45/45 [==============================] - 0s 345us/step - loss: 0.0840 - val_loss: 0.6440\n",
            "Epoch 448/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0849 - val_loss: 0.6199\n",
            "Epoch 449/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0841 - val_loss: 0.6049\n",
            "Epoch 450/2000\n",
            "45/45 [==============================] - 0s 290us/step - loss: 0.0836 - val_loss: 0.6086\n",
            "Epoch 451/2000\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.0837 - val_loss: 0.6088\n",
            "Epoch 452/2000\n",
            "45/45 [==============================] - 0s 347us/step - loss: 0.0831 - val_loss: 0.6130\n",
            "Epoch 453/2000\n",
            "45/45 [==============================] - 0s 291us/step - loss: 0.0835 - val_loss: 0.6342\n",
            "Epoch 454/2000\n",
            "45/45 [==============================] - 0s 296us/step - loss: 0.0826 - val_loss: 0.6316\n",
            "Epoch 455/2000\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0826 - val_loss: 0.6255\n",
            "Epoch 456/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0823 - val_loss: 0.6117\n",
            "Epoch 457/2000\n",
            "45/45 [==============================] - 0s 191us/step - loss: 0.0831 - val_loss: 0.5901\n",
            "Epoch 458/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0848 - val_loss: 0.5914\n",
            "Epoch 459/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0820 - val_loss: 0.5929\n",
            "Epoch 460/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0814 - val_loss: 0.6099\n",
            "Epoch 461/2000\n",
            "45/45 [==============================] - 0s 292us/step - loss: 0.0821 - val_loss: 0.6050\n",
            "Epoch 462/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0823 - val_loss: 0.5829\n",
            "Epoch 463/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0824 - val_loss: 0.6061\n",
            "Epoch 464/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0813 - val_loss: 0.6132\n",
            "Epoch 465/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0806 - val_loss: 0.6054\n",
            "Epoch 466/2000\n",
            "45/45 [==============================] - 0s 298us/step - loss: 0.0810 - val_loss: 0.5974\n",
            "Epoch 467/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0819 - val_loss: 0.5817\n",
            "Epoch 468/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0807 - val_loss: 0.5995\n",
            "Epoch 469/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0800 - val_loss: 0.6036\n",
            "Epoch 470/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0811 - val_loss: 0.5825\n",
            "Epoch 471/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0805 - val_loss: 0.5903\n",
            "Epoch 472/2000\n",
            "45/45 [==============================] - 0s 508us/step - loss: 0.0804 - val_loss: 0.6087\n",
            "Epoch 473/2000\n",
            "45/45 [==============================] - 0s 300us/step - loss: 0.0795 - val_loss: 0.5926\n",
            "Epoch 474/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0795 - val_loss: 0.5940\n",
            "Epoch 475/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0791 - val_loss: 0.5857\n",
            "Epoch 476/2000\n",
            "45/45 [==============================] - 0s 285us/step - loss: 0.0789 - val_loss: 0.5907\n",
            "Epoch 477/2000\n",
            "45/45 [==============================] - 0s 435us/step - loss: 0.0794 - val_loss: 0.5963\n",
            "Epoch 478/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0788 - val_loss: 0.5955\n",
            "Epoch 479/2000\n",
            "45/45 [==============================] - 0s 328us/step - loss: 0.0789 - val_loss: 0.5967\n",
            "Epoch 480/2000\n",
            "45/45 [==============================] - 0s 290us/step - loss: 0.0792 - val_loss: 0.5980\n",
            "Epoch 481/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0792 - val_loss: 0.6085\n",
            "Epoch 482/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0778 - val_loss: 0.6229\n",
            "Epoch 483/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0778 - val_loss: 0.6106\n",
            "Epoch 484/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0771 - val_loss: 0.5901\n",
            "Epoch 485/2000\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0772 - val_loss: 0.5860\n",
            "Epoch 486/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0771 - val_loss: 0.5971\n",
            "Epoch 487/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0777 - val_loss: 0.6116\n",
            "Epoch 488/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0772 - val_loss: 0.5975\n",
            "Epoch 489/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.0767 - val_loss: 0.5978\n",
            "Epoch 490/2000\n",
            "45/45 [==============================] - 0s 388us/step - loss: 0.0765 - val_loss: 0.5880\n",
            "Epoch 491/2000\n",
            "45/45 [==============================] - 0s 344us/step - loss: 0.0764 - val_loss: 0.5884\n",
            "Epoch 492/2000\n",
            "45/45 [==============================] - 0s 320us/step - loss: 0.0760 - val_loss: 0.5897\n",
            "Epoch 493/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0767 - val_loss: 0.5752\n",
            "Epoch 494/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0765 - val_loss: 0.5632\n",
            "Epoch 495/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0756 - val_loss: 0.5723\n",
            "Epoch 496/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0765 - val_loss: 0.5930\n",
            "Epoch 497/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0760 - val_loss: 0.6060\n",
            "Epoch 498/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0742 - val_loss: 0.5979\n",
            "Epoch 499/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0743 - val_loss: 0.5932\n",
            "Epoch 500/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0744 - val_loss: 0.5952\n",
            "Epoch 501/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0743 - val_loss: 0.5904\n",
            "Epoch 502/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0740 - val_loss: 0.5949\n",
            "Epoch 503/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0750 - val_loss: 0.5728\n",
            "Epoch 504/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0743 - val_loss: 0.5564\n",
            "Epoch 505/2000\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.0757 - val_loss: 0.5657\n",
            "Epoch 506/2000\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0742 - val_loss: 0.5604\n",
            "Epoch 507/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0731 - val_loss: 0.5713\n",
            "Epoch 508/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0730 - val_loss: 0.5556\n",
            "Epoch 509/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0723 - val_loss: 0.5826\n",
            "Epoch 510/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0722 - val_loss: 0.5785\n",
            "Epoch 511/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0725 - val_loss: 0.5675\n",
            "Epoch 512/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0720 - val_loss: 0.5600\n",
            "Epoch 513/2000\n",
            "45/45 [==============================] - 0s 183us/step - loss: 0.0739 - val_loss: 0.5773\n",
            "Epoch 514/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0721 - val_loss: 0.5775\n",
            "Epoch 515/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0712 - val_loss: 0.5745\n",
            "Epoch 516/2000\n",
            "45/45 [==============================] - 0s 286us/step - loss: 0.0711 - val_loss: 0.5758\n",
            "Epoch 517/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0715 - val_loss: 0.5584\n",
            "Epoch 518/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0707 - val_loss: 0.5625\n",
            "Epoch 519/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0712 - val_loss: 0.5518\n",
            "Epoch 520/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0705 - val_loss: 0.5545\n",
            "Epoch 521/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0718 - val_loss: 0.5384\n",
            "Epoch 522/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0708 - val_loss: 0.5439\n",
            "Epoch 523/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0705 - val_loss: 0.5622\n",
            "Epoch 524/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0694 - val_loss: 0.5724\n",
            "Epoch 525/2000\n",
            "45/45 [==============================] - 0s 332us/step - loss: 0.0703 - val_loss: 0.5590\n",
            "Epoch 526/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0699 - val_loss: 0.5453\n",
            "Epoch 527/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0699 - val_loss: 0.5386\n",
            "Epoch 528/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0696 - val_loss: 0.5387\n",
            "Epoch 529/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0696 - val_loss: 0.5278\n",
            "Epoch 530/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0699 - val_loss: 0.5732\n",
            "Epoch 531/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0693 - val_loss: 0.5490\n",
            "Epoch 532/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0688 - val_loss: 0.5620\n",
            "Epoch 533/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0684 - val_loss: 0.5647\n",
            "Epoch 534/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0686 - val_loss: 0.5452\n",
            "Epoch 535/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0686 - val_loss: 0.5777\n",
            "Epoch 536/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0682 - val_loss: 0.5766\n",
            "Epoch 537/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0682 - val_loss: 0.5733\n",
            "Epoch 538/2000\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.0677 - val_loss: 0.5603\n",
            "Epoch 539/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0675 - val_loss: 0.5648\n",
            "Epoch 540/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0674 - val_loss: 0.5616\n",
            "Epoch 541/2000\n",
            "45/45 [==============================] - 0s 330us/step - loss: 0.0688 - val_loss: 0.5518\n",
            "Epoch 542/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0668 - val_loss: 0.5335\n",
            "Epoch 543/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0677 - val_loss: 0.5396\n",
            "Epoch 544/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0661 - val_loss: 0.5450\n",
            "Epoch 545/2000\n",
            "45/45 [==============================] - 0s 601us/step - loss: 0.0669 - val_loss: 0.5481\n",
            "Epoch 546/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0665 - val_loss: 0.5495\n",
            "Epoch 547/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0658 - val_loss: 0.5409\n",
            "Epoch 548/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0658 - val_loss: 0.5407\n",
            "Epoch 549/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0667 - val_loss: 0.5418\n",
            "Epoch 550/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0660 - val_loss: 0.5329\n",
            "Epoch 551/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0650 - val_loss: 0.5462\n",
            "Epoch 552/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0648 - val_loss: 0.5392\n",
            "Epoch 553/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0647 - val_loss: 0.5409\n",
            "Epoch 554/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0655 - val_loss: 0.5554\n",
            "Epoch 555/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.0645 - val_loss: 0.5463\n",
            "Epoch 556/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0648 - val_loss: 0.5393\n",
            "Epoch 557/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0643 - val_loss: 0.5371\n",
            "Epoch 558/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0657 - val_loss: 0.5211\n",
            "Epoch 559/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0642 - val_loss: 0.5218\n",
            "Epoch 560/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0644 - val_loss: 0.5381\n",
            "Epoch 561/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0635 - val_loss: 0.5449\n",
            "Epoch 562/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0637 - val_loss: 0.5367\n",
            "Epoch 563/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0644 - val_loss: 0.5544\n",
            "Epoch 564/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0631 - val_loss: 0.5490\n",
            "Epoch 565/2000\n",
            "45/45 [==============================] - 0s 340us/step - loss: 0.0636 - val_loss: 0.5500\n",
            "Epoch 566/2000\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.0631 - val_loss: 0.5493\n",
            "Epoch 567/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0625 - val_loss: 0.5252\n",
            "Epoch 568/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0629 - val_loss: 0.5159\n",
            "Epoch 569/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0634 - val_loss: 0.5260\n",
            "Epoch 570/2000\n",
            "45/45 [==============================] - 0s 191us/step - loss: 0.0619 - val_loss: 0.5381\n",
            "Epoch 571/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0626 - val_loss: 0.5556\n",
            "Epoch 572/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0616 - val_loss: 0.5309\n",
            "Epoch 573/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0618 - val_loss: 0.5085\n",
            "Epoch 574/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0635 - val_loss: 0.5326\n",
            "Epoch 575/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0620 - val_loss: 0.5234\n",
            "Epoch 576/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0611 - val_loss: 0.5147\n",
            "Epoch 577/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0607 - val_loss: 0.5198\n",
            "Epoch 578/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0611 - val_loss: 0.5093\n",
            "Epoch 579/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0611 - val_loss: 0.5269\n",
            "Epoch 580/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0613 - val_loss: 0.5273\n",
            "Epoch 581/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0605 - val_loss: 0.5248\n",
            "Epoch 582/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0602 - val_loss: 0.5409\n",
            "Epoch 583/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0601 - val_loss: 0.5263\n",
            "Epoch 584/2000\n",
            "45/45 [==============================] - 0s 307us/step - loss: 0.0600 - val_loss: 0.5173\n",
            "Epoch 585/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0613 - val_loss: 0.5185\n",
            "Epoch 586/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0598 - val_loss: 0.5192\n",
            "Epoch 587/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0595 - val_loss: 0.5040\n",
            "Epoch 588/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0593 - val_loss: 0.4982\n",
            "Epoch 589/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0600 - val_loss: 0.5025\n",
            "Epoch 590/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0589 - val_loss: 0.5105\n",
            "Epoch 591/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0587 - val_loss: 0.5155\n",
            "Epoch 592/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0585 - val_loss: 0.5086\n",
            "Epoch 593/2000\n",
            "45/45 [==============================] - 0s 328us/step - loss: 0.0587 - val_loss: 0.5316\n",
            "Epoch 594/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0587 - val_loss: 0.5083\n",
            "Epoch 595/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0578 - val_loss: 0.5140\n",
            "Epoch 596/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0582 - val_loss: 0.5084\n",
            "Epoch 597/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0576 - val_loss: 0.5103\n",
            "Epoch 598/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0573 - val_loss: 0.5174\n",
            "Epoch 599/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0576 - val_loss: 0.5260\n",
            "Epoch 600/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.0577 - val_loss: 0.5258\n",
            "Epoch 601/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0572 - val_loss: 0.5166\n",
            "Epoch 602/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0569 - val_loss: 0.5064\n",
            "Epoch 603/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0570 - val_loss: 0.5035\n",
            "Epoch 604/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0564 - val_loss: 0.4963\n",
            "Epoch 605/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0566 - val_loss: 0.4972\n",
            "Epoch 606/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0564 - val_loss: 0.4946\n",
            "Epoch 607/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0565 - val_loss: 0.4930\n",
            "Epoch 608/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0566 - val_loss: 0.4926\n",
            "Epoch 609/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0557 - val_loss: 0.4926\n",
            "Epoch 610/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0567 - val_loss: 0.4976\n",
            "Epoch 611/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0559 - val_loss: 0.5062\n",
            "Epoch 612/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0558 - val_loss: 0.4968\n",
            "Epoch 613/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0557 - val_loss: 0.4883\n",
            "Epoch 614/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0553 - val_loss: 0.4930\n",
            "Epoch 615/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0551 - val_loss: 0.4928\n",
            "Epoch 616/2000\n",
            "45/45 [==============================] - 0s 281us/step - loss: 0.0546 - val_loss: 0.4884\n",
            "Epoch 617/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0548 - val_loss: 0.4836\n",
            "Epoch 618/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0546 - val_loss: 0.4858\n",
            "Epoch 619/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0551 - val_loss: 0.4882\n",
            "Epoch 620/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0543 - val_loss: 0.4883\n",
            "Epoch 621/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0545 - val_loss: 0.4901\n",
            "Epoch 622/2000\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.0543 - val_loss: 0.4879\n",
            "Epoch 623/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0541 - val_loss: 0.4946\n",
            "Epoch 624/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0543 - val_loss: 0.4776\n",
            "Epoch 625/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0540 - val_loss: 0.4895\n",
            "Epoch 626/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0538 - val_loss: 0.4934\n",
            "Epoch 627/2000\n",
            "45/45 [==============================] - 0s 182us/step - loss: 0.0541 - val_loss: 0.4860\n",
            "Epoch 628/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0532 - val_loss: 0.4988\n",
            "Epoch 629/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0538 - val_loss: 0.4911\n",
            "Epoch 630/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0532 - val_loss: 0.5053\n",
            "Epoch 631/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0536 - val_loss: 0.5025\n",
            "Epoch 632/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0529 - val_loss: 0.4881\n",
            "Epoch 633/2000\n",
            "45/45 [==============================] - 0s 276us/step - loss: 0.0528 - val_loss: 0.5047\n",
            "Epoch 634/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0533 - val_loss: 0.4894\n",
            "Epoch 635/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0524 - val_loss: 0.4670\n",
            "Epoch 636/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0526 - val_loss: 0.4755\n",
            "Epoch 637/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0517 - val_loss: 0.4855\n",
            "Epoch 638/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0518 - val_loss: 0.4770\n",
            "Epoch 639/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0518 - val_loss: 0.4852\n",
            "Epoch 640/2000\n",
            "45/45 [==============================] - 0s 303us/step - loss: 0.0514 - val_loss: 0.4812\n",
            "Epoch 641/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0514 - val_loss: 0.4803\n",
            "Epoch 642/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0514 - val_loss: 0.4746\n",
            "Epoch 643/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0512 - val_loss: 0.4771\n",
            "Epoch 644/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0512 - val_loss: 0.4704\n",
            "Epoch 645/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0507 - val_loss: 0.4781\n",
            "Epoch 646/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0513 - val_loss: 0.4806\n",
            "Epoch 647/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0507 - val_loss: 0.4613\n",
            "Epoch 648/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0505 - val_loss: 0.4758\n",
            "Epoch 649/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0519 - val_loss: 0.4753\n",
            "Epoch 650/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0503 - val_loss: 0.4728\n",
            "Epoch 651/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0500 - val_loss: 0.4685\n",
            "Epoch 652/2000\n",
            "45/45 [==============================] - 0s 195us/step - loss: 0.0497 - val_loss: 0.4816\n",
            "Epoch 653/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0500 - val_loss: 0.4804\n",
            "Epoch 654/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0498 - val_loss: 0.4781\n",
            "Epoch 655/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0493 - val_loss: 0.4567\n",
            "Epoch 656/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0493 - val_loss: 0.4466\n",
            "Epoch 657/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0497 - val_loss: 0.4623\n",
            "Epoch 658/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0504 - val_loss: 0.4721\n",
            "Epoch 659/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0490 - val_loss: 0.4584\n",
            "Epoch 660/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0491 - val_loss: 0.4585\n",
            "Epoch 661/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0487 - val_loss: 0.4511\n",
            "Epoch 662/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0483 - val_loss: 0.4538\n",
            "Epoch 663/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0486 - val_loss: 0.4442\n",
            "Epoch 664/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0495 - val_loss: 0.4393\n",
            "Epoch 665/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0484 - val_loss: 0.4504\n",
            "Epoch 666/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0481 - val_loss: 0.4441\n",
            "Epoch 667/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0477 - val_loss: 0.4465\n",
            "Epoch 668/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0489 - val_loss: 0.4534\n",
            "Epoch 669/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0480 - val_loss: 0.4421\n",
            "Epoch 670/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0483 - val_loss: 0.4533\n",
            "Epoch 671/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0483 - val_loss: 0.4520\n",
            "Epoch 672/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0473 - val_loss: 0.4433\n",
            "Epoch 673/2000\n",
            "45/45 [==============================] - 0s 322us/step - loss: 0.0476 - val_loss: 0.4395\n",
            "Epoch 674/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0480 - val_loss: 0.4335\n",
            "Epoch 675/2000\n",
            "45/45 [==============================] - 0s 191us/step - loss: 0.0471 - val_loss: 0.4336\n",
            "Epoch 676/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0467 - val_loss: 0.4352\n",
            "Epoch 677/2000\n",
            "45/45 [==============================] - 0s 297us/step - loss: 0.0467 - val_loss: 0.4479\n",
            "Epoch 678/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0463 - val_loss: 0.4434\n",
            "Epoch 679/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0464 - val_loss: 0.4398\n",
            "Epoch 680/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0465 - val_loss: 0.4455\n",
            "Epoch 681/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0468 - val_loss: 0.4261\n",
            "Epoch 682/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0466 - val_loss: 0.4525\n",
            "Epoch 683/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0457 - val_loss: 0.4474\n",
            "Epoch 684/2000\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0461 - val_loss: 0.4461\n",
            "Epoch 685/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0464 - val_loss: 0.4413\n",
            "Epoch 686/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0457 - val_loss: 0.4432\n",
            "Epoch 687/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0469 - val_loss: 0.4390\n",
            "Epoch 688/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0451 - val_loss: 0.4420\n",
            "Epoch 689/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0459 - val_loss: 0.4323\n",
            "Epoch 690/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0450 - val_loss: 0.4345\n",
            "Epoch 691/2000\n",
            "45/45 [==============================] - 0s 183us/step - loss: 0.0460 - val_loss: 0.4247\n",
            "Epoch 692/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0452 - val_loss: 0.4242\n",
            "Epoch 693/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0454 - val_loss: 0.4500\n",
            "Epoch 694/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0445 - val_loss: 0.4376\n",
            "Epoch 695/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0443 - val_loss: 0.4334\n",
            "Epoch 696/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0446 - val_loss: 0.4278\n",
            "Epoch 697/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0441 - val_loss: 0.4381\n",
            "Epoch 698/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0442 - val_loss: 0.4426\n",
            "Epoch 699/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.0442 - val_loss: 0.4437\n",
            "Epoch 700/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0441 - val_loss: 0.4231\n",
            "Epoch 701/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0436 - val_loss: 0.4296\n",
            "Epoch 702/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0441 - val_loss: 0.4235\n",
            "Epoch 703/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0436 - val_loss: 0.4153\n",
            "Epoch 704/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0433 - val_loss: 0.4219\n",
            "Epoch 705/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0436 - val_loss: 0.4149\n",
            "Epoch 706/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0431 - val_loss: 0.4119\n",
            "Epoch 707/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0436 - val_loss: 0.4264\n",
            "Epoch 708/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0429 - val_loss: 0.4168\n",
            "Epoch 709/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0428 - val_loss: 0.4231\n",
            "Epoch 710/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0430 - val_loss: 0.4115\n",
            "Epoch 711/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0430 - val_loss: 0.4074\n",
            "Epoch 712/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0424 - val_loss: 0.4197\n",
            "Epoch 713/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0423 - val_loss: 0.4182\n",
            "Epoch 714/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0422 - val_loss: 0.4125\n",
            "Epoch 715/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0427 - val_loss: 0.4095\n",
            "Epoch 716/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0420 - val_loss: 0.4228\n",
            "Epoch 717/2000\n",
            "45/45 [==============================] - 0s 287us/step - loss: 0.0423 - val_loss: 0.4064\n",
            "Epoch 718/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0418 - val_loss: 0.4108\n",
            "Epoch 719/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0420 - val_loss: 0.4046\n",
            "Epoch 720/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0413 - val_loss: 0.4125\n",
            "Epoch 721/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0419 - val_loss: 0.4223\n",
            "Epoch 722/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0413 - val_loss: 0.4148\n",
            "Epoch 723/2000\n",
            "45/45 [==============================] - 0s 345us/step - loss: 0.0412 - val_loss: 0.4223\n",
            "Epoch 724/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0412 - val_loss: 0.4065\n",
            "Epoch 725/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0410 - val_loss: 0.4152\n",
            "Epoch 726/2000\n",
            "45/45 [==============================] - 0s 336us/step - loss: 0.0416 - val_loss: 0.4018\n",
            "Epoch 727/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0408 - val_loss: 0.3983\n",
            "Epoch 728/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0404 - val_loss: 0.4050\n",
            "Epoch 729/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0410 - val_loss: 0.4093\n",
            "Epoch 730/2000\n",
            "45/45 [==============================] - 0s 187us/step - loss: 0.0407 - val_loss: 0.4040\n",
            "Epoch 731/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0405 - val_loss: 0.4122\n",
            "Epoch 732/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0403 - val_loss: 0.4128\n",
            "Epoch 733/2000\n",
            "45/45 [==============================] - 0s 167us/step - loss: 0.0400 - val_loss: 0.4148\n",
            "Epoch 734/2000\n",
            "45/45 [==============================] - 0s 180us/step - loss: 0.0400 - val_loss: 0.4192\n",
            "Epoch 735/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0400 - val_loss: 0.4049\n",
            "Epoch 736/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0400 - val_loss: 0.4084\n",
            "Epoch 737/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0398 - val_loss: 0.4148\n",
            "Epoch 738/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0400 - val_loss: 0.4159\n",
            "Epoch 739/2000\n",
            "45/45 [==============================] - 0s 317us/step - loss: 0.0397 - val_loss: 0.4072\n",
            "Epoch 740/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0399 - val_loss: 0.3974\n",
            "Epoch 741/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0393 - val_loss: 0.3895\n",
            "Epoch 742/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0392 - val_loss: 0.3924\n",
            "Epoch 743/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0395 - val_loss: 0.3913\n",
            "Epoch 744/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0391 - val_loss: 0.3879\n",
            "Epoch 745/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0392 - val_loss: 0.4099\n",
            "Epoch 746/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0387 - val_loss: 0.4044\n",
            "Epoch 747/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0387 - val_loss: 0.3999\n",
            "Epoch 748/2000\n",
            "45/45 [==============================] - 0s 190us/step - loss: 0.0385 - val_loss: 0.4057\n",
            "Epoch 749/2000\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.0388 - val_loss: 0.4087\n",
            "Epoch 750/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0384 - val_loss: 0.4043\n",
            "Epoch 751/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0389 - val_loss: 0.3834\n",
            "Epoch 752/2000\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.0387 - val_loss: 0.3806\n",
            "Epoch 753/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0383 - val_loss: 0.3822\n",
            "Epoch 754/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0384 - val_loss: 0.3905\n",
            "Epoch 755/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0380 - val_loss: 0.4007\n",
            "Epoch 756/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0377 - val_loss: 0.3875\n",
            "Epoch 757/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0377 - val_loss: 0.3921\n",
            "Epoch 758/2000\n",
            "45/45 [==============================] - 0s 276us/step - loss: 0.0382 - val_loss: 0.3917\n",
            "Epoch 759/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0381 - val_loss: 0.3827\n",
            "Epoch 760/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0377 - val_loss: 0.3939\n",
            "Epoch 761/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0380 - val_loss: 0.3910\n",
            "Epoch 762/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0373 - val_loss: 0.3763\n",
            "Epoch 763/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0369 - val_loss: 0.3766\n",
            "Epoch 764/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0371 - val_loss: 0.3789\n",
            "Epoch 765/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0376 - val_loss: 0.3813\n",
            "Epoch 766/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0368 - val_loss: 0.3927\n",
            "Epoch 767/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0366 - val_loss: 0.3784\n",
            "Epoch 768/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0373 - val_loss: 0.3920\n",
            "Epoch 769/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0364 - val_loss: 0.3931\n",
            "Epoch 770/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0364 - val_loss: 0.3933\n",
            "Epoch 771/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0363 - val_loss: 0.3761\n",
            "Epoch 772/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0361 - val_loss: 0.3759\n",
            "Epoch 773/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0364 - val_loss: 0.3879\n",
            "Epoch 774/2000\n",
            "45/45 [==============================] - 0s 337us/step - loss: 0.0361 - val_loss: 0.3789\n",
            "Epoch 775/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0368 - val_loss: 0.3846\n",
            "Epoch 776/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0359 - val_loss: 0.3798\n",
            "Epoch 777/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0360 - val_loss: 0.3910\n",
            "Epoch 778/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0357 - val_loss: 0.3844\n",
            "Epoch 779/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0355 - val_loss: 0.3845\n",
            "Epoch 780/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0352 - val_loss: 0.3806\n",
            "Epoch 781/2000\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0362 - val_loss: 0.3794\n",
            "Epoch 782/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0357 - val_loss: 0.3950\n",
            "Epoch 783/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0355 - val_loss: 0.3781\n",
            "Epoch 784/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0353 - val_loss: 0.3792\n",
            "Epoch 785/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0348 - val_loss: 0.3788\n",
            "Epoch 786/2000\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.0348 - val_loss: 0.3773\n",
            "Epoch 787/2000\n",
            "45/45 [==============================] - 0s 191us/step - loss: 0.0348 - val_loss: 0.3716\n",
            "Epoch 788/2000\n",
            "45/45 [==============================] - 0s 187us/step - loss: 0.0347 - val_loss: 0.3714\n",
            "Epoch 789/2000\n",
            "45/45 [==============================] - 0s 187us/step - loss: 0.0351 - val_loss: 0.3570\n",
            "Epoch 790/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0348 - val_loss: 0.3499\n",
            "Epoch 791/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0345 - val_loss: 0.3583\n",
            "Epoch 792/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0352 - val_loss: 0.3683\n",
            "Epoch 793/2000\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0341 - val_loss: 0.3635\n",
            "Epoch 794/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0345 - val_loss: 0.3530\n",
            "Epoch 795/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0342 - val_loss: 0.3646\n",
            "Epoch 796/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0339 - val_loss: 0.3649\n",
            "Epoch 797/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0342 - val_loss: 0.3683\n",
            "Epoch 798/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0341 - val_loss: 0.3843\n",
            "Epoch 799/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0341 - val_loss: 0.3638\n",
            "Epoch 800/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0339 - val_loss: 0.3716\n",
            "Epoch 801/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0338 - val_loss: 0.3715\n",
            "Epoch 802/2000\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0335 - val_loss: 0.3598\n",
            "Epoch 803/2000\n",
            "45/45 [==============================] - 0s 332us/step - loss: 0.0334 - val_loss: 0.3601\n",
            "Epoch 804/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0335 - val_loss: 0.3563\n",
            "Epoch 805/2000\n",
            "45/45 [==============================] - 0s 319us/step - loss: 0.0334 - val_loss: 0.3432\n",
            "Epoch 806/2000\n",
            "45/45 [==============================] - 0s 188us/step - loss: 0.0332 - val_loss: 0.3558\n",
            "Epoch 807/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0331 - val_loss: 0.3595\n",
            "Epoch 808/2000\n",
            "45/45 [==============================] - 0s 313us/step - loss: 0.0335 - val_loss: 0.3610\n",
            "Epoch 809/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0332 - val_loss: 0.3602\n",
            "Epoch 810/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0330 - val_loss: 0.3713\n",
            "Epoch 811/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0328 - val_loss: 0.3638\n",
            "Epoch 812/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0327 - val_loss: 0.3556\n",
            "Epoch 813/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0326 - val_loss: 0.3603\n",
            "Epoch 814/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0325 - val_loss: 0.3521\n",
            "Epoch 815/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0328 - val_loss: 0.3354\n",
            "Epoch 816/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0325 - val_loss: 0.3356\n",
            "Epoch 817/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0327 - val_loss: 0.3335\n",
            "Epoch 818/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0323 - val_loss: 0.3405\n",
            "Epoch 819/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0320 - val_loss: 0.3385\n",
            "Epoch 820/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0326 - val_loss: 0.3471\n",
            "Epoch 821/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0325 - val_loss: 0.3471\n",
            "Epoch 822/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0319 - val_loss: 0.3515\n",
            "Epoch 823/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0323 - val_loss: 0.3508\n",
            "Epoch 824/2000\n",
            "45/45 [==============================] - 0s 310us/step - loss: 0.0318 - val_loss: 0.3440\n",
            "Epoch 825/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0319 - val_loss: 0.3381\n",
            "Epoch 826/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0320 - val_loss: 0.3356\n",
            "Epoch 827/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0316 - val_loss: 0.3301\n",
            "Epoch 828/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0316 - val_loss: 0.3378\n",
            "Epoch 829/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0316 - val_loss: 0.3441\n",
            "Epoch 830/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0313 - val_loss: 0.3528\n",
            "Epoch 831/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0313 - val_loss: 0.3442\n",
            "Epoch 832/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0310 - val_loss: 0.3392\n",
            "Epoch 833/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0313 - val_loss: 0.3456\n",
            "Epoch 834/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0310 - val_loss: 0.3446\n",
            "Epoch 835/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0308 - val_loss: 0.3447\n",
            "Epoch 836/2000\n",
            "45/45 [==============================] - 0s 296us/step - loss: 0.0311 - val_loss: 0.3382\n",
            "Epoch 837/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0308 - val_loss: 0.3383\n",
            "Epoch 838/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0310 - val_loss: 0.3457\n",
            "Epoch 839/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0309 - val_loss: 0.3412\n",
            "Epoch 840/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0308 - val_loss: 0.3427\n",
            "Epoch 841/2000\n",
            "45/45 [==============================] - 0s 327us/step - loss: 0.0304 - val_loss: 0.3436\n",
            "Epoch 842/2000\n",
            "45/45 [==============================] - 0s 280us/step - loss: 0.0304 - val_loss: 0.3389\n",
            "Epoch 843/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0307 - val_loss: 0.3375\n",
            "Epoch 844/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0304 - val_loss: 0.3362\n",
            "Epoch 845/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0302 - val_loss: 0.3415\n",
            "Epoch 846/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0303 - val_loss: 0.3468\n",
            "Epoch 847/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0304 - val_loss: 0.3509\n",
            "Epoch 848/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0304 - val_loss: 0.3481\n",
            "Epoch 849/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0299 - val_loss: 0.3465\n",
            "Epoch 850/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0297 - val_loss: 0.3352\n",
            "Epoch 851/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0299 - val_loss: 0.3213\n",
            "Epoch 852/2000\n",
            "45/45 [==============================] - 0s 293us/step - loss: 0.0298 - val_loss: 0.3326\n",
            "Epoch 853/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0295 - val_loss: 0.3392\n",
            "Epoch 854/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0298 - val_loss: 0.3388\n",
            "Epoch 855/2000\n",
            "45/45 [==============================] - 0s 307us/step - loss: 0.0295 - val_loss: 0.3251\n",
            "Epoch 856/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0294 - val_loss: 0.3342\n",
            "Epoch 857/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0294 - val_loss: 0.3361\n",
            "Epoch 858/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0293 - val_loss: 0.3351\n",
            "Epoch 859/2000\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.0291 - val_loss: 0.3291\n",
            "Epoch 860/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0293 - val_loss: 0.3330\n",
            "Epoch 861/2000\n",
            "45/45 [==============================] - 0s 326us/step - loss: 0.0290 - val_loss: 0.3315\n",
            "Epoch 862/2000\n",
            "45/45 [==============================] - 0s 307us/step - loss: 0.0290 - val_loss: 0.3393\n",
            "Epoch 863/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0290 - val_loss: 0.3264\n",
            "Epoch 864/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0291 - val_loss: 0.3373\n",
            "Epoch 865/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0287 - val_loss: 0.3267\n",
            "Epoch 866/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0288 - val_loss: 0.3265\n",
            "Epoch 867/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0287 - val_loss: 0.3238\n",
            "Epoch 868/2000\n",
            "45/45 [==============================] - 0s 315us/step - loss: 0.0294 - val_loss: 0.3159\n",
            "Epoch 869/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0288 - val_loss: 0.3227\n",
            "Epoch 870/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0284 - val_loss: 0.3172\n",
            "Epoch 871/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0283 - val_loss: 0.3220\n",
            "Epoch 872/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0283 - val_loss: 0.3137\n",
            "Epoch 873/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0283 - val_loss: 0.3094\n",
            "Epoch 874/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0282 - val_loss: 0.3161\n",
            "Epoch 875/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0280 - val_loss: 0.3151\n",
            "Epoch 876/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0285 - val_loss: 0.3137\n",
            "Epoch 877/2000\n",
            "45/45 [==============================] - 0s 313us/step - loss: 0.0280 - val_loss: 0.3128\n",
            "Epoch 878/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0277 - val_loss: 0.3151\n",
            "Epoch 879/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0281 - val_loss: 0.3133\n",
            "Epoch 880/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0281 - val_loss: 0.3112\n",
            "Epoch 881/2000\n",
            "45/45 [==============================] - 0s 283us/step - loss: 0.0277 - val_loss: 0.3157\n",
            "Epoch 882/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0277 - val_loss: 0.3100\n",
            "Epoch 883/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0276 - val_loss: 0.3111\n",
            "Epoch 884/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0276 - val_loss: 0.3112\n",
            "Epoch 885/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0275 - val_loss: 0.3115\n",
            "Epoch 886/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0273 - val_loss: 0.3085\n",
            "Epoch 887/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0272 - val_loss: 0.3020\n",
            "Epoch 888/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0274 - val_loss: 0.3089\n",
            "Epoch 889/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0276 - val_loss: 0.3142\n",
            "Epoch 890/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0270 - val_loss: 0.3093\n",
            "Epoch 891/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0269 - val_loss: 0.3060\n",
            "Epoch 892/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0274 - val_loss: 0.3009\n",
            "Epoch 893/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0271 - val_loss: 0.2983\n",
            "Epoch 894/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0268 - val_loss: 0.3102\n",
            "Epoch 895/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0269 - val_loss: 0.3160\n",
            "Epoch 896/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0269 - val_loss: 0.3032\n",
            "Epoch 897/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0269 - val_loss: 0.3037\n",
            "Epoch 898/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0267 - val_loss: 0.2980\n",
            "Epoch 899/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0265 - val_loss: 0.3054\n",
            "Epoch 900/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0265 - val_loss: 0.3011\n",
            "Epoch 901/2000\n",
            "45/45 [==============================] - 0s 317us/step - loss: 0.0265 - val_loss: 0.3093\n",
            "Epoch 902/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0266 - val_loss: 0.3040\n",
            "Epoch 903/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0266 - val_loss: 0.3020\n",
            "Epoch 904/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0264 - val_loss: 0.2983\n",
            "Epoch 905/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0264 - val_loss: 0.3021\n",
            "Epoch 906/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0261 - val_loss: 0.3023\n",
            "Epoch 907/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0266 - val_loss: 0.2941\n",
            "Epoch 908/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0265 - val_loss: 0.2919\n",
            "Epoch 909/2000\n",
            "45/45 [==============================] - 0s 297us/step - loss: 0.0261 - val_loss: 0.3054\n",
            "Epoch 910/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0262 - val_loss: 0.3076\n",
            "Epoch 911/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0261 - val_loss: 0.3076\n",
            "Epoch 912/2000\n",
            "45/45 [==============================] - 0s 287us/step - loss: 0.0260 - val_loss: 0.3030\n",
            "Epoch 913/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0262 - val_loss: 0.3008\n",
            "Epoch 914/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0261 - val_loss: 0.3039\n",
            "Epoch 915/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0261 - val_loss: 0.2949\n",
            "Epoch 916/2000\n",
            "45/45 [==============================] - 0s 301us/step - loss: 0.0262 - val_loss: 0.3022\n",
            "Epoch 917/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0257 - val_loss: 0.3057\n",
            "Epoch 918/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0255 - val_loss: 0.3052\n",
            "Epoch 919/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0258 - val_loss: 0.2985\n",
            "Epoch 920/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0254 - val_loss: 0.2947\n",
            "Epoch 921/2000\n",
            "45/45 [==============================] - 0s 276us/step - loss: 0.0256 - val_loss: 0.2929\n",
            "Epoch 922/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0254 - val_loss: 0.2934\n",
            "Epoch 923/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0255 - val_loss: 0.2919\n",
            "Epoch 924/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0253 - val_loss: 0.2973\n",
            "Epoch 925/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0254 - val_loss: 0.3018\n",
            "Epoch 926/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0251 - val_loss: 0.2969\n",
            "Epoch 927/2000\n",
            "45/45 [==============================] - 0s 281us/step - loss: 0.0252 - val_loss: 0.3037\n",
            "Epoch 928/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0253 - val_loss: 0.2936\n",
            "Epoch 929/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0248 - val_loss: 0.2873\n",
            "Epoch 930/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0248 - val_loss: 0.2887\n",
            "Epoch 931/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0251 - val_loss: 0.2904\n",
            "Epoch 932/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0247 - val_loss: 0.2946\n",
            "Epoch 933/2000\n",
            "45/45 [==============================] - 0s 311us/step - loss: 0.0250 - val_loss: 0.2887\n",
            "Epoch 934/2000\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0251 - val_loss: 0.2869\n",
            "Epoch 935/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0246 - val_loss: 0.2851\n",
            "Epoch 936/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0246 - val_loss: 0.2882\n",
            "Epoch 937/2000\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.0247 - val_loss: 0.2911\n",
            "Epoch 938/2000\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.0245 - val_loss: 0.2937\n",
            "Epoch 939/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0249 - val_loss: 0.2981\n",
            "Epoch 940/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0246 - val_loss: 0.2965\n",
            "Epoch 941/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0246 - val_loss: 0.2941\n",
            "Epoch 942/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0247 - val_loss: 0.2855\n",
            "Epoch 943/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0244 - val_loss: 0.2796\n",
            "Epoch 944/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0247 - val_loss: 0.2820\n",
            "Epoch 945/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0240 - val_loss: 0.2775\n",
            "Epoch 946/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0240 - val_loss: 0.2833\n",
            "Epoch 947/2000\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0240 - val_loss: 0.2828\n",
            "Epoch 948/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0240 - val_loss: 0.2850\n",
            "Epoch 949/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0242 - val_loss: 0.2813\n",
            "Epoch 950/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0242 - val_loss: 0.2769\n",
            "Epoch 951/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0240 - val_loss: 0.2758\n",
            "Epoch 952/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0240 - val_loss: 0.2834\n",
            "Epoch 953/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0240 - val_loss: 0.2766\n",
            "Epoch 954/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0237 - val_loss: 0.2758\n",
            "Epoch 955/2000\n",
            "45/45 [==============================] - 0s 378us/step - loss: 0.0238 - val_loss: 0.2742\n",
            "Epoch 956/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0234 - val_loss: 0.2745\n",
            "Epoch 957/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0236 - val_loss: 0.2690\n",
            "Epoch 958/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0235 - val_loss: 0.2746\n",
            "Epoch 959/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0234 - val_loss: 0.2790\n",
            "Epoch 960/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0234 - val_loss: 0.2836\n",
            "Epoch 961/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0234 - val_loss: 0.2819\n",
            "Epoch 962/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0235 - val_loss: 0.2891\n",
            "Epoch 963/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0233 - val_loss: 0.2853\n",
            "Epoch 964/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0233 - val_loss: 0.2809\n",
            "Epoch 965/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0233 - val_loss: 0.2807\n",
            "Epoch 966/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0233 - val_loss: 0.2695\n",
            "Epoch 967/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0233 - val_loss: 0.2618\n",
            "Epoch 968/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0233 - val_loss: 0.2713\n",
            "Epoch 969/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0228 - val_loss: 0.2748\n",
            "Epoch 970/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0230 - val_loss: 0.2708\n",
            "Epoch 971/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0227 - val_loss: 0.2715\n",
            "Epoch 972/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0232 - val_loss: 0.2780\n",
            "Epoch 973/2000\n",
            "45/45 [==============================] - 0s 385us/step - loss: 0.0227 - val_loss: 0.2759\n",
            "Epoch 974/2000\n",
            "45/45 [==============================] - 0s 398us/step - loss: 0.0232 - val_loss: 0.2765\n",
            "Epoch 975/2000\n",
            "45/45 [==============================] - 0s 283us/step - loss: 0.0229 - val_loss: 0.2769\n",
            "Epoch 976/2000\n",
            "45/45 [==============================] - 0s 300us/step - loss: 0.0226 - val_loss: 0.2776\n",
            "Epoch 977/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0234 - val_loss: 0.2682\n",
            "Epoch 978/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0225 - val_loss: 0.2741\n",
            "Epoch 979/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0226 - val_loss: 0.2696\n",
            "Epoch 980/2000\n",
            "45/45 [==============================] - 0s 319us/step - loss: 0.0224 - val_loss: 0.2701\n",
            "Epoch 981/2000\n",
            "45/45 [==============================] - 0s 303us/step - loss: 0.0224 - val_loss: 0.2762\n",
            "Epoch 982/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0224 - val_loss: 0.2780\n",
            "Epoch 983/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0223 - val_loss: 0.2713\n",
            "Epoch 984/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0223 - val_loss: 0.2772\n",
            "Epoch 985/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0225 - val_loss: 0.2716\n",
            "Epoch 986/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0227 - val_loss: 0.2694\n",
            "Epoch 987/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0225 - val_loss: 0.2711\n",
            "Epoch 988/2000\n",
            "45/45 [==============================] - 0s 300us/step - loss: 0.0220 - val_loss: 0.2661\n",
            "Epoch 989/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0223 - val_loss: 0.2621\n",
            "Epoch 990/2000\n",
            "45/45 [==============================] - 0s 333us/step - loss: 0.0221 - val_loss: 0.2665\n",
            "Epoch 991/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0224 - val_loss: 0.2614\n",
            "Epoch 992/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0219 - val_loss: 0.2642\n",
            "Epoch 993/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.0220 - val_loss: 0.2568\n",
            "Epoch 994/2000\n",
            "45/45 [==============================] - 0s 308us/step - loss: 0.0222 - val_loss: 0.2616\n",
            "Epoch 995/2000\n",
            "45/45 [==============================] - 0s 292us/step - loss: 0.0218 - val_loss: 0.2559\n",
            "Epoch 996/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0218 - val_loss: 0.2585\n",
            "Epoch 997/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0218 - val_loss: 0.2632\n",
            "Epoch 998/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0217 - val_loss: 0.2656\n",
            "Epoch 999/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0218 - val_loss: 0.2681\n",
            "Epoch 1000/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0223 - val_loss: 0.2746\n",
            "Epoch 1001/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0218 - val_loss: 0.2690\n",
            "Epoch 1002/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0215 - val_loss: 0.2568\n",
            "Epoch 1003/2000\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.0217 - val_loss: 0.2628\n",
            "Epoch 1004/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0215 - val_loss: 0.2566\n",
            "Epoch 1005/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0215 - val_loss: 0.2573\n",
            "Epoch 1006/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0217 - val_loss: 0.2521\n",
            "Epoch 1007/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0215 - val_loss: 0.2617\n",
            "Epoch 1008/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0212 - val_loss: 0.2606\n",
            "Epoch 1009/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0215 - val_loss: 0.2548\n",
            "Epoch 1010/2000\n",
            "45/45 [==============================] - 0s 298us/step - loss: 0.0212 - val_loss: 0.2514\n",
            "Epoch 1011/2000\n",
            "45/45 [==============================] - 0s 305us/step - loss: 0.0212 - val_loss: 0.2523\n",
            "Epoch 1012/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0211 - val_loss: 0.2508\n",
            "Epoch 1013/2000\n",
            "45/45 [==============================] - 0s 316us/step - loss: 0.0211 - val_loss: 0.2525\n",
            "Epoch 1014/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0214 - val_loss: 0.2508\n",
            "Epoch 1015/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0210 - val_loss: 0.2511\n",
            "Epoch 1016/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0211 - val_loss: 0.2523\n",
            "Epoch 1017/2000\n",
            "45/45 [==============================] - 0s 288us/step - loss: 0.0209 - val_loss: 0.2488\n",
            "Epoch 1018/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0214 - val_loss: 0.2552\n",
            "Epoch 1019/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0211 - val_loss: 0.2529\n",
            "Epoch 1020/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0210 - val_loss: 0.2547\n",
            "Epoch 1021/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0211 - val_loss: 0.2546\n",
            "Epoch 1022/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0210 - val_loss: 0.2536\n",
            "Epoch 1023/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0208 - val_loss: 0.2474\n",
            "Epoch 1024/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0207 - val_loss: 0.2485\n",
            "Epoch 1025/2000\n",
            "45/45 [==============================] - 0s 375us/step - loss: 0.0206 - val_loss: 0.2504\n",
            "Epoch 1026/2000\n",
            "45/45 [==============================] - 0s 292us/step - loss: 0.0208 - val_loss: 0.2546\n",
            "Epoch 1027/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0208 - val_loss: 0.2509\n",
            "Epoch 1028/2000\n",
            "45/45 [==============================] - 0s 342us/step - loss: 0.0207 - val_loss: 0.2511\n",
            "Epoch 1029/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0205 - val_loss: 0.2464\n",
            "Epoch 1030/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0207 - val_loss: 0.2372\n",
            "Epoch 1031/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0208 - val_loss: 0.2372\n",
            "Epoch 1032/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0206 - val_loss: 0.2362\n",
            "Epoch 1033/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0206 - val_loss: 0.2426\n",
            "Epoch 1034/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0205 - val_loss: 0.2446\n",
            "Epoch 1035/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0204 - val_loss: 0.2406\n",
            "Epoch 1036/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0204 - val_loss: 0.2443\n",
            "Epoch 1037/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0203 - val_loss: 0.2466\n",
            "Epoch 1038/2000\n",
            "45/45 [==============================] - 0s 325us/step - loss: 0.0202 - val_loss: 0.2469\n",
            "Epoch 1039/2000\n",
            "45/45 [==============================] - 0s 286us/step - loss: 0.0201 - val_loss: 0.2454\n",
            "Epoch 1040/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0202 - val_loss: 0.2457\n",
            "Epoch 1041/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0204 - val_loss: 0.2492\n",
            "Epoch 1042/2000\n",
            "45/45 [==============================] - 0s 282us/step - loss: 0.0202 - val_loss: 0.2438\n",
            "Epoch 1043/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0200 - val_loss: 0.2420\n",
            "Epoch 1044/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0200 - val_loss: 0.2451\n",
            "Epoch 1045/2000\n",
            "45/45 [==============================] - 0s 303us/step - loss: 0.0202 - val_loss: 0.2490\n",
            "Epoch 1046/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0203 - val_loss: 0.2488\n",
            "Epoch 1047/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0205 - val_loss: 0.2493\n",
            "Epoch 1048/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0199 - val_loss: 0.2438\n",
            "Epoch 1049/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0198 - val_loss: 0.2429\n",
            "Epoch 1050/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0199 - val_loss: 0.2445\n",
            "Epoch 1051/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0200 - val_loss: 0.2450\n",
            "Epoch 1052/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0197 - val_loss: 0.2411\n",
            "Epoch 1053/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0199 - val_loss: 0.2457\n",
            "Epoch 1054/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0196 - val_loss: 0.2463\n",
            "Epoch 1055/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0197 - val_loss: 0.2470\n",
            "Epoch 1056/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0200 - val_loss: 0.2491\n",
            "Epoch 1057/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0202 - val_loss: 0.2463\n",
            "Epoch 1058/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0199 - val_loss: 0.2443\n",
            "Epoch 1059/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0205 - val_loss: 0.2423\n",
            "Epoch 1060/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0194 - val_loss: 0.2320\n",
            "Epoch 1061/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0195 - val_loss: 0.2335\n",
            "Epoch 1062/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0193 - val_loss: 0.2358\n",
            "Epoch 1063/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0196 - val_loss: 0.2458\n",
            "Epoch 1064/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0197 - val_loss: 0.2428\n",
            "Epoch 1065/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0197 - val_loss: 0.2418\n",
            "Epoch 1066/2000\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0195 - val_loss: 0.2383\n",
            "Epoch 1067/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0192 - val_loss: 0.2385\n",
            "Epoch 1068/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0196 - val_loss: 0.2354\n",
            "Epoch 1069/2000\n",
            "45/45 [==============================] - 0s 332us/step - loss: 0.0194 - val_loss: 0.2339\n",
            "Epoch 1070/2000\n",
            "45/45 [==============================] - 0s 319us/step - loss: 0.0193 - val_loss: 0.2334\n",
            "Epoch 1071/2000\n",
            "45/45 [==============================] - 0s 320us/step - loss: 0.0193 - val_loss: 0.2396\n",
            "Epoch 1072/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0191 - val_loss: 0.2371\n",
            "Epoch 1073/2000\n",
            "45/45 [==============================] - 0s 285us/step - loss: 0.0193 - val_loss: 0.2289\n",
            "Epoch 1074/2000\n",
            "45/45 [==============================] - 0s 303us/step - loss: 0.0190 - val_loss: 0.2330\n",
            "Epoch 1075/2000\n",
            "45/45 [==============================] - 0s 323us/step - loss: 0.0190 - val_loss: 0.2362\n",
            "Epoch 1076/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0193 - val_loss: 0.2377\n",
            "Epoch 1077/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0189 - val_loss: 0.2371\n",
            "Epoch 1078/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0190 - val_loss: 0.2315\n",
            "Epoch 1079/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0191 - val_loss: 0.2341\n",
            "Epoch 1080/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0188 - val_loss: 0.2330\n",
            "Epoch 1081/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0189 - val_loss: 0.2279\n",
            "Epoch 1082/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0188 - val_loss: 0.2323\n",
            "Epoch 1083/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0188 - val_loss: 0.2340\n",
            "Epoch 1084/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0189 - val_loss: 0.2283\n",
            "Epoch 1085/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0190 - val_loss: 0.2360\n",
            "Epoch 1086/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0191 - val_loss: 0.2380\n",
            "Epoch 1087/2000\n",
            "45/45 [==============================] - 0s 327us/step - loss: 0.0188 - val_loss: 0.2359\n",
            "Epoch 1088/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0188 - val_loss: 0.2335\n",
            "Epoch 1089/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0188 - val_loss: 0.2225\n",
            "Epoch 1090/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0189 - val_loss: 0.2364\n",
            "Epoch 1091/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0188 - val_loss: 0.2307\n",
            "Epoch 1092/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0186 - val_loss: 0.2247\n",
            "Epoch 1093/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0189 - val_loss: 0.2283\n",
            "Epoch 1094/2000\n",
            "45/45 [==============================] - 0s 288us/step - loss: 0.0186 - val_loss: 0.2283\n",
            "Epoch 1095/2000\n",
            "45/45 [==============================] - 0s 371us/step - loss: 0.0186 - val_loss: 0.2260\n",
            "Epoch 1096/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0184 - val_loss: 0.2252\n",
            "Epoch 1097/2000\n",
            "45/45 [==============================] - 0s 352us/step - loss: 0.0186 - val_loss: 0.2218\n",
            "Epoch 1098/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0185 - val_loss: 0.2304\n",
            "Epoch 1099/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0188 - val_loss: 0.2334\n",
            "Epoch 1100/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0186 - val_loss: 0.2283\n",
            "Epoch 1101/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0186 - val_loss: 0.2184\n",
            "Epoch 1102/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0183 - val_loss: 0.2236\n",
            "Epoch 1103/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0182 - val_loss: 0.2206\n",
            "Epoch 1104/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0181 - val_loss: 0.2248\n",
            "Epoch 1105/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0184 - val_loss: 0.2229\n",
            "Epoch 1106/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0184 - val_loss: 0.2232\n",
            "Epoch 1107/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0181 - val_loss: 0.2263\n",
            "Epoch 1108/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0187 - val_loss: 0.2239\n",
            "Epoch 1109/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0180 - val_loss: 0.2217\n",
            "Epoch 1110/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0183 - val_loss: 0.2287\n",
            "Epoch 1111/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0180 - val_loss: 0.2209\n",
            "Epoch 1112/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0181 - val_loss: 0.2244\n",
            "Epoch 1113/2000\n",
            "45/45 [==============================] - 0s 285us/step - loss: 0.0181 - val_loss: 0.2140\n",
            "Epoch 1114/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0179 - val_loss: 0.2167\n",
            "Epoch 1115/2000\n",
            "45/45 [==============================] - 0s 323us/step - loss: 0.0178 - val_loss: 0.2174\n",
            "Epoch 1116/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0181 - val_loss: 0.2161\n",
            "Epoch 1117/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0179 - val_loss: 0.2197\n",
            "Epoch 1118/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0180 - val_loss: 0.2291\n",
            "Epoch 1119/2000\n",
            "45/45 [==============================] - 0s 280us/step - loss: 0.0181 - val_loss: 0.2285\n",
            "Epoch 1120/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0179 - val_loss: 0.2234\n",
            "Epoch 1121/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0180 - val_loss: 0.2259\n",
            "Epoch 1122/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0177 - val_loss: 0.2203\n",
            "Epoch 1123/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0178 - val_loss: 0.2224\n",
            "Epoch 1124/2000\n",
            "45/45 [==============================] - 0s 280us/step - loss: 0.0178 - val_loss: 0.2223\n",
            "Epoch 1125/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0177 - val_loss: 0.2197\n",
            "Epoch 1126/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0177 - val_loss: 0.2164\n",
            "Epoch 1127/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0179 - val_loss: 0.2104\n",
            "Epoch 1128/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0175 - val_loss: 0.2107\n",
            "Epoch 1129/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0178 - val_loss: 0.2122\n",
            "Epoch 1130/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0177 - val_loss: 0.2143\n",
            "Epoch 1131/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0178 - val_loss: 0.2201\n",
            "Epoch 1132/2000\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0176 - val_loss: 0.2196\n",
            "Epoch 1133/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0179 - val_loss: 0.2157\n",
            "Epoch 1134/2000\n",
            "45/45 [==============================] - 0s 298us/step - loss: 0.0176 - val_loss: 0.2195\n",
            "Epoch 1135/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0174 - val_loss: 0.2137\n",
            "Epoch 1136/2000\n",
            "45/45 [==============================] - 0s 300us/step - loss: 0.0177 - val_loss: 0.2122\n",
            "Epoch 1137/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0177 - val_loss: 0.2121\n",
            "Epoch 1138/2000\n",
            "45/45 [==============================] - 0s 340us/step - loss: 0.0172 - val_loss: 0.2132\n",
            "Epoch 1139/2000\n",
            "45/45 [==============================] - 0s 318us/step - loss: 0.0175 - val_loss: 0.2146\n",
            "Epoch 1140/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0178 - val_loss: 0.2089\n",
            "Epoch 1141/2000\n",
            "45/45 [==============================] - 0s 289us/step - loss: 0.0177 - val_loss: 0.2038\n",
            "Epoch 1142/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0176 - val_loss: 0.2045\n",
            "Epoch 1143/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0172 - val_loss: 0.2094\n",
            "Epoch 1144/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0172 - val_loss: 0.2124\n",
            "Epoch 1145/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0174 - val_loss: 0.2160\n",
            "Epoch 1146/2000\n",
            "45/45 [==============================] - 0s 305us/step - loss: 0.0171 - val_loss: 0.2132\n",
            "Epoch 1147/2000\n",
            "45/45 [==============================] - 0s 314us/step - loss: 0.0171 - val_loss: 0.2139\n",
            "Epoch 1148/2000\n",
            "45/45 [==============================] - 0s 298us/step - loss: 0.0171 - val_loss: 0.2123\n",
            "Epoch 1149/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0172 - val_loss: 0.2085\n",
            "Epoch 1150/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0173 - val_loss: 0.2087\n",
            "Epoch 1151/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0172 - val_loss: 0.2112\n",
            "Epoch 1152/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0171 - val_loss: 0.2096\n",
            "Epoch 1153/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0174 - val_loss: 0.2063\n",
            "Epoch 1154/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0172 - val_loss: 0.2085\n",
            "Epoch 1155/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0172 - val_loss: 0.2043\n",
            "Epoch 1156/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0171 - val_loss: 0.2051\n",
            "Epoch 1157/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0172 - val_loss: 0.2024\n",
            "Epoch 1158/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0170 - val_loss: 0.1997\n",
            "Epoch 1159/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0170 - val_loss: 0.2105\n",
            "Epoch 1160/2000\n",
            "45/45 [==============================] - 0s 289us/step - loss: 0.0170 - val_loss: 0.2068\n",
            "Epoch 1161/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0170 - val_loss: 0.2038\n",
            "Epoch 1162/2000\n",
            "45/45 [==============================] - 0s 293us/step - loss: 0.0168 - val_loss: 0.2063\n",
            "Epoch 1163/2000\n",
            "45/45 [==============================] - 0s 283us/step - loss: 0.0168 - val_loss: 0.2089\n",
            "Epoch 1164/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0170 - val_loss: 0.2088\n",
            "Epoch 1165/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0169 - val_loss: 0.2066\n",
            "Epoch 1166/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0169 - val_loss: 0.2051\n",
            "Epoch 1167/2000\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.0171 - val_loss: 0.2057\n",
            "Epoch 1168/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0167 - val_loss: 0.2072\n",
            "Epoch 1169/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0167 - val_loss: 0.2018\n",
            "Epoch 1170/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0166 - val_loss: 0.2042\n",
            "Epoch 1171/2000\n",
            "45/45 [==============================] - 0s 295us/step - loss: 0.0165 - val_loss: 0.2001\n",
            "Epoch 1172/2000\n",
            "45/45 [==============================] - 0s 319us/step - loss: 0.0170 - val_loss: 0.2091\n",
            "Epoch 1173/2000\n",
            "45/45 [==============================] - 0s 294us/step - loss: 0.0167 - val_loss: 0.2030\n",
            "Epoch 1174/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0167 - val_loss: 0.2032\n",
            "Epoch 1175/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0167 - val_loss: 0.2014\n",
            "Epoch 1176/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0166 - val_loss: 0.2003\n",
            "Epoch 1177/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0167 - val_loss: 0.2031\n",
            "Epoch 1178/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0165 - val_loss: 0.2015\n",
            "Epoch 1179/2000\n",
            "45/45 [==============================] - 0s 290us/step - loss: 0.0164 - val_loss: 0.1983\n",
            "Epoch 1180/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0168 - val_loss: 0.1970\n",
            "Epoch 1181/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0165 - val_loss: 0.1978\n",
            "Epoch 1182/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0166 - val_loss: 0.1988\n",
            "Epoch 1183/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0165 - val_loss: 0.1993\n",
            "Epoch 1184/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0166 - val_loss: 0.1999\n",
            "Epoch 1185/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0164 - val_loss: 0.2018\n",
            "Epoch 1186/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0164 - val_loss: 0.2017\n",
            "Epoch 1187/2000\n",
            "45/45 [==============================] - 0s 295us/step - loss: 0.0165 - val_loss: 0.2050\n",
            "Epoch 1188/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0163 - val_loss: 0.1990\n",
            "Epoch 1189/2000\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.0163 - val_loss: 0.1949\n",
            "Epoch 1190/2000\n",
            "45/45 [==============================] - 0s 301us/step - loss: 0.0163 - val_loss: 0.1941\n",
            "Epoch 1191/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0163 - val_loss: 0.1933\n",
            "Epoch 1192/2000\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.0164 - val_loss: 0.1956\n",
            "Epoch 1193/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0163 - val_loss: 0.1974\n",
            "Epoch 1194/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0164 - val_loss: 0.1885\n",
            "Epoch 1195/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0163 - val_loss: 0.1977\n",
            "Epoch 1196/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0161 - val_loss: 0.1938\n",
            "Epoch 1197/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0161 - val_loss: 0.1991\n",
            "Epoch 1198/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0161 - val_loss: 0.1968\n",
            "Epoch 1199/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0162 - val_loss: 0.1912\n",
            "Epoch 1200/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0161 - val_loss: 0.1903\n",
            "Epoch 1201/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0161 - val_loss: 0.1996\n",
            "Epoch 1202/2000\n",
            "45/45 [==============================] - 0s 302us/step - loss: 0.0160 - val_loss: 0.1946\n",
            "Epoch 1203/2000\n",
            "45/45 [==============================] - 0s 409us/step - loss: 0.0160 - val_loss: 0.1995\n",
            "Epoch 1204/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0160 - val_loss: 0.1948\n",
            "Epoch 1205/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0160 - val_loss: 0.1904\n",
            "Epoch 1206/2000\n",
            "45/45 [==============================] - 0s 327us/step - loss: 0.0163 - val_loss: 0.1932\n",
            "Epoch 1207/2000\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0160 - val_loss: 0.1931\n",
            "Epoch 1208/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0162 - val_loss: 0.1961\n",
            "Epoch 1209/2000\n",
            "45/45 [==============================] - 0s 335us/step - loss: 0.0160 - val_loss: 0.1958\n",
            "Epoch 1210/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0160 - val_loss: 0.1928\n",
            "Epoch 1211/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0160 - val_loss: 0.1885\n",
            "Epoch 1212/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0159 - val_loss: 0.1922\n",
            "Epoch 1213/2000\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.0158 - val_loss: 0.1888\n",
            "Epoch 1214/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0161 - val_loss: 0.1996\n",
            "Epoch 1215/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0161 - val_loss: 0.1951\n",
            "Epoch 1216/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0158 - val_loss: 0.1968\n",
            "Epoch 1217/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0157 - val_loss: 0.1917\n",
            "Epoch 1218/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0157 - val_loss: 0.1924\n",
            "Epoch 1219/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0158 - val_loss: 0.1937\n",
            "Epoch 1220/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0159 - val_loss: 0.1903\n",
            "Epoch 1221/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0159 - val_loss: 0.1933\n",
            "Epoch 1222/2000\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.0158 - val_loss: 0.1919\n",
            "Epoch 1223/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0157 - val_loss: 0.1932\n",
            "Epoch 1224/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0159 - val_loss: 0.1923\n",
            "Epoch 1225/2000\n",
            "45/45 [==============================] - 0s 302us/step - loss: 0.0159 - val_loss: 0.1954\n",
            "Epoch 1226/2000\n",
            "45/45 [==============================] - 0s 318us/step - loss: 0.0156 - val_loss: 0.1915\n",
            "Epoch 1227/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.0159 - val_loss: 0.1885\n",
            "Epoch 1228/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0157 - val_loss: 0.1890\n",
            "Epoch 1229/2000\n",
            "45/45 [==============================] - 0s 309us/step - loss: 0.0158 - val_loss: 0.1904\n",
            "Epoch 1230/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0156 - val_loss: 0.1866\n",
            "Epoch 1231/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0155 - val_loss: 0.1837\n",
            "Epoch 1232/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0156 - val_loss: 0.1797\n",
            "Epoch 1233/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0156 - val_loss: 0.1837\n",
            "Epoch 1234/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0157 - val_loss: 0.1808\n",
            "Epoch 1235/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0155 - val_loss: 0.1871\n",
            "Epoch 1236/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0156 - val_loss: 0.1864\n",
            "Epoch 1237/2000\n",
            "45/45 [==============================] - 0s 191us/step - loss: 0.0154 - val_loss: 0.1870\n",
            "Epoch 1238/2000\n",
            "45/45 [==============================] - 0s 281us/step - loss: 0.0155 - val_loss: 0.1874\n",
            "Epoch 1239/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0154 - val_loss: 0.1851\n",
            "Epoch 1240/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0155 - val_loss: 0.1863\n",
            "Epoch 1241/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0156 - val_loss: 0.1816\n",
            "Epoch 1242/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0154 - val_loss: 0.1847\n",
            "Epoch 1243/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0156 - val_loss: 0.1845\n",
            "Epoch 1244/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0155 - val_loss: 0.1811\n",
            "Epoch 1245/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0153 - val_loss: 0.1824\n",
            "Epoch 1246/2000\n",
            "45/45 [==============================] - 0s 276us/step - loss: 0.0154 - val_loss: 0.1832\n",
            "Epoch 1247/2000\n",
            "45/45 [==============================] - 0s 276us/step - loss: 0.0153 - val_loss: 0.1834\n",
            "Epoch 1248/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0154 - val_loss: 0.1911\n",
            "Epoch 1249/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0155 - val_loss: 0.1834\n",
            "Epoch 1250/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.0154 - val_loss: 0.1818\n",
            "Epoch 1251/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0153 - val_loss: 0.1834\n",
            "Epoch 1252/2000\n",
            "45/45 [==============================] - 0s 330us/step - loss: 0.0152 - val_loss: 0.1848\n",
            "Epoch 1253/2000\n",
            "45/45 [==============================] - 0s 287us/step - loss: 0.0152 - val_loss: 0.1830\n",
            "Epoch 1254/2000\n",
            "45/45 [==============================] - 0s 309us/step - loss: 0.0154 - val_loss: 0.1815\n",
            "Epoch 1255/2000\n",
            "45/45 [==============================] - 0s 322us/step - loss: 0.0153 - val_loss: 0.1801\n",
            "Epoch 1256/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0153 - val_loss: 0.1847\n",
            "Epoch 1257/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0155 - val_loss: 0.1840\n",
            "Epoch 1258/2000\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0153 - val_loss: 0.1842\n",
            "Epoch 1259/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0151 - val_loss: 0.1847\n",
            "Epoch 1260/2000\n",
            "45/45 [==============================] - 0s 307us/step - loss: 0.0152 - val_loss: 0.1845\n",
            "Epoch 1261/2000\n",
            "45/45 [==============================] - 0s 330us/step - loss: 0.0151 - val_loss: 0.1859\n",
            "Epoch 1262/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0151 - val_loss: 0.1833\n",
            "Epoch 1263/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0151 - val_loss: 0.1877\n",
            "Epoch 1264/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0151 - val_loss: 0.1863\n",
            "Epoch 1265/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0151 - val_loss: 0.1862\n",
            "Epoch 1266/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0153 - val_loss: 0.1796\n",
            "Epoch 1267/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.0151 - val_loss: 0.1813\n",
            "Epoch 1268/2000\n",
            "45/45 [==============================] - 0s 289us/step - loss: 0.0150 - val_loss: 0.1827\n",
            "Epoch 1269/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0149 - val_loss: 0.1827\n",
            "Epoch 1270/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0152 - val_loss: 0.1749\n",
            "Epoch 1271/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0150 - val_loss: 0.1802\n",
            "Epoch 1272/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0150 - val_loss: 0.1813\n",
            "Epoch 1273/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0150 - val_loss: 0.1808\n",
            "Epoch 1274/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0152 - val_loss: 0.1840\n",
            "Epoch 1275/2000\n",
            "45/45 [==============================] - 0s 278us/step - loss: 0.0154 - val_loss: 0.1868\n",
            "Epoch 1276/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0149 - val_loss: 0.1832\n",
            "Epoch 1277/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0150 - val_loss: 0.1835\n",
            "Epoch 1278/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0151 - val_loss: 0.1838\n",
            "Epoch 1279/2000\n",
            "45/45 [==============================] - 0s 296us/step - loss: 0.0149 - val_loss: 0.1763\n",
            "Epoch 1280/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0150 - val_loss: 0.1763\n",
            "Epoch 1281/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0148 - val_loss: 0.1817\n",
            "Epoch 1282/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0151 - val_loss: 0.1766\n",
            "Epoch 1283/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0148 - val_loss: 0.1789\n",
            "Epoch 1284/2000\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.0151 - val_loss: 0.1857\n",
            "Epoch 1285/2000\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0150 - val_loss: 0.1809\n",
            "Epoch 1286/2000\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.0147 - val_loss: 0.1793\n",
            "Epoch 1287/2000\n",
            "45/45 [==============================] - 0s 358us/step - loss: 0.0148 - val_loss: 0.1751\n",
            "Epoch 1288/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0148 - val_loss: 0.1756\n",
            "Epoch 1289/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0148 - val_loss: 0.1774\n",
            "Epoch 1290/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0147 - val_loss: 0.1761\n",
            "Epoch 1291/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0153 - val_loss: 0.1711\n",
            "Epoch 1292/2000\n",
            "45/45 [==============================] - 0s 372us/step - loss: 0.0148 - val_loss: 0.1715\n",
            "Epoch 1293/2000\n",
            "45/45 [==============================] - 0s 301us/step - loss: 0.0149 - val_loss: 0.1675\n",
            "Epoch 1294/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0150 - val_loss: 0.1722\n",
            "Epoch 1295/2000\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.0146 - val_loss: 0.1727\n",
            "Epoch 1296/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0147 - val_loss: 0.1708\n",
            "Epoch 1297/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0148 - val_loss: 0.1695\n",
            "Epoch 1298/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0147 - val_loss: 0.1736\n",
            "Epoch 1299/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0149 - val_loss: 0.1745\n",
            "Epoch 1300/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0146 - val_loss: 0.1706\n",
            "Epoch 1301/2000\n",
            "45/45 [==============================] - 0s 323us/step - loss: 0.0146 - val_loss: 0.1728\n",
            "Epoch 1302/2000\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0147 - val_loss: 0.1753\n",
            "Epoch 1303/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.0147 - val_loss: 0.1726\n",
            "Epoch 1304/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0147 - val_loss: 0.1756\n",
            "Epoch 1305/2000\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0147 - val_loss: 0.1721\n",
            "Epoch 1306/2000\n",
            "45/45 [==============================] - 0s 283us/step - loss: 0.0145 - val_loss: 0.1735\n",
            "Epoch 1307/2000\n",
            "45/45 [==============================] - 0s 291us/step - loss: 0.0145 - val_loss: 0.1743\n",
            "Epoch 1308/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0146 - val_loss: 0.1766\n",
            "Epoch 1309/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0146 - val_loss: 0.1715\n",
            "Epoch 1310/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0145 - val_loss: 0.1740\n",
            "Epoch 1311/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0145 - val_loss: 0.1741\n",
            "Epoch 1312/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.0144 - val_loss: 0.1751\n",
            "Epoch 1313/2000\n",
            "45/45 [==============================] - 0s 195us/step - loss: 0.0145 - val_loss: 0.1749\n",
            "Epoch 1314/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0144 - val_loss: 0.1753\n",
            "Epoch 1315/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0145 - val_loss: 0.1769\n",
            "Epoch 1316/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0144 - val_loss: 0.1745\n",
            "Epoch 1317/2000\n",
            "45/45 [==============================] - 0s 281us/step - loss: 0.0144 - val_loss: 0.1697\n",
            "Epoch 1318/2000\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0144 - val_loss: 0.1752\n",
            "Epoch 1319/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0147 - val_loss: 0.1785\n",
            "Epoch 1320/2000\n",
            "45/45 [==============================] - 0s 290us/step - loss: 0.0145 - val_loss: 0.1714\n",
            "Epoch 1321/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0145 - val_loss: 0.1674\n",
            "Epoch 1322/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0143 - val_loss: 0.1666\n",
            "Epoch 1323/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0144 - val_loss: 0.1653\n",
            "Epoch 1324/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0144 - val_loss: 0.1702\n",
            "Epoch 1325/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0144 - val_loss: 0.1703\n",
            "Epoch 1326/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0143 - val_loss: 0.1709\n",
            "Epoch 1327/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0143 - val_loss: 0.1702\n",
            "Epoch 1328/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0144 - val_loss: 0.1739\n",
            "Epoch 1329/2000\n",
            "45/45 [==============================] - 0s 324us/step - loss: 0.0145 - val_loss: 0.1741\n",
            "Epoch 1330/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0145 - val_loss: 0.1705\n",
            "Epoch 1331/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0143 - val_loss: 0.1685\n",
            "Epoch 1332/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0143 - val_loss: 0.1688\n",
            "Epoch 1333/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0143 - val_loss: 0.1678\n",
            "Epoch 1334/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0144 - val_loss: 0.1704\n",
            "Epoch 1335/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0145 - val_loss: 0.1659\n",
            "Epoch 1336/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0145 - val_loss: 0.1653\n",
            "Epoch 1337/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0144 - val_loss: 0.1659\n",
            "Epoch 1338/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0143 - val_loss: 0.1716\n",
            "Epoch 1339/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0143 - val_loss: 0.1694\n",
            "Epoch 1340/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0141 - val_loss: 0.1668\n",
            "Epoch 1341/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0141 - val_loss: 0.1633\n",
            "Epoch 1342/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0142 - val_loss: 0.1678\n",
            "Epoch 1343/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0141 - val_loss: 0.1688\n",
            "Epoch 1344/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0142 - val_loss: 0.1684\n",
            "Epoch 1345/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0143 - val_loss: 0.1636\n",
            "Epoch 1346/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0143 - val_loss: 0.1678\n",
            "Epoch 1347/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0145 - val_loss: 0.1681\n",
            "Epoch 1348/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0142 - val_loss: 0.1660\n",
            "Epoch 1349/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0141 - val_loss: 0.1664\n",
            "Epoch 1350/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0143 - val_loss: 0.1628\n",
            "Epoch 1351/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0141 - val_loss: 0.1662\n",
            "Epoch 1352/2000\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.0142 - val_loss: 0.1628\n",
            "Epoch 1353/2000\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.0142 - val_loss: 0.1598\n",
            "Epoch 1354/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0143 - val_loss: 0.1646\n",
            "Epoch 1355/2000\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.0141 - val_loss: 0.1646\n",
            "Epoch 1356/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0141 - val_loss: 0.1666\n",
            "Epoch 1357/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0140 - val_loss: 0.1682\n",
            "Epoch 1358/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0142 - val_loss: 0.1654\n",
            "Epoch 1359/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0141 - val_loss: 0.1631\n",
            "Epoch 1360/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0142 - val_loss: 0.1674\n",
            "Epoch 1361/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0141 - val_loss: 0.1631\n",
            "Epoch 1362/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0142 - val_loss: 0.1673\n",
            "Epoch 1363/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0140 - val_loss: 0.1676\n",
            "Epoch 1364/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0138 - val_loss: 0.1629\n",
            "Epoch 1365/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0141 - val_loss: 0.1646\n",
            "Epoch 1366/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0139 - val_loss: 0.1627\n",
            "Epoch 1367/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0139 - val_loss: 0.1631\n",
            "Epoch 1368/2000\n",
            "45/45 [==============================] - 0s 185us/step - loss: 0.0140 - val_loss: 0.1619\n",
            "Epoch 1369/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0139 - val_loss: 0.1639\n",
            "Epoch 1370/2000\n",
            "45/45 [==============================] - 0s 371us/step - loss: 0.0138 - val_loss: 0.1658\n",
            "Epoch 1371/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0139 - val_loss: 0.1644\n",
            "Epoch 1372/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0141 - val_loss: 0.1608\n",
            "Epoch 1373/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0139 - val_loss: 0.1586\n",
            "Epoch 1374/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0140 - val_loss: 0.1612\n",
            "Epoch 1375/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0141 - val_loss: 0.1656\n",
            "Epoch 1376/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0139 - val_loss: 0.1612\n",
            "Epoch 1377/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0140 - val_loss: 0.1590\n",
            "Epoch 1378/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0138 - val_loss: 0.1592\n",
            "Epoch 1379/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0140 - val_loss: 0.1556\n",
            "Epoch 1380/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0141 - val_loss: 0.1570\n",
            "Epoch 1381/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0139 - val_loss: 0.1584\n",
            "Epoch 1382/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0137 - val_loss: 0.1610\n",
            "Epoch 1383/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0139 - val_loss: 0.1592\n",
            "Epoch 1384/2000\n",
            "45/45 [==============================] - 0s 195us/step - loss: 0.0138 - val_loss: 0.1587\n",
            "Epoch 1385/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0142 - val_loss: 0.1562\n",
            "Epoch 1386/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0137 - val_loss: 0.1583\n",
            "Epoch 1387/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0138 - val_loss: 0.1613\n",
            "Epoch 1388/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0139 - val_loss: 0.1630\n",
            "Epoch 1389/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0139 - val_loss: 0.1640\n",
            "Epoch 1390/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0138 - val_loss: 0.1624\n",
            "Epoch 1391/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0137 - val_loss: 0.1639\n",
            "Epoch 1392/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0138 - val_loss: 0.1590\n",
            "Epoch 1393/2000\n",
            "45/45 [==============================] - 0s 307us/step - loss: 0.0136 - val_loss: 0.1589\n",
            "Epoch 1394/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0137 - val_loss: 0.1559\n",
            "Epoch 1395/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0137 - val_loss: 0.1572\n",
            "Epoch 1396/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0136 - val_loss: 0.1591\n",
            "Epoch 1397/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0141 - val_loss: 0.1599\n",
            "Epoch 1398/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0137 - val_loss: 0.1598\n",
            "Epoch 1399/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0139 - val_loss: 0.1551\n",
            "Epoch 1400/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0136 - val_loss: 0.1519\n",
            "Epoch 1401/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0135 - val_loss: 0.1534\n",
            "Epoch 1402/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0136 - val_loss: 0.1549\n",
            "Epoch 1403/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0136 - val_loss: 0.1565\n",
            "Epoch 1404/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0139 - val_loss: 0.1513\n",
            "Epoch 1405/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0136 - val_loss: 0.1541\n",
            "Epoch 1406/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0136 - val_loss: 0.1552\n",
            "Epoch 1407/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0137 - val_loss: 0.1588\n",
            "Epoch 1408/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0136 - val_loss: 0.1586\n",
            "Epoch 1409/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0136 - val_loss: 0.1598\n",
            "Epoch 1410/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0137 - val_loss: 0.1584\n",
            "Epoch 1411/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0137 - val_loss: 0.1548\n",
            "Epoch 1412/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0135 - val_loss: 0.1530\n",
            "Epoch 1413/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0135 - val_loss: 0.1552\n",
            "Epoch 1414/2000\n",
            "45/45 [==============================] - 0s 321us/step - loss: 0.0137 - val_loss: 0.1530\n",
            "Epoch 1415/2000\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.0136 - val_loss: 0.1550\n",
            "Epoch 1416/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0135 - val_loss: 0.1553\n",
            "Epoch 1417/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0135 - val_loss: 0.1555\n",
            "Epoch 1418/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0134 - val_loss: 0.1546\n",
            "Epoch 1419/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0135 - val_loss: 0.1552\n",
            "Epoch 1420/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0135 - val_loss: 0.1578\n",
            "Epoch 1421/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0134 - val_loss: 0.1548\n",
            "Epoch 1422/2000\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.0136 - val_loss: 0.1552\n",
            "Epoch 1423/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0134 - val_loss: 0.1537\n",
            "Epoch 1424/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0133 - val_loss: 0.1542\n",
            "Epoch 1425/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0134 - val_loss: 0.1590\n",
            "Epoch 1426/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0133 - val_loss: 0.1550\n",
            "Epoch 1427/2000\n",
            "45/45 [==============================] - 0s 190us/step - loss: 0.0135 - val_loss: 0.1540\n",
            "Epoch 1428/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0133 - val_loss: 0.1566\n",
            "Epoch 1429/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0134 - val_loss: 0.1544\n",
            "Epoch 1430/2000\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.0133 - val_loss: 0.1557\n",
            "Epoch 1431/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0134 - val_loss: 0.1513\n",
            "Epoch 1432/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0135 - val_loss: 0.1549\n",
            "Epoch 1433/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0134 - val_loss: 0.1550\n",
            "Epoch 1434/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0133 - val_loss: 0.1514\n",
            "Epoch 1435/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0133 - val_loss: 0.1519\n",
            "Epoch 1436/2000\n",
            "45/45 [==============================] - 0s 289us/step - loss: 0.0134 - val_loss: 0.1497\n",
            "Epoch 1437/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0135 - val_loss: 0.1535\n",
            "Epoch 1438/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0135 - val_loss: 0.1506\n",
            "Epoch 1439/2000\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0133 - val_loss: 0.1537\n",
            "Epoch 1440/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0133 - val_loss: 0.1523\n",
            "Epoch 1441/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0134 - val_loss: 0.1534\n",
            "Epoch 1442/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0133 - val_loss: 0.1483\n",
            "Epoch 1443/2000\n",
            "45/45 [==============================] - 0s 306us/step - loss: 0.0133 - val_loss: 0.1494\n",
            "Epoch 1444/2000\n",
            "45/45 [==============================] - 0s 276us/step - loss: 0.0135 - val_loss: 0.1523\n",
            "Epoch 1445/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0133 - val_loss: 0.1550\n",
            "Epoch 1446/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0133 - val_loss: 0.1530\n",
            "Epoch 1447/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0133 - val_loss: 0.1500\n",
            "Epoch 1448/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0137 - val_loss: 0.1489\n",
            "Epoch 1449/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0133 - val_loss: 0.1473\n",
            "Epoch 1450/2000\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.0133 - val_loss: 0.1482\n",
            "Epoch 1451/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0133 - val_loss: 0.1493\n",
            "Epoch 1452/2000\n",
            "45/45 [==============================] - 0s 446us/step - loss: 0.0135 - val_loss: 0.1514\n",
            "Epoch 1453/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0131 - val_loss: 0.1543\n",
            "Epoch 1454/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0131 - val_loss: 0.1533\n",
            "Epoch 1455/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0133 - val_loss: 0.1517\n",
            "Epoch 1456/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0131 - val_loss: 0.1482\n",
            "Epoch 1457/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.0132 - val_loss: 0.1454\n",
            "Epoch 1458/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0132 - val_loss: 0.1458\n",
            "Epoch 1459/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0134 - val_loss: 0.1477\n",
            "Epoch 1460/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0132 - val_loss: 0.1471\n",
            "Epoch 1461/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0133 - val_loss: 0.1492\n",
            "Epoch 1462/2000\n",
            "45/45 [==============================] - 0s 286us/step - loss: 0.0130 - val_loss: 0.1509\n",
            "Epoch 1463/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0133 - val_loss: 0.1476\n",
            "Epoch 1464/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0133 - val_loss: 0.1486\n",
            "Epoch 1465/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0133 - val_loss: 0.1472\n",
            "Epoch 1466/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0132 - val_loss: 0.1488\n",
            "Epoch 1467/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0132 - val_loss: 0.1495\n",
            "Epoch 1468/2000\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0133 - val_loss: 0.1499\n",
            "Epoch 1469/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0131 - val_loss: 0.1490\n",
            "Epoch 1470/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0132 - val_loss: 0.1547\n",
            "Epoch 1471/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0131 - val_loss: 0.1528\n",
            "Epoch 1472/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0131 - val_loss: 0.1486\n",
            "Epoch 1473/2000\n",
            "45/45 [==============================] - 0s 297us/step - loss: 0.0131 - val_loss: 0.1464\n",
            "Epoch 1474/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0132 - val_loss: 0.1431\n",
            "Epoch 1475/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0130 - val_loss: 0.1467\n",
            "Epoch 1476/2000\n",
            "45/45 [==============================] - 0s 288us/step - loss: 0.0130 - val_loss: 0.1466\n",
            "Epoch 1477/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0130 - val_loss: 0.1490\n",
            "Epoch 1478/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0130 - val_loss: 0.1472\n",
            "Epoch 1479/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0131 - val_loss: 0.1453\n",
            "Epoch 1480/2000\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0131 - val_loss: 0.1468\n",
            "Epoch 1481/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0130 - val_loss: 0.1483\n",
            "Epoch 1482/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0131 - val_loss: 0.1483\n",
            "Epoch 1483/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0129 - val_loss: 0.1477\n",
            "Epoch 1484/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0131 - val_loss: 0.1457\n",
            "Epoch 1485/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0130 - val_loss: 0.1487\n",
            "Epoch 1486/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0134 - val_loss: 0.1499\n",
            "Epoch 1487/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0129 - val_loss: 0.1464\n",
            "Epoch 1488/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0129 - val_loss: 0.1469\n",
            "Epoch 1489/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0130 - val_loss: 0.1463\n",
            "Epoch 1490/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0129 - val_loss: 0.1466\n",
            "Epoch 1491/2000\n",
            "45/45 [==============================] - 0s 195us/step - loss: 0.0131 - val_loss: 0.1494\n",
            "Epoch 1492/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0130 - val_loss: 0.1435\n",
            "Epoch 1493/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0130 - val_loss: 0.1450\n",
            "Epoch 1494/2000\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0130 - val_loss: 0.1441\n",
            "Epoch 1495/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0130 - val_loss: 0.1440\n",
            "Epoch 1496/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0130 - val_loss: 0.1482\n",
            "Epoch 1497/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.0132 - val_loss: 0.1438\n",
            "Epoch 1498/2000\n",
            "45/45 [==============================] - 0s 290us/step - loss: 0.0130 - val_loss: 0.1398\n",
            "Epoch 1499/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0130 - val_loss: 0.1406\n",
            "Epoch 1500/2000\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.0128 - val_loss: 0.1432\n",
            "Epoch 1501/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0129 - val_loss: 0.1445\n",
            "Epoch 1502/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0128 - val_loss: 0.1460\n",
            "Epoch 1503/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0129 - val_loss: 0.1468\n",
            "Epoch 1504/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0129 - val_loss: 0.1462\n",
            "Epoch 1505/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0128 - val_loss: 0.1450\n",
            "Epoch 1506/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0130 - val_loss: 0.1434\n",
            "Epoch 1507/2000\n",
            "45/45 [==============================] - 0s 280us/step - loss: 0.0129 - val_loss: 0.1456\n",
            "Epoch 1508/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0129 - val_loss: 0.1447\n",
            "Epoch 1509/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0129 - val_loss: 0.1436\n",
            "Epoch 1510/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0128 - val_loss: 0.1423\n",
            "Epoch 1511/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0132 - val_loss: 0.1399\n",
            "Epoch 1512/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0128 - val_loss: 0.1412\n",
            "Epoch 1513/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0127 - val_loss: 0.1389\n",
            "Epoch 1514/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0130 - val_loss: 0.1421\n",
            "Epoch 1515/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0127 - val_loss: 0.1419\n",
            "Epoch 1516/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0129 - val_loss: 0.1424\n",
            "Epoch 1517/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0128 - val_loss: 0.1388\n",
            "Epoch 1518/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0128 - val_loss: 0.1450\n",
            "Epoch 1519/2000\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.0130 - val_loss: 0.1412\n",
            "Epoch 1520/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0129 - val_loss: 0.1436\n",
            "Epoch 1521/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0129 - val_loss: 0.1471\n",
            "Epoch 1522/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0129 - val_loss: 0.1439\n",
            "Epoch 1523/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0131 - val_loss: 0.1405\n",
            "Epoch 1524/2000\n",
            "45/45 [==============================] - 0s 303us/step - loss: 0.0128 - val_loss: 0.1408\n",
            "Epoch 1525/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0129 - val_loss: 0.1430\n",
            "Epoch 1526/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0130 - val_loss: 0.1405\n",
            "Epoch 1527/2000\n",
            "45/45 [==============================] - 0s 185us/step - loss: 0.0126 - val_loss: 0.1406\n",
            "Epoch 1528/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0128 - val_loss: 0.1374\n",
            "Epoch 1529/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0128 - val_loss: 0.1399\n",
            "Epoch 1530/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0127 - val_loss: 0.1394\n",
            "Epoch 1531/2000\n",
            "45/45 [==============================] - 0s 174us/step - loss: 0.0126 - val_loss: 0.1389\n",
            "Epoch 1532/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0128 - val_loss: 0.1393\n",
            "Epoch 1533/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0127 - val_loss: 0.1379\n",
            "Epoch 1534/2000\n",
            "45/45 [==============================] - 0s 374us/step - loss: 0.0127 - val_loss: 0.1370\n",
            "Epoch 1535/2000\n",
            "45/45 [==============================] - 0s 291us/step - loss: 0.0129 - val_loss: 0.1395\n",
            "Epoch 1536/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0127 - val_loss: 0.1434\n",
            "Epoch 1537/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0126 - val_loss: 0.1412\n",
            "Epoch 1538/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0129 - val_loss: 0.1405\n",
            "Epoch 1539/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0126 - val_loss: 0.1412\n",
            "Epoch 1540/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0129 - val_loss: 0.1363\n",
            "Epoch 1541/2000\n",
            "45/45 [==============================] - 0s 188us/step - loss: 0.0128 - val_loss: 0.1441\n",
            "Epoch 1542/2000\n",
            "45/45 [==============================] - 0s 188us/step - loss: 0.0126 - val_loss: 0.1422\n",
            "Epoch 1543/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0127 - val_loss: 0.1416\n",
            "Epoch 1544/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0127 - val_loss: 0.1442\n",
            "Epoch 1545/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0128 - val_loss: 0.1433\n",
            "Epoch 1546/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0127 - val_loss: 0.1362\n",
            "Epoch 1547/2000\n",
            "45/45 [==============================] - 0s 187us/step - loss: 0.0126 - val_loss: 0.1366\n",
            "Epoch 1548/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0127 - val_loss: 0.1371\n",
            "Epoch 1549/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0127 - val_loss: 0.1343\n",
            "Epoch 1550/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0128 - val_loss: 0.1349\n",
            "Epoch 1551/2000\n",
            "45/45 [==============================] - 0s 188us/step - loss: 0.0126 - val_loss: 0.1360\n",
            "Epoch 1552/2000\n",
            "45/45 [==============================] - 0s 189us/step - loss: 0.0125 - val_loss: 0.1377\n",
            "Epoch 1553/2000\n",
            "45/45 [==============================] - 0s 183us/step - loss: 0.0126 - val_loss: 0.1379\n",
            "Epoch 1554/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0126 - val_loss: 0.1395\n",
            "Epoch 1555/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0126 - val_loss: 0.1366\n",
            "Epoch 1556/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0127 - val_loss: 0.1367\n",
            "Epoch 1557/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0125 - val_loss: 0.1404\n",
            "Epoch 1558/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0127 - val_loss: 0.1415\n",
            "Epoch 1559/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0125 - val_loss: 0.1399\n",
            "Epoch 1560/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0126 - val_loss: 0.1382\n",
            "Epoch 1561/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0126 - val_loss: 0.1404\n",
            "Epoch 1562/2000\n",
            "45/45 [==============================] - 0s 181us/step - loss: 0.0125 - val_loss: 0.1383\n",
            "Epoch 1563/2000\n",
            "45/45 [==============================] - 0s 189us/step - loss: 0.0127 - val_loss: 0.1400\n",
            "Epoch 1564/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0127 - val_loss: 0.1416\n",
            "Epoch 1565/2000\n",
            "45/45 [==============================] - 0s 309us/step - loss: 0.0127 - val_loss: 0.1359\n",
            "Epoch 1566/2000\n",
            "45/45 [==============================] - 0s 189us/step - loss: 0.0126 - val_loss: 0.1353\n",
            "Epoch 1567/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0126 - val_loss: 0.1352\n",
            "Epoch 1568/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0125 - val_loss: 0.1407\n",
            "Epoch 1569/2000\n",
            "45/45 [==============================] - 0s 188us/step - loss: 0.0126 - val_loss: 0.1390\n",
            "Epoch 1570/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0126 - val_loss: 0.1410\n",
            "Epoch 1571/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0125 - val_loss: 0.1353\n",
            "Epoch 1572/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0128 - val_loss: 0.1345\n",
            "Epoch 1573/2000\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0126 - val_loss: 0.1367\n",
            "Epoch 1574/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0125 - val_loss: 0.1385\n",
            "Epoch 1575/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0124 - val_loss: 0.1370\n",
            "Epoch 1576/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0126 - val_loss: 0.1344\n",
            "Epoch 1577/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0126 - val_loss: 0.1368\n",
            "Epoch 1578/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0124 - val_loss: 0.1369\n",
            "Epoch 1579/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0124 - val_loss: 0.1356\n",
            "Epoch 1580/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0125 - val_loss: 0.1343\n",
            "Epoch 1581/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0127 - val_loss: 0.1366\n",
            "Epoch 1582/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0127 - val_loss: 0.1376\n",
            "Epoch 1583/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0125 - val_loss: 0.1344\n",
            "Epoch 1584/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0124 - val_loss: 0.1368\n",
            "Epoch 1585/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0125 - val_loss: 0.1343\n",
            "Epoch 1586/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0124 - val_loss: 0.1359\n",
            "Epoch 1587/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0123 - val_loss: 0.1385\n",
            "Epoch 1588/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0124 - val_loss: 0.1377\n",
            "Epoch 1589/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0124 - val_loss: 0.1358\n",
            "Epoch 1590/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0124 - val_loss: 0.1355\n",
            "Epoch 1591/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0124 - val_loss: 0.1374\n",
            "Epoch 1592/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0124 - val_loss: 0.1366\n",
            "Epoch 1593/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0126 - val_loss: 0.1325\n",
            "Epoch 1594/2000\n",
            "45/45 [==============================] - 0s 195us/step - loss: 0.0123 - val_loss: 0.1341\n",
            "Epoch 1595/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0124 - val_loss: 0.1308\n",
            "Epoch 1596/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0124 - val_loss: 0.1281\n",
            "Epoch 1597/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0126 - val_loss: 0.1362\n",
            "Epoch 1598/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0124 - val_loss: 0.1341\n",
            "Epoch 1599/2000\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.0123 - val_loss: 0.1323\n",
            "Epoch 1600/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0123 - val_loss: 0.1357\n",
            "Epoch 1601/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0123 - val_loss: 0.1340\n",
            "Epoch 1602/2000\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.0123 - val_loss: 0.1331\n",
            "Epoch 1603/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0125 - val_loss: 0.1341\n",
            "Epoch 1604/2000\n",
            "45/45 [==============================] - 0s 195us/step - loss: 0.0125 - val_loss: 0.1330\n",
            "Epoch 1605/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0124 - val_loss: 0.1349\n",
            "Epoch 1606/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0123 - val_loss: 0.1358\n",
            "Epoch 1607/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0123 - val_loss: 0.1336\n",
            "Epoch 1608/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0124 - val_loss: 0.1339\n",
            "Epoch 1609/2000\n",
            "45/45 [==============================] - 0s 276us/step - loss: 0.0123 - val_loss: 0.1334\n",
            "Epoch 1610/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0125 - val_loss: 0.1322\n",
            "Epoch 1611/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0124 - val_loss: 0.1313\n",
            "Epoch 1612/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0122 - val_loss: 0.1328\n",
            "Epoch 1613/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0124 - val_loss: 0.1357\n",
            "Epoch 1614/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0124 - val_loss: 0.1342\n",
            "Epoch 1615/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0125 - val_loss: 0.1316\n",
            "Epoch 1616/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0124 - val_loss: 0.1311\n",
            "Epoch 1617/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0123 - val_loss: 0.1294\n",
            "Epoch 1618/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0122 - val_loss: 0.1291\n",
            "Epoch 1619/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0122 - val_loss: 0.1303\n",
            "Epoch 1620/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0122 - val_loss: 0.1319\n",
            "Epoch 1621/2000\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.0122 - val_loss: 0.1331\n",
            "Epoch 1622/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0123 - val_loss: 0.1304\n",
            "Epoch 1623/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0126 - val_loss: 0.1278\n",
            "Epoch 1624/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0123 - val_loss: 0.1289\n",
            "Epoch 1625/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0122 - val_loss: 0.1322\n",
            "Epoch 1626/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0123 - val_loss: 0.1357\n",
            "Epoch 1627/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0122 - val_loss: 0.1336\n",
            "Epoch 1628/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0123 - val_loss: 0.1337\n",
            "Epoch 1629/2000\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0123 - val_loss: 0.1321\n",
            "Epoch 1630/2000\n",
            "45/45 [==============================] - 0s 351us/step - loss: 0.0124 - val_loss: 0.1317\n",
            "Epoch 1631/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0123 - val_loss: 0.1329\n",
            "Epoch 1632/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0122 - val_loss: 0.1317\n",
            "Epoch 1633/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0123 - val_loss: 0.1329\n",
            "Epoch 1634/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0123 - val_loss: 0.1339\n",
            "Epoch 1635/2000\n",
            "45/45 [==============================] - 0s 195us/step - loss: 0.0122 - val_loss: 0.1329\n",
            "Epoch 1636/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0122 - val_loss: 0.1291\n",
            "Epoch 1637/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0123 - val_loss: 0.1291\n",
            "Epoch 1638/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0123 - val_loss: 0.1310\n",
            "Epoch 1639/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0121 - val_loss: 0.1324\n",
            "Epoch 1640/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0122 - val_loss: 0.1316\n",
            "Epoch 1641/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0122 - val_loss: 0.1298\n",
            "Epoch 1642/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0124 - val_loss: 0.1322\n",
            "Epoch 1643/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0122 - val_loss: 0.1297\n",
            "Epoch 1644/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0124 - val_loss: 0.1337\n",
            "Epoch 1645/2000\n",
            "45/45 [==============================] - 0s 293us/step - loss: 0.0124 - val_loss: 0.1287\n",
            "Epoch 1646/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0123 - val_loss: 0.1285\n",
            "Epoch 1647/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0122 - val_loss: 0.1290\n",
            "Epoch 1648/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0121 - val_loss: 0.1250\n",
            "Epoch 1649/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0124 - val_loss: 0.1233\n",
            "Epoch 1650/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0121 - val_loss: 0.1264\n",
            "Epoch 1651/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0122 - val_loss: 0.1279\n",
            "Epoch 1652/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0121 - val_loss: 0.1315\n",
            "Epoch 1653/2000\n",
            "45/45 [==============================] - 0s 344us/step - loss: 0.0121 - val_loss: 0.1314\n",
            "Epoch 1654/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0123 - val_loss: 0.1261\n",
            "Epoch 1655/2000\n",
            "45/45 [==============================] - 0s 298us/step - loss: 0.0122 - val_loss: 0.1295\n",
            "Epoch 1656/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0120 - val_loss: 0.1286\n",
            "Epoch 1657/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0121 - val_loss: 0.1294\n",
            "Epoch 1658/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0120 - val_loss: 0.1277\n",
            "Epoch 1659/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0122 - val_loss: 0.1283\n",
            "Epoch 1660/2000\n",
            "45/45 [==============================] - 0s 291us/step - loss: 0.0120 - val_loss: 0.1273\n",
            "Epoch 1661/2000\n",
            "45/45 [==============================] - 0s 185us/step - loss: 0.0121 - val_loss: 0.1288\n",
            "Epoch 1662/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0121 - val_loss: 0.1281\n",
            "Epoch 1663/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0123 - val_loss: 0.1270\n",
            "Epoch 1664/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0120 - val_loss: 0.1291\n",
            "Epoch 1665/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0122 - val_loss: 0.1307\n",
            "Epoch 1666/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0120 - val_loss: 0.1292\n",
            "Epoch 1667/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0122 - val_loss: 0.1300\n",
            "Epoch 1668/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0119 - val_loss: 0.1283\n",
            "Epoch 1669/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0120 - val_loss: 0.1291\n",
            "Epoch 1670/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0120 - val_loss: 0.1287\n",
            "Epoch 1671/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0123 - val_loss: 0.1296\n",
            "Epoch 1672/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0121 - val_loss: 0.1292\n",
            "Epoch 1673/2000\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0120 - val_loss: 0.1292\n",
            "Epoch 1674/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0120 - val_loss: 0.1304\n",
            "Epoch 1675/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0122 - val_loss: 0.1300\n",
            "Epoch 1676/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0119 - val_loss: 0.1276\n",
            "Epoch 1677/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0121 - val_loss: 0.1274\n",
            "Epoch 1678/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0121 - val_loss: 0.1305\n",
            "Epoch 1679/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0120 - val_loss: 0.1283\n",
            "Epoch 1680/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0121 - val_loss: 0.1263\n",
            "Epoch 1681/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0120 - val_loss: 0.1276\n",
            "Epoch 1682/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0121 - val_loss: 0.1283\n",
            "Epoch 1683/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0122 - val_loss: 0.1289\n",
            "Epoch 1684/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0121 - val_loss: 0.1278\n",
            "Epoch 1685/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0119 - val_loss: 0.1268\n",
            "Epoch 1686/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0120 - val_loss: 0.1309\n",
            "Epoch 1687/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0121 - val_loss: 0.1255\n",
            "Epoch 1688/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0119 - val_loss: 0.1255\n",
            "Epoch 1689/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0119 - val_loss: 0.1257\n",
            "Epoch 1690/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0120 - val_loss: 0.1263\n",
            "Epoch 1691/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0121 - val_loss: 0.1267\n",
            "Epoch 1692/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0120 - val_loss: 0.1274\n",
            "Epoch 1693/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0120 - val_loss: 0.1256\n",
            "Epoch 1694/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0120 - val_loss: 0.1240\n",
            "Epoch 1695/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0118 - val_loss: 0.1239\n",
            "Epoch 1696/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0119 - val_loss: 0.1248\n",
            "Epoch 1697/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0120 - val_loss: 0.1292\n",
            "Epoch 1698/2000\n",
            "45/45 [==============================] - 0s 332us/step - loss: 0.0120 - val_loss: 0.1274\n",
            "Epoch 1699/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0119 - val_loss: 0.1279\n",
            "Epoch 1700/2000\n",
            "45/45 [==============================] - 0s 195us/step - loss: 0.0121 - val_loss: 0.1280\n",
            "Epoch 1701/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0119 - val_loss: 0.1274\n",
            "Epoch 1702/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0119 - val_loss: 0.1252\n",
            "Epoch 1703/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0120 - val_loss: 0.1256\n",
            "Epoch 1704/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0120 - val_loss: 0.1231\n",
            "Epoch 1705/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0120 - val_loss: 0.1252\n",
            "Epoch 1706/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0120 - val_loss: 0.1234\n",
            "Epoch 1707/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0119 - val_loss: 0.1236\n",
            "Epoch 1708/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0120 - val_loss: 0.1207\n",
            "Epoch 1709/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0119 - val_loss: 0.1227\n",
            "Epoch 1710/2000\n",
            "45/45 [==============================] - 0s 353us/step - loss: 0.0120 - val_loss: 0.1280\n",
            "Epoch 1711/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0118 - val_loss: 0.1272\n",
            "Epoch 1712/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0118 - val_loss: 0.1271\n",
            "Epoch 1713/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0118 - val_loss: 0.1283\n",
            "Epoch 1714/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0121 - val_loss: 0.1270\n",
            "Epoch 1715/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0119 - val_loss: 0.1243\n",
            "Epoch 1716/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0119 - val_loss: 0.1248\n",
            "Epoch 1717/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0118 - val_loss: 0.1242\n",
            "Epoch 1718/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0118 - val_loss: 0.1276\n",
            "Epoch 1719/2000\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0119 - val_loss: 0.1244\n",
            "Epoch 1720/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0118 - val_loss: 0.1247\n",
            "Epoch 1721/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0118 - val_loss: 0.1262\n",
            "Epoch 1722/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0119 - val_loss: 0.1229\n",
            "Epoch 1723/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0118 - val_loss: 0.1247\n",
            "Epoch 1724/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0119 - val_loss: 0.1275\n",
            "Epoch 1725/2000\n",
            "45/45 [==============================] - 0s 288us/step - loss: 0.0121 - val_loss: 0.1262\n",
            "Epoch 1726/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0118 - val_loss: 0.1228\n",
            "Epoch 1727/2000\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0119 - val_loss: 0.1218\n",
            "Epoch 1728/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0118 - val_loss: 0.1220\n",
            "Epoch 1729/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0118 - val_loss: 0.1253\n",
            "Epoch 1730/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0120 - val_loss: 0.1282\n",
            "Epoch 1731/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0118 - val_loss: 0.1254\n",
            "Epoch 1732/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0118 - val_loss: 0.1248\n",
            "Epoch 1733/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0117 - val_loss: 0.1241\n",
            "Epoch 1734/2000\n",
            "45/45 [==============================] - 0s 287us/step - loss: 0.0118 - val_loss: 0.1235\n",
            "Epoch 1735/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0119 - val_loss: 0.1228\n",
            "Epoch 1736/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0118 - val_loss: 0.1235\n",
            "Epoch 1737/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0117 - val_loss: 0.1231\n",
            "Epoch 1738/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0118 - val_loss: 0.1242\n",
            "Epoch 1739/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0117 - val_loss: 0.1239\n",
            "Epoch 1740/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0118 - val_loss: 0.1227\n",
            "Epoch 1741/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0121 - val_loss: 0.1202\n",
            "Epoch 1742/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0117 - val_loss: 0.1222\n",
            "Epoch 1743/2000\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0118 - val_loss: 0.1202\n",
            "Epoch 1744/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0118 - val_loss: 0.1216\n",
            "Epoch 1745/2000\n",
            "45/45 [==============================] - 0s 338us/step - loss: 0.0117 - val_loss: 0.1233\n",
            "Epoch 1746/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0118 - val_loss: 0.1276\n",
            "Epoch 1747/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0120 - val_loss: 0.1272\n",
            "Epoch 1748/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0119 - val_loss: 0.1218\n",
            "Epoch 1749/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0118 - val_loss: 0.1180\n",
            "Epoch 1750/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0118 - val_loss: 0.1223\n",
            "Epoch 1751/2000\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.0118 - val_loss: 0.1222\n",
            "Epoch 1752/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0117 - val_loss: 0.1206\n",
            "Epoch 1753/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0117 - val_loss: 0.1202\n",
            "Epoch 1754/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0117 - val_loss: 0.1222\n",
            "Epoch 1755/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0118 - val_loss: 0.1214\n",
            "Epoch 1756/2000\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.0116 - val_loss: 0.1228\n",
            "Epoch 1757/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0116 - val_loss: 0.1210\n",
            "Epoch 1758/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0117 - val_loss: 0.1235\n",
            "Epoch 1759/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0119 - val_loss: 0.1234\n",
            "Epoch 1760/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0116 - val_loss: 0.1227\n",
            "Epoch 1761/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0116 - val_loss: 0.1212\n",
            "Epoch 1762/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0118 - val_loss: 0.1219\n",
            "Epoch 1763/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0117 - val_loss: 0.1204\n",
            "Epoch 1764/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0116 - val_loss: 0.1204\n",
            "Epoch 1765/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0117 - val_loss: 0.1180\n",
            "Epoch 1766/2000\n",
            "45/45 [==============================] - 0s 376us/step - loss: 0.0118 - val_loss: 0.1165\n",
            "Epoch 1767/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0119 - val_loss: 0.1185\n",
            "Epoch 1768/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0118 - val_loss: 0.1207\n",
            "Epoch 1769/2000\n",
            "45/45 [==============================] - 0s 313us/step - loss: 0.0116 - val_loss: 0.1252\n",
            "Epoch 1770/2000\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0117 - val_loss: 0.1229\n",
            "Epoch 1771/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0118 - val_loss: 0.1254\n",
            "Epoch 1772/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0117 - val_loss: 0.1218\n",
            "Epoch 1773/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0116 - val_loss: 0.1217\n",
            "Epoch 1774/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0116 - val_loss: 0.1214\n",
            "Epoch 1775/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0116 - val_loss: 0.1223\n",
            "Epoch 1776/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0116 - val_loss: 0.1203\n",
            "Epoch 1777/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0117 - val_loss: 0.1204\n",
            "Epoch 1778/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0116 - val_loss: 0.1211\n",
            "Epoch 1779/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0119 - val_loss: 0.1235\n",
            "Epoch 1780/2000\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0116 - val_loss: 0.1220\n",
            "Epoch 1781/2000\n",
            "45/45 [==============================] - 0s 189us/step - loss: 0.0117 - val_loss: 0.1168\n",
            "Epoch 1782/2000\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.0116 - val_loss: 0.1160\n",
            "Epoch 1783/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0115 - val_loss: 0.1191\n",
            "Epoch 1784/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0117 - val_loss: 0.1185\n",
            "Epoch 1785/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0117 - val_loss: 0.1181\n",
            "Epoch 1786/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0118 - val_loss: 0.1162\n",
            "Epoch 1787/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0117 - val_loss: 0.1176\n",
            "Epoch 1788/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0115 - val_loss: 0.1200\n",
            "Epoch 1789/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0118 - val_loss: 0.1193\n",
            "Epoch 1790/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0115 - val_loss: 0.1222\n",
            "Epoch 1791/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0115 - val_loss: 0.1220\n",
            "Epoch 1792/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0116 - val_loss: 0.1211\n",
            "Epoch 1793/2000\n",
            "45/45 [==============================] - 0s 181us/step - loss: 0.0117 - val_loss: 0.1239\n",
            "Epoch 1794/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.0116 - val_loss: 0.1199\n",
            "Epoch 1795/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0115 - val_loss: 0.1199\n",
            "Epoch 1796/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0116 - val_loss: 0.1222\n",
            "Epoch 1797/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0116 - val_loss: 0.1246\n",
            "Epoch 1798/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0116 - val_loss: 0.1212\n",
            "Epoch 1799/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0115 - val_loss: 0.1186\n",
            "Epoch 1800/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0116 - val_loss: 0.1203\n",
            "Epoch 1801/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0115 - val_loss: 0.1217\n",
            "Epoch 1802/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0118 - val_loss: 0.1166\n",
            "Epoch 1803/2000\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0116 - val_loss: 0.1184\n",
            "Epoch 1804/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0116 - val_loss: 0.1163\n",
            "Epoch 1805/2000\n",
            "45/45 [==============================] - 0s 190us/step - loss: 0.0117 - val_loss: 0.1187\n",
            "Epoch 1806/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0117 - val_loss: 0.1236\n",
            "Epoch 1807/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0115 - val_loss: 0.1213\n",
            "Epoch 1808/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0116 - val_loss: 0.1174\n",
            "Epoch 1809/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0117 - val_loss: 0.1154\n",
            "Epoch 1810/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0116 - val_loss: 0.1155\n",
            "Epoch 1811/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0116 - val_loss: 0.1169\n",
            "Epoch 1812/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0116 - val_loss: 0.1188\n",
            "Epoch 1813/2000\n",
            "45/45 [==============================] - 0s 298us/step - loss: 0.0115 - val_loss: 0.1204\n",
            "Epoch 1814/2000\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0114 - val_loss: 0.1217\n",
            "Epoch 1815/2000\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0115 - val_loss: 0.1206\n",
            "Epoch 1816/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0114 - val_loss: 0.1172\n",
            "Epoch 1817/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0115 - val_loss: 0.1210\n",
            "Epoch 1818/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0114 - val_loss: 0.1189\n",
            "Epoch 1819/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0114 - val_loss: 0.1207\n",
            "Epoch 1820/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0116 - val_loss: 0.1206\n",
            "Epoch 1821/2000\n",
            "45/45 [==============================] - 0s 293us/step - loss: 0.0115 - val_loss: 0.1209\n",
            "Epoch 1822/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0116 - val_loss: 0.1180\n",
            "Epoch 1823/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0114 - val_loss: 0.1173\n",
            "Epoch 1824/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0116 - val_loss: 0.1173\n",
            "Epoch 1825/2000\n",
            "45/45 [==============================] - 0s 330us/step - loss: 0.0116 - val_loss: 0.1172\n",
            "Epoch 1826/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0114 - val_loss: 0.1150\n",
            "Epoch 1827/2000\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0115 - val_loss: 0.1188\n",
            "Epoch 1828/2000\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0114 - val_loss: 0.1167\n",
            "Epoch 1829/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0114 - val_loss: 0.1184\n",
            "Epoch 1830/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0116 - val_loss: 0.1175\n",
            "Epoch 1831/2000\n",
            "45/45 [==============================] - 0s 341us/step - loss: 0.0116 - val_loss: 0.1150\n",
            "Epoch 1832/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0115 - val_loss: 0.1186\n",
            "Epoch 1833/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0114 - val_loss: 0.1176\n",
            "Epoch 1834/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0115 - val_loss: 0.1165\n",
            "Epoch 1835/2000\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.0114 - val_loss: 0.1166\n",
            "Epoch 1836/2000\n",
            "45/45 [==============================] - 0s 186us/step - loss: 0.0114 - val_loss: 0.1190\n",
            "Epoch 1837/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0114 - val_loss: 0.1171\n",
            "Epoch 1838/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0114 - val_loss: 0.1158\n",
            "Epoch 1839/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0113 - val_loss: 0.1159\n",
            "Epoch 1840/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0114 - val_loss: 0.1179\n",
            "Epoch 1841/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0114 - val_loss: 0.1135\n",
            "Epoch 1842/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0114 - val_loss: 0.1168\n",
            "Epoch 1843/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0114 - val_loss: 0.1186\n",
            "Epoch 1844/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0114 - val_loss: 0.1171\n",
            "Epoch 1845/2000\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0114 - val_loss: 0.1155\n",
            "Epoch 1846/2000\n",
            "45/45 [==============================] - 0s 187us/step - loss: 0.0117 - val_loss: 0.1177\n",
            "Epoch 1847/2000\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.0114 - val_loss: 0.1175\n",
            "Epoch 1848/2000\n",
            "45/45 [==============================] - 0s 195us/step - loss: 0.0116 - val_loss: 0.1177\n",
            "Epoch 1849/2000\n",
            "45/45 [==============================] - 0s 292us/step - loss: 0.0114 - val_loss: 0.1158\n",
            "Epoch 1850/2000\n",
            "45/45 [==============================] - 0s 310us/step - loss: 0.0115 - val_loss: 0.1161\n",
            "Epoch 1851/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0114 - val_loss: 0.1170\n",
            "Epoch 1852/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0114 - val_loss: 0.1184\n",
            "Epoch 1853/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0115 - val_loss: 0.1129\n",
            "Epoch 1854/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0114 - val_loss: 0.1139\n",
            "Epoch 1855/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0114 - val_loss: 0.1142\n",
            "Epoch 1856/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0115 - val_loss: 0.1132\n",
            "Epoch 1857/2000\n",
            "45/45 [==============================] - 0s 387us/step - loss: 0.0113 - val_loss: 0.1160\n",
            "Epoch 1858/2000\n",
            "45/45 [==============================] - 0s 329us/step - loss: 0.0114 - val_loss: 0.1159\n",
            "Epoch 1859/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0117 - val_loss: 0.1139\n",
            "Epoch 1860/2000\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0114 - val_loss: 0.1129\n",
            "Epoch 1861/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0114 - val_loss: 0.1122\n",
            "Epoch 1862/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0113 - val_loss: 0.1135\n",
            "Epoch 1863/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0116 - val_loss: 0.1189\n",
            "Epoch 1864/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0113 - val_loss: 0.1167\n",
            "Epoch 1865/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0114 - val_loss: 0.1192\n",
            "Epoch 1866/2000\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0113 - val_loss: 0.1168\n",
            "Epoch 1867/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0114 - val_loss: 0.1179\n",
            "Epoch 1868/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0113 - val_loss: 0.1193\n",
            "Epoch 1869/2000\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0114 - val_loss: 0.1184\n",
            "Epoch 1870/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0113 - val_loss: 0.1147\n",
            "Epoch 1871/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0113 - val_loss: 0.1166\n",
            "Epoch 1872/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0113 - val_loss: 0.1128\n",
            "Epoch 1873/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0113 - val_loss: 0.1162\n",
            "Epoch 1874/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0113 - val_loss: 0.1141\n",
            "Epoch 1875/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0112 - val_loss: 0.1165\n",
            "Epoch 1876/2000\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0112 - val_loss: 0.1172\n",
            "Epoch 1877/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0114 - val_loss: 0.1167\n",
            "Epoch 1878/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0113 - val_loss: 0.1140\n",
            "Epoch 1879/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0113 - val_loss: 0.1179\n",
            "Epoch 1880/2000\n",
            "45/45 [==============================] - 0s 290us/step - loss: 0.0113 - val_loss: 0.1209\n",
            "Epoch 1881/2000\n",
            "45/45 [==============================] - 0s 305us/step - loss: 0.0113 - val_loss: 0.1180\n",
            "Epoch 1882/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0112 - val_loss: 0.1140\n",
            "Epoch 1883/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0112 - val_loss: 0.1140\n",
            "Epoch 1884/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0112 - val_loss: 0.1158\n",
            "Epoch 1885/2000\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0113 - val_loss: 0.1137\n",
            "Epoch 1886/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0113 - val_loss: 0.1148\n",
            "Epoch 1887/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0112 - val_loss: 0.1157\n",
            "Epoch 1888/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0113 - val_loss: 0.1148\n",
            "Epoch 1889/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0113 - val_loss: 0.1155\n",
            "Epoch 1890/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0112 - val_loss: 0.1132\n",
            "Epoch 1891/2000\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0113 - val_loss: 0.1119\n",
            "Epoch 1892/2000\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0113 - val_loss: 0.1143\n",
            "Epoch 1893/2000\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0112 - val_loss: 0.1158\n",
            "Epoch 1894/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0112 - val_loss: 0.1188\n",
            "Epoch 1895/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0113 - val_loss: 0.1203\n",
            "Epoch 1896/2000\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0113 - val_loss: 0.1148\n",
            "Epoch 1897/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0112 - val_loss: 0.1132\n",
            "Epoch 1898/2000\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0113 - val_loss: 0.1128\n",
            "Epoch 1899/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0112 - val_loss: 0.1137\n",
            "Epoch 1900/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0115 - val_loss: 0.1145\n",
            "Epoch 1901/2000\n",
            "45/45 [==============================] - 0s 293us/step - loss: 0.0113 - val_loss: 0.1152\n",
            "Epoch 1902/2000\n",
            "45/45 [==============================] - 0s 297us/step - loss: 0.0114 - val_loss: 0.1161\n",
            "Epoch 1903/2000\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0112 - val_loss: 0.1133\n",
            "Epoch 1904/2000\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0112 - val_loss: 0.1144\n",
            "Epoch 1905/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0113 - val_loss: 0.1158\n",
            "Epoch 1906/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0111 - val_loss: 0.1142\n",
            "Epoch 1907/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0112 - val_loss: 0.1160\n",
            "Epoch 1908/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0111 - val_loss: 0.1164\n",
            "Epoch 1909/2000\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.0111 - val_loss: 0.1137\n",
            "Epoch 1910/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0112 - val_loss: 0.1171\n",
            "Epoch 1911/2000\n",
            "45/45 [==============================] - 0s 368us/step - loss: 0.0114 - val_loss: 0.1143\n",
            "Epoch 1912/2000\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0111 - val_loss: 0.1168\n",
            "Epoch 1913/2000\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0115 - val_loss: 0.1181\n",
            "Epoch 1914/2000\n",
            "45/45 [==============================] - 0s 338us/step - loss: 0.0112 - val_loss: 0.1151\n",
            "Epoch 1915/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0112 - val_loss: 0.1152\n",
            "Epoch 1916/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0111 - val_loss: 0.1142\n",
            "Epoch 1917/2000\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0112 - val_loss: 0.1135\n",
            "Epoch 1918/2000\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0112 - val_loss: 0.1106\n",
            "Epoch 1919/2000\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0111 - val_loss: 0.1122\n",
            "Epoch 1920/2000\n",
            "45/45 [==============================] - 0s 282us/step - loss: 0.0111 - val_loss: 0.1111\n",
            "Epoch 1921/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0112 - val_loss: 0.1130\n",
            "Epoch 1922/2000\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0112 - val_loss: 0.1149\n",
            "Epoch 1923/2000\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0112 - val_loss: 0.1158\n",
            "Epoch 1924/2000\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0112 - val_loss: 0.1114\n",
            "Epoch 1925/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0114 - val_loss: 0.1084\n",
            "Epoch 1926/2000\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0114 - val_loss: 0.1098\n",
            "Epoch 1927/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0113 - val_loss: 0.1126\n",
            "Epoch 1928/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0114 - val_loss: 0.1175\n",
            "Epoch 1929/2000\n",
            "45/45 [==============================] - 0s 282us/step - loss: 0.0111 - val_loss: 0.1178\n",
            "Epoch 1930/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0111 - val_loss: 0.1171\n",
            "Epoch 1931/2000\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0111 - val_loss: 0.1125\n",
            "Epoch 1932/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0111 - val_loss: 0.1090\n",
            "Epoch 1933/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0113 - val_loss: 0.1092\n",
            "Epoch 1934/2000\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0112 - val_loss: 0.1097\n",
            "Epoch 1935/2000\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0112 - val_loss: 0.1119\n",
            "Epoch 1936/2000\n",
            "45/45 [==============================] - 0s 343us/step - loss: 0.0111 - val_loss: 0.1147\n",
            "Epoch 1937/2000\n",
            "45/45 [==============================] - 0s 341us/step - loss: 0.0111 - val_loss: 0.1125\n",
            "Epoch 1938/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0110 - val_loss: 0.1152\n",
            "Epoch 1939/2000\n",
            "45/45 [==============================] - 0s 279us/step - loss: 0.0112 - val_loss: 0.1126\n",
            "Epoch 1940/2000\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0110 - val_loss: 0.1139\n",
            "Epoch 1941/2000\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0111 - val_loss: 0.1085\n",
            "Epoch 1942/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0112 - val_loss: 0.1110\n",
            "Epoch 1943/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0111 - val_loss: 0.1172\n",
            "Epoch 1944/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0111 - val_loss: 0.1139\n",
            "Epoch 1945/2000\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0110 - val_loss: 0.1135\n",
            "Epoch 1946/2000\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0110 - val_loss: 0.1116\n",
            "Epoch 1947/2000\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0112 - val_loss: 0.1129\n",
            "Epoch 1948/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0110 - val_loss: 0.1112\n",
            "Epoch 1949/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0112 - val_loss: 0.1086\n",
            "Epoch 1950/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0112 - val_loss: 0.1132\n",
            "Epoch 1951/2000\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.0110 - val_loss: 0.1140\n",
            "Epoch 1952/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0111 - val_loss: 0.1100\n",
            "Epoch 1953/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0110 - val_loss: 0.1128\n",
            "Epoch 1954/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0113 - val_loss: 0.1107\n",
            "Epoch 1955/2000\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0112 - val_loss: 0.1109\n",
            "Epoch 1956/2000\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.0111 - val_loss: 0.1124\n",
            "Epoch 1957/2000\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0112 - val_loss: 0.1108\n",
            "Epoch 1958/2000\n",
            "45/45 [==============================] - 0s 307us/step - loss: 0.0111 - val_loss: 0.1095\n",
            "Epoch 1959/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0111 - val_loss: 0.1112\n",
            "Epoch 1960/2000\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0110 - val_loss: 0.1127\n",
            "Epoch 1961/2000\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0110 - val_loss: 0.1133\n",
            "Epoch 1962/2000\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.0110 - val_loss: 0.1091\n",
            "Epoch 1963/2000\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0110 - val_loss: 0.1130\n",
            "Epoch 1964/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0109 - val_loss: 0.1142\n",
            "Epoch 1965/2000\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0113 - val_loss: 0.1129\n",
            "Epoch 1966/2000\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0110 - val_loss: 0.1111\n",
            "Epoch 1967/2000\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.0111 - val_loss: 0.1110\n",
            "Epoch 1968/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0110 - val_loss: 0.1169\n",
            "Epoch 1969/2000\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0110 - val_loss: 0.1128\n",
            "Epoch 1970/2000\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0110 - val_loss: 0.1135\n",
            "Epoch 1971/2000\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0109 - val_loss: 0.1128\n",
            "Epoch 1972/2000\n",
            "45/45 [==============================] - 0s 333us/step - loss: 0.0112 - val_loss: 0.1130\n",
            "Epoch 1973/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0109 - val_loss: 0.1128\n",
            "Epoch 1974/2000\n",
            "45/45 [==============================] - 0s 348us/step - loss: 0.0111 - val_loss: 0.1117\n",
            "Epoch 1975/2000\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0111 - val_loss: 0.1141\n",
            "Epoch 1976/2000\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0110 - val_loss: 0.1137\n",
            "Epoch 1977/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0113 - val_loss: 0.1157\n",
            "Epoch 1978/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0109 - val_loss: 0.1120\n",
            "Epoch 1979/2000\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0111 - val_loss: 0.1126\n",
            "Epoch 1980/2000\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0110 - val_loss: 0.1112\n",
            "Epoch 1981/2000\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0111 - val_loss: 0.1124\n",
            "Epoch 1982/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0111 - val_loss: 0.1105\n",
            "Epoch 1983/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0109 - val_loss: 0.1091\n",
            "Epoch 1984/2000\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0109 - val_loss: 0.1079\n",
            "Epoch 1985/2000\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0112 - val_loss: 0.1100\n",
            "Epoch 1986/2000\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.0112 - val_loss: 0.1113\n",
            "Epoch 1987/2000\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0111 - val_loss: 0.1103\n",
            "Epoch 1988/2000\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0110 - val_loss: 0.1104\n",
            "Epoch 1989/2000\n",
            "45/45 [==============================] - 0s 287us/step - loss: 0.0109 - val_loss: 0.1108\n",
            "Epoch 1990/2000\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0109 - val_loss: 0.1103\n",
            "Epoch 1991/2000\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.0110 - val_loss: 0.1095\n",
            "Epoch 1992/2000\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0110 - val_loss: 0.1077\n",
            "Epoch 1993/2000\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0109 - val_loss: 0.1099\n",
            "Epoch 1994/2000\n",
            "45/45 [==============================] - 0s 285us/step - loss: 0.0109 - val_loss: 0.1101\n",
            "Epoch 1995/2000\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0109 - val_loss: 0.1129\n",
            "Epoch 1996/2000\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.0111 - val_loss: 0.1162\n",
            "Epoch 1997/2000\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0110 - val_loss: 0.1102\n",
            "Epoch 1998/2000\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0111 - val_loss: 0.1109\n",
            "Epoch 1999/2000\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0110 - val_loss: 0.1081\n",
            "Epoch 2000/2000\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0108 - val_loss: 0.1102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b8dSg8IiVNg",
        "colab_type": "text"
      },
      "source": [
        "## 学習の推移\n",
        "\n",
        "学習を表示する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kU7bWWDhzJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8fb40b0e-30e9-48bd-c8bc-0095ffb152c1"
      },
      "source": [
        "loss = history.history['loss'] # 訓練用データの誤差\n",
        "vloss = history.history['val_loss'] # 検証用データの誤差\n",
        "\n",
        "plt.plot(np.arange(len(loss)), loss)\n",
        "plt.plot(np.arange(len(vloss)), vloss)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqmSSZXXjDTL",
        "colab_type": "text"
      },
      "source": [
        "### モデルの使用\n",
        "\n",
        "predict()メソッドによる予測を行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdyTGTCOiuqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "99d99479-fb32-4cec-babc-801be8a0e5a9"
      },
      "source": [
        "plt.plot(x, model.predict(x))\n",
        "plt.plot(x, t)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3yNd/vA8c+VLYgZRJDEau0V1B5V\no1pUB510qefX6tL1dD8dT8fT51HdVKmWFtUqLa2i9g6NPRIiCCKCSELm+f7+uA9NNUbkJHdOzvV+\nvc4r5/7e6zrGufK9v0uMMSillPJcXnYHoJRSyl6aCJRSysNpIlBKKQ+niUAppTycJgKllPJwPnYH\ncCWqVq1qwsPD7Q5DKaXcyoYNG44ZY4LPL3fLRBAeHk5UVJTdYSillFsRkfj8yvXRkFJKeThNBEop\n5eE0ESillIfTRKCUUh5OE4FSSnk4lyQCEZkoIkdFZOsF9ouIfCAisSKyWURa59k3TERinK9hrohH\nKaXU5XNVjeBLoO9F9vcDGjhfI4BPAUSkMvAK0B5oB7wiIpVcFJNSSqnL4JJxBMaYZSISfpFDBgJf\nGWvO6zUiUlFEQoDuwAJjzHEAEVmAlVC+dUVcSqkS5MwJSDsKZ05CRgpknPzzfdmqENICqjUG3wC7\nI/U4xTWgLBQ4kGf7oLPsQuV/IyIjsGoT1KlTp2iiVEq51skDsGMObJ8DB9YCl1j/xMsHghtZSSGk\nBUR0hWpXF0uonsxtRhYbY8YD4wEiIyN1NR2lSqrkPX9++R/aaJVVbwbdn4Mq9SGgIpSpaP0MqAAB\nQXDqEBze9Odr9y8QPcU6t9610HEU1O0OInZ9qlKtuBJBAlA7z3YtZ1kC1uOhvOVLiikmpZQrpRyE\nBa/A1pnWds3W0OtVaDQAqtS7+LmVI6xXk0HWtjFwKgE2T4e14+DrQVYy6TgKmg4Gb9+i/CQeR1y1\nVKWzjeBnY0zTfPb1Bx4BrsdqGP7AGNPO2Vi8ATjbi2gj0OZsm8GFREZGGp1rSKkSIvsMrPoQVowB\n44AOj0CbYVDRRY9wczJh8wzrHsd2QVCodY92I8DbbR5qlAgissEYE3l+uUv+FEXkW6zf7KuKyEGs\nnkC+AMaYz4B5WEkgFjgN3Ovcd1xEXgfWOy/12qWSgFKqhDAGts+G316ClP3QeBCZPV4lgWB8HV74\np2YQ4OtNgI83vt6CXOljHR9/aH03tLwTYhfCqg9g/j9h2ywYPA4q13Xt5/JALqsRFCetEShlr6zE\n3WTOGkX5I2tILFOfL4NGMje1PgdOnCa/rxQvgTK+3kQEl6VpzQo0Ca1A05pBNAoJIsDXu+ABbJkJ\nPz8JJhf6vWMlCW0/uKQL1Qg0ESilLltMYirrF87gxpgXyTFe/DfnVr6XXoRVDaJetXLUDy5HWJVA\nch2GjBwHmdm5ZGTnkpnjIC0zh5jENLYeSuHk6WwAvL2E+sHluKZuZfo1C6FteGW8vS7zC/3kAfjx\nH7BvudUOceNYCKxchJ/e/WkiUEpdkfTMHOZuOcz0dftpmfANz/tM5ZB/XfZcO56I+o2oVSnw8r+8\nAWMMCSfPsDXhFNsOpbD5YApr9iaTmeOgajk/ejepQb+mNbimbhV8vS8x5tWRC6s/gkWvW2MRBn0C\n9XoW8hOXXpoIlFIFciYrl/cX7mbq2v1kZZ5hbLmv6JeziMwG/fG/ZTz4l3PZvdIzc1i86yi/bD3C\n4p1HOZ2VS8VAX/o1DWFYxzCurhF08Qsc3gzfP2A1Jvd5Czr8n8tiK000ESilLtvqPck898Nm4pNP\nc3ezQJ5NeYNyR6Og27PQ7TnwKrr5KjOyc1m2O4l5Ww7zy9YjZOY46FC3CsM7hdOrUfUL1z6yz8AP\nD8KOn6D789DtGW03OI8mAqXUJaVl5vD2LzuYsmY/YVUC+bCnL82XjYT0Y9Zjl6aDizWeE+lZTI86\nwNer40k4eYZalcpwT4cwhkTWoUJgPmMJcnNgzijY9I3VxbT3G5oM8tBEoJS6qKW7k3j+hy0cSjnD\n/Z0ieKplLgFTbgDfQLj9G6jZyrbYcnIdLNyRyKSV+1gbd5xAP2+GdwxnRNe6VAz0++vBDgf8+hys\nGweth8ENY8DrCnomlUKaCJRS+crOdfDy7K18u+4A9YLL8u4tLWhT7jhM7Gt9gd73K1QKtzvMc7Yf\nOsWnS/fw8+ZDlPXz4b7OEdzfOYIKZfLUEIyB39+A5e9Bk8EweLyORkYTgVIqHxnZuTzyzUYW7jjK\nQ93q8kSvhgSkH4JJ/SD7NNz7CwRfZXeY+dp1JJUxC3bz67YjBAX4MKJrXYZ3iqCcf55xsiveh4Wv\nQMO+cOuX4FvGtnhLAk0ESqm/OJ2Vw0Nfb2B5zDFeH9iEuzuEW9NET+xrtQkM/8maAbSE25qQwvsL\nd7Nwx1EqBfryeK+G3Nm+Dj5nu56u/wLmjoar+8NtXxdpQ3dJd6FE4Ll/Ikp5sFMZ2QybuI6Vscd4\n79YWVhI4fRy+GgSph+HO79wiCQA0Da3AhGFt+fHhTlxdI4hX5myj39jlLNudZB3Q9n7o+xbs/BkW\nvmxvsCWUJgKlPMyJ9CzumrCWP/af5MPbW3NLm1qQmQpTb4XkGBj6DdRpb3eYBdaydkW+ebA94+5u\nQ1aug3smruP+L9ezNykN2o+Etg9aE9dFTbQ71BJHp+5TyoMcTc3g7gnriEtOZ9zdbbi2UXXIzYZp\nd8KhP2DI11Cvh91hXjERoU+TGnS/KphJK/fx0e+x9B6zjGEdw3ms5+sEndgHc5+yZkat38vucEsM\nrREo5SGS0zIZOm4N+4+fZtLwtlYSAFjwMsQthYEfWc/RSwF/H29GdqvH4qe6c0ubWkxcGce1Y1Yy\n7+q3MNWuhhnDIXG73WGWGJoIlPIAObkOHp32BwdPnuGr+9vRqX5Va8eWmbDmE+vRScs77A2yCASX\n9+ftm5sz5+HO1AgK4P9m7uZx7xfI8Q2Eb26D1ES7QywRNBEo5QH+u2A3K2OTeWNgU9qGO2foTNxm\njcKt09EagVuKNatVgR8f7sSrNzZmUYIPt6U8RnZqEo5vhkDWabvDs50mAqVKuV+3HuHTJXu4vV0d\nbmvrXDH2zEmYfhf4B1n96z1gsJW3lzC8UwQLn+xGSKMO/F/G/8HhaJK/eZB8F1HwIC5JBCLSV0R2\niUisiDyXz/4xIhLtfO0WkZN59uXm2TfHFfEopSx7ktJ46rtNtKhVgVcHNLYKHQ6Y9RCc3A+3fQXl\nq9sbZDGrUSGAj+9szR33/IMJvndQZd/PzJr4FmmZOXaHZptCJwIR8QY+BvoBjYHbRaRx3mOMMU8Y\nY1oaY1oCHwI/5Nl95uw+Y8yAwsajlLKkZ+Yw8usN+Pl48cldbfD3cc63s/w92P0r9H3bLbuJukqP\nq6tx1+gxxJVvQ9/9Y3jwvaks2XXU7rBs4YoaQTsg1hiz1xiTBUwDBl7k+NuBb11wX6XUBRhjeOb7\nzexJSuPD21sRWtE5tULMAlj8b2g+FNo+YG+QJUBggD8RD07FJ6Acb+T+j4cmrWT0jE2cPJ1ld2jF\nyhWJIBQ4kGf7oLPsb0QkDIgAfs9THCAiUSKyRkQGXegmIjLCeVxUUlKSC8JWqvT6YkUcczcf5uk+\nV//ZQyjloLV4S/Wm1oycOj2zJSgE35vHUc+xj2lhc/kxOoFe/1vGr1uP2B1ZsSnuxuKhwExjTG6e\nsjDn3Bd3AO+LSL38TjTGjDfGRBpjIoODg4sjVqXc0ob4E7z1y076NKnOyG51rUKHA2Y/bA0eG/IV\n+AXaG2RJ07A3XPMwrRK/4/f+6VQr78/IKRt4bNofHlE7cEUiSABq59mu5SzLz1DOeyxkjElw/twL\nLAHsm/RcKTeXlePgnz9spkZQAO/d2gI5+1t/1Bewdwn0eRMq17U1xhKr1ytQozlhK55m9j3hPN6r\nAXM3H6b3mGX8vrN0jzdwRSJYDzQQkQgR8cP6sv9b7x8RuRqoBKzOU1ZJRPyd76sCnQAd7qfUFZqw\nYi+7E9P414AmlA9wdglN3gO/vWRNqdBmuK3xlWg+/nDLJMjJwvfHh3i8Zz1+fLgTlQL9uO/LKJ6Z\nuYlTGdl2R1kkCp0IjDE5wCPAfGAHMMMYs01EXhORvL2AhgLTzF/nvW4ERInIJmAx8LYxRhOBUldg\nf/Jpxi6MoW+TGvRq7OwS6siFWSPBxw8GfKjtApdStT70/y/Er4Rl79E0tAJzRnXi/7rXY+aGg/Qd\ns4wVMcfsjtLldD0CpUoBYwzDJ60nat9xFo7uRkgFZy+hFWNg4asweAI0v9XWGN3K9w/C1u9hxBII\naQ7AH/tPMPq7TexNSmdYhzCe69eIMn7utQSmrkegVCk2d8thlu5OYnTvq/5MAonbrK6ijQdCs1vs\nDdDd9HsHAqvAnEcg1xpo1qpOJeY92oV7O4UzeXU8/T9czqYDJy9xIfegiUApN3cqI5t//bSdpqFB\nDOsYbhXmZMEPD0FABej/P30kVFCBleH6d+HwJmtSPqcAX29eubEJUx9oz5msXAZ/uooxC3aTneuw\nMdjC00SglJt7b/4uktMy+fdNzfD2cn7hL30HErfAjR9A2ar2BuiuGg+Cq/pbtarje/+yq1P9qvz6\neFcGtKjJ2EUx3PzpKmKPptkUaOFpIlDKjUUfOMnXa+K5p0M4zWtVtAoTNsCK/0GLO+Dq6+0N0J2J\nQP/3rAn5fnrsbxPTVSjjy5ghLfnkztYcOH6a/h8sZ/Kqfbhju6smAqXcVE6ug+d/2EK18v6M7t3Q\nKnTkwk+PQ9lq0O9tewMsDYJqwnX/grhl8MfX+R5yfbMQ5j/elQ71qvDKnG0Mm7SexFMZxRxo4Wgi\nUMpNfbU6nu2HT/HqjXnGDKyfAEc2W4u1B1SwN8DSovVwCOsEv70IqflPO1EtKIBJw9vyxqCmrItL\nps/7y5i35XDxxlkImgiUckNpmTl8tDiWzvWr0rdpDasw9Qj8/gbU7QFNbrI3wNLEy8tqa8nOgHlP\nX/AwEeGua8KY92gXwioH8n9TN/LkjGi3GISmiUApNzRpRRzH07N4qs9Vf04jMf8FyMmwBkRpLyHX\nqlofuj8HO+bAjp8uemjd4HLM/EdHHr22AbOjD9Hv/eWs3ZtcTIFeGU0ESrmZlNPZjF++l+saV6dl\nbWcD8d4lsHUmdH4CquQ7b6MqrI6joEYzmPsUZKRc9FBfby+evK4h343sgK+3MPTzNbz9y06yckpm\nN1NNBEq5mXHL9pCWmfNnA3FOJswdDZUioPOT9gZXmnn7Wo+I0hJh6buXdUrrOpWY+2gXhratw2dL\n9zDo45XsTkwt4kALThOBUm4kKTWTSSv3cUPzmlxdI8gqXPUBJMfC9e+Bb4C9AZZ2oa2h9d2w9jNI\n2n1Zp5T19+Gtwc34/J5IEk9lcMOHK5i4Ig6Ho+R0M9VEoJQb+XTJHrJyHTzRq4FVcDwOlr1nTSPR\noJe9wXmKni+Db1n49bkCLXp/XePq/Pp4VzrXr8prP29n2KR1HEkpGd1MNREo5SYOp5xhytp4bm4d\nSt3gctaX0C/PgJePtf6wKh7lgq2G4z2LrLWfCyC4vD9fDIvkzZuaErXvBH3eX8bczfZ3M9VEoJSb\n+GBRLMYYRvV01gZ2zoWY36DH89bAJ1V82j0IVa+yagXZBfutXkS4s30Ycx/tTHjVsjz8zUaemB5N\nyhn7uplqIlDKDcQnp/Nd1AFub1eH2pUDrQbi+c9DtcbQ7iG7w/M83r7WyO0T+2DNx1d0ibrB5Zg5\nsgOP92rAnE2H6Pf+MlbvsaebqUsSgYj0FZFdIhIrIs/ls3+4iCSJSLTz9UCefcNEJMb5GuaKeJQq\nbcYujMHbS3ikR32rYO04OBkPff4N3j72Buep6vWEq2+AZf+FU4eu6BK+3l483qshM0d2wN/Xmzsm\nrOHNudvJzMm99MkuVOhEICLewMdAP6AxcLuINM7n0OnGmJbO1wTnuZWBV4D2QDvgFRGpVNiYlCpN\nYhJTmRWdwLCO4VQLCoD0Y7DsP9CgD9TrYXd4nq33G+DIgQWvFOoyrepUYu6jnbmzfR0+Xx7HwI9W\nsv3QKRcFeWmuqBG0A2KNMXuNMVnANGDgZZ7bB1hgjDlujDkBLAD6uiAmpUqN9xfGUNbPh5HdnAPF\nlrwNWenQ+3V7A1NQOQI6PQpbZsD+NYW6VKCfD28Masak4W1JTs9i4Mcr+HTJHnKLoZupKxJBKHAg\nz/ZBZ9n5bhaRzSIyU0RqF/BcpTxSfHI687Ye5p4OYVQu6wdJuyBqIkTeB8FX2R2eAms0d1CoNQ+R\no/CPdHpcXY35j3elV6PqvPPrToaMW83+5NMuCPTCiqux+Ccg3BjTHOu3/skFvYCIjBCRKBGJSkpK\ncnmASpVEX6yIw9fLi+FnVx777SXwK2d1X1Qlg19ZuO41a9bX6KkuuWTlsn58cmdrxgxpwa7EVPqO\nXca36/YX2VoHrkgECUDtPNu1nGXnGGOSjTGZzs0JQJvLPTfPNcYbYyKNMZHBwcEuCFupku1EehYz\nog4wsGVNq21gz+8QMx+6PqWrjpU0TW+G0EhrNbMs1/z2LiLc1KoW8x/vSsvaFfnnD1t4YHIUSamZ\nlz65gFyRCNYDDUQkQkT8gKHAnLwHiEhIns0BwA7n+/lAbxGp5Gwk7u0sU8rjTV0bT0a2gwe71rUe\nOcx/ESqGQXvtLlriiFhtNqmHYe2nLr10zYplmHJ/e16+oTGbDp4kI9v1PYoK3e/MGJMjIo9gfYF7\nAxONMdtE5DUgyhgzB3hURAYAOcBxYLjz3OMi8jpWMgF4zRhzvLAxKeXuMrJz+XJVPN0aBtOwennY\nMBmOboNbJ4OPv93hqfyEdYSG/WDF+9ZiNmWruOzSXl7CfZ0juL1dHcr4ebvsumeJO66vGRkZaaKi\nouwOQ6kiM339fp79fgtTH2hPp9r+8EFrqFwX7vtV1xooyY7uhE87QPuR1ipxJYyIbDDGRJ5friOL\nlSphHA7D58vjaBwSRMd6VazfMNOPQp83NQmUdNWuhlZ3wbrPrQkB3YQmAqVKmKW7k4g9msaIrnWR\ntERY/TE0vQVq/e0XOVUSdX/emgjw9zfsjuSyaSJQqoQZv2wvIRUC6N88xFoAxZENPV+wOyx1uYJC\noMPD1opxh/6wO5rLoolAqRJka0IKq/cmc2+ncHxT9sHGydB6mNU+oNxHp8cgsAoseLlAaxbYRROB\nUiXI58v3Us7fh6Ht6lh90r18odszdoelCiogCLo+A3HLIHaR3dFckiYCpUqIhJNn+HnzYYa2rU3Q\nyZ2wZSZcMxLK17A7NHUlIu+DSuGw8BWXTD1RlDQRKFVCfLnS6mVyb+cIWPS69Vtlp8dsjkpdMR8/\nuPZlSNwKm2fYHc1FaSJQqgRIy8zh23UH6N8shNCUaGsqiU6PQxmdld2tNRkMIS1hyVuQk2V3NBek\niUCpEuDHPxJIy8zh3o5hsOhfUK6GNShJuTcR6PmitYhQ9BS7o7kgTQRK2cwYw5Q18TSpGUTLzPWw\nfzV0exr8Au0OTblC/V5Q+xpY+p8Cr29cXDQRKGWzjftPsPNIKne1r40seh0qRVhdRlXpcLZWkHrI\nWkuiBNJEoJTNvl4dT3l/Hwb7rYXELdDjBWtxdFV6RHSBiG6w4n+QmWZ3NH+jiUApGyWnZTJvyxFu\nbV0D/2VvQfWm1tz2qvTp+RKkJ8G68XZH8jeaCJSy0XcbDpKV6+ChCmvhRJz1CMFL/1uWSrXbQsO+\nsHIsnDlpdzR/of/ilLKJw2GYujaejuHlqR79IdRsbX1RqNKrx/OQcRLWfGJ3JH+hiUApmyyNSeLA\n8TM8W2MjnNxvfUnoNNOlW0gLaDwQVn8C6cl2R3OOSxKBiPQVkV0iEisif1tVW0SeFJHtIrJZRBaJ\nSFiefbkiEu18zTn/XKVKq6lr4gkp60XzveOhVlurm6Eq/bo/D1lpsGqs3ZGcU+hEICLewMdAP6Ax\ncLuIND7vsD+ASGNMc2Am8G6efWeMMS2drwGFjUcpd5Bw8gy/7zzK63U2IqcSoPs/tTbgKapdDc2H\nwNrxkHrE7mgA19QI2gGxxpi9xpgsYBowMO8BxpjFxpjTzs01QC0X3Fcpt/Xt2v34kUWPpK+twUb1\netodkipO3Z+F3CxY/j+7IwFckwhCgQN5tg86yy7kfuCXPNsBIhIlImtEZNCFThKREc7jopKSkgoX\nsVI2yspxMG39fl4OWY932mFtG/BEletCqzthw5dw6pDd0RRvY7GI3AVEAv/JUxzmXEz5DuB9EamX\n37nGmPHGmEhjTGRwcHAxRKtU0Zi/7QipaWncfHoGhHWCiK52h6Ts0GU0mFxrTWqbuSIRJAC182zX\ncpb9hYj0Al4ABhhjMs+WG2MSnD/3AkuAVi6ISakSa8qaeB4pvwz/jCStDXiySuHQ8o4SUStwRSJY\nDzQQkQgR8QOGAn/p/SMirYBxWEngaJ7ySiLi73xfFegEbHdBTEqVSLFHU9kcd4j7+dGqCYR3tjsk\nZacSUisodCIwxuQAjwDzgR3ADGPMNhF5TUTO9gL6D1AO+O68bqKNgCgR2QQsBt42xmgiUKXWtHUH\nGOa7iMDs41Y3QuXZSkitwMcVFzHGzAPmnVf2cp73+XaQNsasApq5IgalSrrMnFx+2RjLr34/Q1gP\nCOtgd0iqJOgyGqK/sWoF17976eOLgI4sVqqYLNx+lP6Z8yifm2K1DSgFVq2gxe3OWsFhW0LQRKBU\nMZm1dhf/8J2LqdsDarezOxxVkpxtK1hpT1uBJgKlisGB46cJj59BJU4h3f82C4vydJUjrFpB1CRb\nagWaCJQqBrPWxfKQ989k1O4Mda6xOxxVEtlYK9BEoFQRy3UYctdPIlhSCLhW2wbUBdhYK9BEoFQR\nW7HzIHfk/EBycDsI72R3OKoks6lWoIlAqSJ2+PdxVJeTBPV50e5QVElXOQJaDLVqBcU4M6kmAqWK\n0LGTp+ieNJX95VriW0/nFFKXoctocOTAqg+L7ZaaCJQqQjvnfUwNOY53j2d1TiF1eSrXhea3wfov\nIK14ZlrWRKBUETHZGTSM+Zydvo0Jbd3P7nCUO+kyGnIzYXXx1Ao0EShVROJ/n0A1k8zRVo9pbUAV\nTNUG0PRmWDehWNY21kSgVFHIySIo6gM2mQZEXnuz3dEod9TlKcg+DWs+KfJbaSJQqgic2TCVytmJ\n/FF3BIH+vnaHo9xRtauh8UBYOw7OnCjSW2kiUMrVcnPIWfIemxx1adXjVrujUe6s69OQlQprPivS\n22giUMrVtnxH+TMHmVX+DprXrmh3NMqd1WgKV98Aaz6FjJQiu40mAqVcyZFL5uJ32e4II6zDzYg2\nEqvC6vo0ZKbAuvFFdguXJAIR6Ssiu0QkVkT+NrWiiPiLyHTn/rUiEp5n3z+d5btEpI8r4lHKNttm\n4Z+yl08cgxnUqpbd0ajSoGZLaNgXVn8MmalFcotCJwIR8QY+BvoBjYHbRaTxeYfdD5wwxtQHxgDv\nOM9tjLXGcROgL/CJ83pKuR+HA8fSd4mlNjS6gUpl/eyOSJUWXZ+xGozXTyiSy7uiRtAOiDXG7DXG\nZAHTgIHnHTMQmOx8PxO4Vqw680BgmjEm0xgTB8Q6r1c0VoyBBS9f+jilrsSOOXgd28XYrIHc1jbM\n7mhUaVKrDdS71pp2Iivd5Zd3RSIIBQ7k2T7oLMv3GOdi9ylAlcs8FwARGSEiUSISlZR0hcOuT+6H\n1Z9AysErO1+pC3E4YNl/OORTi+jy3elcv6rdEanSptuzEFABTsS7/NJu01hsjBlvjIk0xkQGBwdf\n2UU6PwEYa5FopVxp9y+QuJX3ztzI4MgwvLy0kVi5WJ328EgUVD//yXvhuSIRJAC182zXcpble4yI\n+AAVgOTLPNd1KtaBlnfAxq9sWyRalULGwNJ3OBlQizmOjtwaqY3Eqoh4FU0TqisSwXqggYhEiIgf\nVuPvnPOOmQMMc76/BfjdGGOc5UOdvYoigAbAOhfEdGGdn3RO8fpBkd5GeZCYBXB4E5/kDKRD/erU\nqhRod0RKFUihE4Hzmf8jwHxgBzDDGLNNRF4TkQHOw74AqohILPAk8Jzz3G3ADGA78CvwsDEmt7Ax\nXVTlCGg+BKImQtrRIr2V8gDO2kBG2VAmprXntsjalz5HqRLGxxUXMcbMA+adV/ZynvcZQL5j7Y0x\nbwJvuiKOy9ZlNGyeZrXA9369WG+tSpm9iyEhilnVnqDcmTL0blLd7oiUKjC3aSx2qar1oektVp/c\n9GN2R6PclTGw9F0c5UJ4I6E1g1qG4u+jw2CU+/HMRADQ9SnIPmON1lPqSsQtg/2rWRs6jPRcb4a0\n1cdCyj15biIIvgqaDLLm7zh93O5olDta+i6mfAj/PtKW5rUq0CgkyO6IlLoinpsIwDnFaxqsLdop\nXlUptG8FxK/gUJOH2JKYqY3Eyq15diKo3gQa3WjN9X3mpN3RKHey9B0oV51x6V0I8PViQMuadkek\n1BXz7EQAxTLFqypl4ldD3DIy24/ih83JXN8shKAAXYVMuS9NBCEtoGE/q9E445Td0Sh3sPQdKBvM\nHJ/epGXmcGf7OnZHpFShaCIA6PYMZJzUWoG6tAPrrLEDHR9lyoYkrqpentZ1KtkdlVKFookAILS1\nc+GHj7RWoC5u6TsQWIVtobey6WAKt7errauQKbenieCsbs9aCz9orUBdyMENELsQOo7imz+O4e/j\nxU26CpkqBTQRnBXaGhr00VqBurCl70CZSqQ3H87s6EPc0LwmFQK1kVi5P00EeXXXWoG6gEN/QMx8\n6PAIP+1MJS0zhzva69gBVTpoIsgrtI3WClT+lr4LARWh3Qi+XbefhtXLaSOxKjU0EZxPawXqfIf+\ngF3zoMPDbE02zkbiOtpIrEoNTQTny1sryEy1OxpVEix+C8pUgvYj+Xbdfvx9vBisjcSqFNFEkB+t\nFaizDkZZbQMdR5EugcyOPkT/5iHaSKxKlUIlAhGpLCILRCTG+fNvD01FpKWIrBaRbSKyWUSG5Nn3\npYjEiUi089WyMPG4TGgbaNDbWrhGawWebclbEFgF2o3g582HrEbidjqSWJUuha0RPAcsMsY0ABY5\nt893GrjHGNME6Au8LyIV85Q6C+cAABvLSURBVOx/2hjT0vmKLmQ8rtPtOa0VeLr9a61xA50eA//y\nfLPuAA2rl6NNmDYSq9KlsIlgIDDZ+X4yMOj8A4wxu40xMc73h4CjQHAh71v0ammtwOMt+TeUDYa2\nD7DtUAqbDpzURmJVKhU2EVQ3xhx2vj8CXHTBVhFpB/gBe/IUv+l8ZDRGRPwvcu4IEYkSkaikpKRC\nhn2ZujtrBWt0vQKPE78K9i6BTo+DX9lzjcQ3tQq1OzKlXO6SiUBEForI1nxeA/MeZ4wxgLnIdUKA\nr4F7jTEOZ/E/gauBtkBl4NkLnW+MGW+MiTTGRAYHF1OFIrQNXHW9VSs4c6J47qlKhsX/hnLVIfI+\nUjOymbUxgf7NQqgY6Gd3ZEq53CUTgTGmlzGmaT6v2UCi8wv+7Bf90fyuISJBwFzgBWPMmjzXPmws\nmcAkoJ0rPpRL9XjeWq9g1Ud2R6KKS9wy2LccOj8BfoF8F3WQ9KxchnUMtzsypYpEYR8NzQGGOd8P\nA2aff4CI+AGzgK+MMTPP23c2iQhW+8LWQsbjejWaQZPBsOZTSCumR1LKPsZY4wbKh0Cb4Tgchsmr\n99G6TkVa1K54ydOVckeFTQRvA9eJSAzQy7mNiESKyATnMbcBXYHh+XQTnSoiW4AtQFXgjULGUzS6\n/xNyzsDK9+2ORBW1vUtg/yroMhp8y7B411Hik09zb6cIuyNTqsj4FOZkY0wycG0+5VHAA873U4Ap\nFzi/Z2HuX1An0rPw8/GirH8BP3ZwQ2g+FNZPgA4PQ5CuT1sqGWONGwgKhdb3APDlqn3UCAqgb9Ma\nNgenVNHxmJHFxhgemx7NgI9WEJN4Bd1Buz8LjhxY/l/XB6dKhpjf4MBaqzbg409MYirLY45xd4cw\nfL095r+K8kAe869bRBjZrS4pZ7IZ+PFKZkcnFOwClcKt3xI3TIYT8UUSo7KRwwGLXoNKEX+pDfj5\neDG0rU43rUo3j0kEAB3rVWXuo11oUjOIx6ZF89KPW8nMyb38C3R5CsTLmpJYlS5bv4fErdDjBfD2\nJeV0Nj9sTGBgi5pUKXfB4S1KlQoelQgAqgcF8M2D1/Bglwi+XhPPbePWcPDE6cs7uUIotL0fNn0D\nx2KLNlBVfHKzYfGbUL0pNL0ZgBlRBziTncvwTuH2xqZUMfC4RADg6+3FC/0b89ldrdl7NI0bPlzB\n4l35DoH4u85Pgk+A1aioSoeNX8GJOLj2ZfDyItfZZbRdRGWa1Kxgd3RKFTmPTARn9W0awpxRnakR\nFMB9X65nzILdOBwXHBxtKRcM7Uc6HyVsK55AVdHJOm096qvTwZpbCli4I5GDJ85wn9YGlIfw6EQA\nEFG1LLP+rxODW9Vi7KIY7v1yPSdPZ138pI6jwD/IalxU7m3dOEg7Ate+As7J5CatjCO0Yhl6Nbro\n1FlKlRoenwgAyvh5896tzXnzpqas3pPMDR+uYGtCyoVPCKwMXZ6A3b/CvhXFF6hyrTMnYMUYqyYQ\n1gGAHYdPsWbvce7uEIaPdhlVHkL/pTuJCHe2D2PGyA44HIbBn65i+vr9Fz6h/Uhr4NGCl62BSMr9\nrPwAMlKstgGnyav2EeCrXUaVZ9FEcJ6WtSvy06jOtAuvzLPfb+HZmZvJyM6ni6lvGWtCuoQNsP3H\n4g9UFU7qEVj7GTS9xZpPCjiWlsmsPxK4qVUtnWVUeRRNBPmoUs6fyfe14+Ee9ZgedYBbP1udfxfT\nFrdDtcZWW0HOJdoVVMmy7D+Qm2Ulc6cJy+PIynXwQBedV0h5Fk0EF+DtJTzd52o+vyeSfcfSufHD\nFSyPOW/2US9v6PUvOL4XNnxpS5zqCpz9+2p9D1SpB1jzUH29eh83NK9JveBytoanVHHTRHAJ1zWu\nzpxRnalWPoB7Jq7j48Wxf+1i2uA6CO8CS9+BjFP2Baou38JXwdsPuj5zrmjSqn2kZ+XySI/69sWl\nlE00EVyGiKplmfVwR25sXpP/zN/FQ1M2cCoj29opAtf9C04fs1YyUyVb/GrYPttagjIoBIBTGdlM\nWhlHnybVuapGeZsDVKr4aSK4TIF+Powd2pJXbmzM4p1HGfjRSnYdcc5iGtrGWrxm9UdWI6QqmRwO\nmP88lK8JHR85V/z16nhSM3IY1bOBjcEpZZ9CJQIRqSwiC0Qkxvmz0gWOy82zKM2cPOURIrJWRGJF\nZLpzNbMSS0S4t1ME3464hrTMHAZ9vJKfNh2ydl77kjVnjU49UXJtnQmHNlrdRf3KApCemcOE5Xvp\ncVUwTUN1OgnlmQpbI3gOWGSMaQAscm7n54wxpqXzNSBP+TvAGGNMfeAEcH8h4ykWbcMrM3dUZ5rU\nDGLUt3/w+s/bya4QDpH3wcavIWm33SGq82WdttoGQlpA8yHnir9Zu58Tp7N5RGsDyoMVNhEMBCY7\n30/GWnf4sjjXKe4JnF3HuEDn262acxbT4R3D+WJFHHdOWMuxNo+BbyAseMnu8NT51nwMpxKgz7/B\ny/pnn5Gdy7hle+lUvwptwvKtzCrlEQqbCKobYw473x8BLjQ5S4CIRInIGhE5+2VfBThpjMlxbh8E\nQgsZT7Hy8/Hi1QFNGDOkBZsPnqT/Fzs42Pxha+qJmIV2h6fOSk2E5WPg6hsgvPO54mnr9nMsLVPb\nBpTHu+TivSKyEMhvwdYX8m4YY4yIXGiuhTBjTIKI1AV+dy5Yf5HJfPKNYwQwAqBOnToFObXI3dSq\nFldVD2LklA30Wd2Y1RXqUP7X55CIVeBTops9PMPiN6zBY9f9OUlgZo5VG2gbXon2EZVtDE4p+12y\nRmCM6WWMaZrPazaQKCIhAM6f+U7qb4xJcP7cCywBWgHJQEUROZuMagEXXD/SGDPeGBNpjIkMDg4u\nwEcsHo1rBvHTI51pVz+ER08OQZJjyF79qd1hqSNbrHabdiPODR4D+H5DAodTMhjVswHinHVUKU9V\n2EdDc4BhzvfDgNnnHyAilUTE3/m+KtAJ2G6MMcBi4JaLne9OKgT68sWwtrTqOYRFua3IWvQWB/bH\n2R2W5zIG5r8AZSpCt6fPFWfnOvhkSSwtalWgS4OqNgaoVMlQ2ETwNnCdiMQAvZzbiEikiExwHtMI\niBKRTVhf/G8bY7Y79z0LPCkisVhtBl8UMh7beXkJj/VqQNmB7+JHFlETH2fRjkS7w/JMu+dD3FLo\n9hyU+bMxePr6Axw8cUZrA0o5iXHDKZQjIyNNVFSU3WFc0qmfnidow8cMzHyNbj368livhnh76RdP\nscg+Ax+3t6aS+MefbTUpZ7Lp8d4S6lcrx/QR12giUB5FRDYYYyLPL9eRxUUoqPc/MWWr82HFb/nw\n993c++V6TqTrLKXFYvl/4WQ89P/vXxrsP1gUw4nTWbx8Q2NNAko5aSIoSv7lkd6vUefMDr5pG8ca\n5+pnmw6ctDuy0u1YDKwcC81ug7rdzhXvSUpj8qp9DImsraOIlcpDE0FRa3Yb1GpLh70f8v19TQG4\n9bPVTFkTjzs+livxjIG5o8GnDPR+4y+73py7gwBfb0b3vsqm4JQqmTQRFDUvL+j3DqQn0Sz2M34e\n1ZkO9arw4o9bGT1jE2ey8ln9TF25rd9bDcTXvgTl/xzfuHR3Er/vPMqonvUJLu9vY4BKlTyaCIpD\naBtofTes+ZRKp3YyaXhbnujVkFnRCQz6eCV7k9LsjrB0yEixZhet2cqa98kpO9fB6z9vJ6xKIMM7\nhdsXn1IllCaC4tLrXxBYBeY8gpfJ5bFeDfjy3nYcTc1gwEcrmbv58KWvoS5u8b8h7Sj0/5+1epzT\n1DXxxB5N48X+jfH38b7IBZTyTJoIiktgZbj+XTi8yZoADejWMJifH+1Cg+rlePibjbwyeyuZOfqo\n6IocioZ146Ht/RDa+lzxifQsxiyMoXP9qvRqVM3GAJUquTQRFKfGg+Cq/tZvrsl7AAitWIbpIzrw\nQOcIJq+O59bPVrM/+bTNgboZhwPmPmnVuHr+debX9xfuJjUjm5e0u6hSF6SJoDiJQP/3rEFOPz9u\n9XDBmsX0xRsaM/7uNuw7lk7/D5fz61Zd6eyybfwSEjZA7zet6SScdiemMmXtfu5sH6ZLUCp1EZoI\niltQTWsWzLhl8MfXf9nVu0kN5j7ahbpVyzJyygZe+2k7WTkOmwJ1Eyfi4beXIaIrNL/tXHFWjoOn\nvttE+QAfnriuoY0BKlXyaSKwQ+thENYJ5r/4tzWOa1cOZMbIDgzvGM7ElXHc/Okq4o6l2xRoCedw\nwOyHrfcDPrJqXE7vL9zN5oMpvD24GZXL6lTgSl2MJgI7eHnBjR9ATgbMe+pvu/19vHl1QBPG3d2G\n/cdPc8MHy/lh40EbAi3h1o2Hfcuh77+hUti54tV7kvl06R6Gtq1N36YhNgaolHvQRGCXqvWh+3Ow\n4yfYPiffQ/o0qcEvj3WhSc0KPDljE09MjyYtMyffYz3OsRhY+Ao06AOt7j5XfPJ0Fk/OiCaiSlle\nvrGxjQEq5T40Edip4yio0cyqFaQn53tIzYpl+HbENTzRqyGzoxPo/8FyNh/08LmKcnNg1kPgWwYG\nfHDukZAxhudnbSEpNZP3h7Yk0O+SC/AppdBEYC9vXxj4CZw5YT3rvsDcQ97ONQ6mP9SB7BwHgz9Z\nxSdLYsl1eOhcRSvft3oJ9f8vlP9zFdXvNhxk3pYjjO59Fc1rVbzIBZRSeWkisFtIc6sX0e5frGfe\nF9E2vDLzHutC7ybVeffXXdw2bjXxyR7WkHxkCyx5G5oMhqY3nyuOO5bOq3O20aFuFR7qWtfGAJVy\nP4VKBCJSWUQWiEiM82elfI7pISLReV4ZIjLIue9LEYnLs69lYeJxW+1HWs+6f3sRDm++6KEVA/34\n+I7WvD+kJbsTU+k3djlT13rITKY5mfDDQ9Yo7f7/PVecnevg8Wl/4Ovtxf+GtMBLF/9RqkAKWyN4\nDlhkjGkALHJu/4UxZrExpqUxpiXQEzgN/JbnkKfP7jfGRBcyHvckAoM+gTKVYeZ9kHXx3/JFhEGt\nQpn/eFda16nEC7O2MnzSehJPZRRTwDZZ8hYc3QYDPrSSgdO7v+5kk7OraEiFMjYGqJR7KmwiGAhM\ndr6fDAy6xPG3AL8YY3QOhfOVrQqDx0NyLPzyzGWdUrNiGb66rx3/GtCEtXHJ9B6zjNnRCaWzdhCz\nAFa8b/UQatjnXPFnS/fw+fI47ukQRr9m2lVUqStR2ERQ3RhzdtrMI0D1ix0MDAW+Pa/sTRHZLCJj\nROSCE8WLyAgRiRKRqKSkpEKEXILV7QZdnoQ/psCWmZd1ipeXMKxjOHMf7UJ41bI8Ni2ae79cz4Hj\npSjXHo+D7++H6k2h37vniqesieftX3ZyY4uavHJjExsDVMq9XXLxehFZCNTIZ9cLwGRjTMU8x54w\nxvytncC5LwTYDNQ0xmTnKTsC+AHjgT3GmNcuFbS7LF5/RXKzYdL1cHQHjFwOlSMu/1SHYfKqfbz3\n2y6MgdG9GzK8Yzg+3m7cJyDrNHzRG1IOwIgl5/48Zkcn8Pj0aK69uhqf3tUGX3f+jEoVkytevN4Y\n08sY0zSf12wg0fllfvZL/ehFLnUbMOtsEnBe+7CxZAKTgHYF/WCljrcv3DwBxMv6LTjn8he79/YS\n7uscwYInu9GhXhXemLuDmz5ZxbZDKUUYcBEyxpqcL3Gr9WfiTAILtify5IxNXBNRhY/uaK1JQKlC\nKuz/oDnAMOf7YcDsixx7O+c9FsqTRASrfWFrIeMpHSqFwYCxVl/5eaMvOL7gQkIrluGLYZF8dEcr\nDqdYC9+8OXc7pzKyL31ySbLuc9g8HXo8Dw2uA2Bl7DEe/mYjzUIr8PmwSAJ8daEZpQqrsIngbeA6\nEYkBejm3EZFIEZlw9iARCQdqA0vPO3+qiGwBtgBVgTdQliY3QZfRsPErWDm2wKeLCDc0r8miJ7tx\nW2QtJqyIo/t/lvD1mnhyct1gRtP9a2D+P6FhP+hizce0If4ED34VRd2qZfny3raU89eRw0q5wiXb\nCEqiUt1GkJfDYT0e2vYD3PYVNB54xZfampDC6z9vZ23ccRpUK8fz/RvR46oSumJX6hEY1w38AuHB\nxVCmIj9sPMiLP26lWnl/ZozsQLXyAXZHqZTbueI2AmUjLy9rfEGtdvDDCDh45cmvaWgFpo24hvF3\ntyE718G9k9Zzz8R17DqS6sKAXSAnE74bDpmnYMhU0r3KMXrGJp6csYmmoRWY/pAmAaVcTWsE7iD9\nGHzeE7JPwwOL/jLl8pXIynHw9Zp4xi7cTWpmDv2a1uAf3erTrFYFFwV8hXJz4LthsPNnuGUiO6pc\nxyPfbGTvsXRG9WzAoz3ru3cPKKVsdqEagSYCd5G0CyZcB0EhcP9vEFD4L+0T6VlMWLGXr1bHk5qR\nQ+f6Vfm/7vXoUK9K8a/v63DAj/+AzdMwfd9mKtfz2s/bqVDGl7FDWtKxftXijUepUkgTQWmwdylM\nGQzhXeDO76yupi6QmpHN1LX7+WJFHEmpmbSoVYF/dK9Hr0bVi+c3cGNg7miI+oLk9s/wYnJfftl6\nhC4NqjJmSEuqlrvgOEOlVAFoIigt/phiTVnd5Ca4aTz4uG4ZxozsXL7feJBxS/ey//hpqpbz44bm\nNRnQsiatalcsmlqCMZgFryCrxvJLhSH8I3EAfj7ePNGrIQ91rasTyCnlQpoISpOVH8CCl6wZS2+b\nbC3Q4kI5uQ4W7TzK7OgEFu44SlaOgzqVAxnYsiYDW9akfrXyLrlPdq6DmJmv0njHWKbkXMv//EZy\nV4dw7r4mjODyWgtQytU0EZQ2URPh5ychvDPc/i34u+bL+XynMrL5bVsis6MTWBl7DIeBmhUCaFar\nAs1rVaR5rQo0C61AxcBL10xOZWSz/dApth06xbaEFEJ3f8Xo3C9Y4NOdpF5jGdymtg4QU6oIaSIo\njTZ/Zy3ZWLMl3DnzL1MzF4WjqRn8uvUIUftOsCUhhbhjf06XHVYlkNqVAvH1Fny9vfD18cLP2wtf\nbyEtM4dth04Rn3x2IjzDk4G/8qjja46G9qLqvdPw8nFNe4dS6sI0EZRWO+dZ/e6r1IO7f4Tyl5oA\n1nVSTmez9VAKmw6eZPOBFI6mZpCda8jOdThf1ns/Hy8ahwTRpGYQzWoE0G7rvyiz/TtoPMiaettH\nHwMpVRw0EZRme5fAt3dYSeDuHws9zqDIpCbC9Dvh4Hro8QJ0ffrcwvNKqaKnI4tLs7rd4Z4f4XQy\njO8G2+fYHdHfHYqGz3tA4jZruoxuz2gSUKqE0ERQWtRuBw/8DpXCYcbdVhfTzBIyfcS2WTCxLyBw\n3/xCzZmklHI9TQSlSdX6cP8Ca7bO6G/gs85wYJ198Zw+DnOfstowQprDiMXWT6VUiaKJoLTx9oVr\nX4Lh88A4rN/EF79lzeNTXHJzYP0E+LANRH0B7R6CYT9BuRI626lSHk4TQWkV1gFGroDmt8HSt+Hz\n7rD1h6JPCHHLrXaKuaOhehN4aDlc/672DFKqBNNEUJoFVICbPoNbJ1tr/868Fz5sBWs+g8w0197r\nWAzMuAcm3wAZp6wG4WE/QY2mrr2PUsrlCpUIRORWEdkmIg4R+VuXpDzH9RWRXSISKyLP5SmPEJG1\nzvLpIuK6iXPUn5oMgkfWw5CpUL4m/PosjGkCi16zFoG5Ukd3wtJ34dPO8FEkxCyAHi/CI+usBmHt\nFaSUWyjUOAIRaQQ4gHHAU8aYv3XuFxFvYDdwHXAQWA/cbozZLiIzgB+MMdNE5DNgkzHm00vdV8cR\nFNKBdbDqA9jxs7VdpT6EtMjzag5lKv15fHYGZKRAxklrbYS9i60uqsd2AQK121tf/E0HQ/katnwk\npdSlXWgcQaEWfTXG7HBe/GKHtQNijTF7ncdOAwaKyA6gJ3CH87jJwKvAJROBKqTa7WDIFEjeA1u/\nh8Ob4MBa2Drzz2OCQsGRa33552T89XzxgrBO0O5BaHSjfvkr5eaKY/XvUOBAnu2DQHugCnDSGJOT\npzz0QhcRkRHACIA6deoUTaSepko9a2DXWenJcDjaSgxJO60G3oAKEFARylS0fgZUtOY2KqsLxShV\nWlwyEYjIQiC/X/leMMbMdn1I+TPGjAfGg/VoqLju61HKVoH611ovpZTHuGQiMMb0KuQ9EoDaebZr\nOcuSgYoi4uOsFZwtV0opVYyKo/voeqCBs4eQHzAUmGOsVurFwC3O44YBxVbDUEopZSls99GbROQg\n0AGYKyLzneU1RWQegPO3/UeA+cAOYIYxZpvzEs8CT4pILFabwReFiUcppVTB6TTUSinlIXQaaqWU\nUvnSRKCUUh5OE4FSSnk4TQRKKeXh3LKxWESSgPgiuHRV4FgRXLe4uHv84P6fwd3jB/f/DO4ePxTd\nZwgzxgSfX+iWiaCoiEhUfi3q7sLd4wf3/wzuHj+4/2dw9/ih+D+DPhpSSikPp4lAKaU8nCaCvxpv\ndwCF5O7xg/t/BnePH9z/M7h7/FDMn0HbCJRSysNpjUAppTycJgKllPJwmgjOIyKvi8hmEYkWkd9E\npKbdMRWEiPxHRHY6P8MsEalod0wFJSK3isg2EXGIiNt0AxSRviKyS0RiReQ5u+MpKBGZKCJHRWSr\n3bFcCRGpLSKLRWS789/PY3bHVBAiEiAi60RkkzP+fxXbvbWN4K9EJMgYc8r5/lGgsTFmpM1hXTYR\n6Q38bozJEZF3AIwxz9ocVoGISCPAAYwDnjLGlPipZkXEG9gNXIe17Op64HZjzHZbAysAEekKpAFf\nGWOa2h1PQYlICBBijNkoIuWBDcAgd/k7EGvx97LGmDQR8QVWAI8ZY9YU9b21RnCes0nAqSzgVpnS\nGPNbnnWg12Ct/OZWjDE7jDG77I6jgNoBscaYvcaYLGAaMNDmmArEGLMMOG53HFfKGHPYGLPR+T4V\na/2TC66DXtIYS5pz09f5KpbvH00E+RCRN0XkAHAn8LLd8RTCfcAvdgfhIUKBA3m2D+JGX0KljYiE\nA62AtfZGUjAi4i0i0cBRYIExplji98hEICILRWRrPq+BAMaYF4wxtYGpWKurlSiXit95zAtADtZn\nKHEu5zModSVEpBzwPfD4eTX8Es8Yk2uMaYlVk28nIsXyiO6Si9eXRsaYXpd56FRgHvBKEYZTYJeK\nX0SGAzcA15oS2ghUgL8Dd5EA1M6zXctZpoqR89n698BUY8wPdsdzpYwxJ0VkMdAXKPLGe4+sEVyM\niDTIszkQ2GlXLFdCRPoCzwADjDGn7Y7Hg6wHGohIhIj4AUOBOTbH5FGcja1fADuMMf+zO56CEpHg\ns738RKQMVseDYvn+0V5D5xGR74GrsHqtxAMjjTFu85udiMQC/kCys2iNO/V6AhCRm4APgWDgJBBt\njOljb1SXJiLXA+8D3sBEY8ybNodUICLyLdAdawrkROAVY8wXtgZVACLSGVgObMH6/wvwvDFmnn1R\nXT4RaQ5Mxvr34wXMMMa8Viz31kSglFKeTR8NKaWUh9NEoJRSHk4TgVJKeThNBEop5eE0ESillIfT\nRKCUUh5OE4FSSnm4/wfmhCc3v4YmOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sn6P8EdjST9",
        "colab_type": "text"
      },
      "source": [
        "### 課題\n",
        "\n",
        "コサイン関数の場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o79trebZjNz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "51ff569e-47c7-4c22-d53e-ad9dfa0ec8cc"
      },
      "source": [
        "x = np.linspace(-np.pi, np.pi).reshape(-1, 1)\n",
        "t = np.cos(x)\n",
        "\n",
        "plt.plot(x, t)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ3x2BfjjbEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba16bc54-45b7-4dad-8bce-fd1fc624a41c"
      },
      "source": [
        "history = model.fit(x, t, batch_size=batch_size, epochs=500, validation_split=0.1) # 10%のデータを検証用に使う"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 45 samples, validate on 5 samples\n",
            "Epoch 1/500\n",
            "45/45 [==============================] - 0s 385us/step - loss: 0.9072 - val_loss: 2.0474\n",
            "Epoch 2/500\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.8319 - val_loss: 1.9904\n",
            "Epoch 3/500\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.7865 - val_loss: 1.6231\n",
            "Epoch 4/500\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.7575 - val_loss: 1.5553\n",
            "Epoch 5/500\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.7091 - val_loss: 1.4858\n",
            "Epoch 6/500\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.6891 - val_loss: 1.3382\n",
            "Epoch 7/500\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.6740 - val_loss: 1.1482\n",
            "Epoch 8/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.6642 - val_loss: 1.1343\n",
            "Epoch 9/500\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.6546 - val_loss: 1.0112\n",
            "Epoch 10/500\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.6366 - val_loss: 1.0196\n",
            "Epoch 11/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.6294 - val_loss: 0.9523\n",
            "Epoch 12/500\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.6247 - val_loss: 0.8994\n",
            "Epoch 13/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.6184 - val_loss: 0.8787\n",
            "Epoch 14/500\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.6109 - val_loss: 0.8501\n",
            "Epoch 15/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.6041 - val_loss: 0.8532\n",
            "Epoch 16/500\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.6061 - val_loss: 0.7775\n",
            "Epoch 17/500\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.6002 - val_loss: 0.8323\n",
            "Epoch 18/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.5885 - val_loss: 0.7875\n",
            "Epoch 19/500\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.5886 - val_loss: 0.8059\n",
            "Epoch 20/500\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.5828 - val_loss: 0.7689\n",
            "Epoch 21/500\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.5780 - val_loss: 0.7982\n",
            "Epoch 22/500\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.5762 - val_loss: 0.6646\n",
            "Epoch 23/500\n",
            "45/45 [==============================] - 0s 280us/step - loss: 0.5695 - val_loss: 0.6589\n",
            "Epoch 24/500\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.5663 - val_loss: 0.7712\n",
            "Epoch 25/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.5635 - val_loss: 0.7756\n",
            "Epoch 26/500\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.5540 - val_loss: 0.7118\n",
            "Epoch 27/500\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.5676 - val_loss: 0.6416\n",
            "Epoch 28/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.5495 - val_loss: 0.6615\n",
            "Epoch 29/500\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.5435 - val_loss: 0.6338\n",
            "Epoch 30/500\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.5573 - val_loss: 0.7034\n",
            "Epoch 31/500\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.5350 - val_loss: 0.6971\n",
            "Epoch 32/500\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.5358 - val_loss: 0.7493\n",
            "Epoch 33/500\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.5365 - val_loss: 0.7289\n",
            "Epoch 34/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.5255 - val_loss: 0.7133\n",
            "Epoch 35/500\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.5308 - val_loss: 0.6469\n",
            "Epoch 36/500\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.5247 - val_loss: 0.7122\n",
            "Epoch 37/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.5207 - val_loss: 0.7307\n",
            "Epoch 38/500\n",
            "45/45 [==============================] - 0s 298us/step - loss: 0.5132 - val_loss: 0.6823\n",
            "Epoch 39/500\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.5172 - val_loss: 0.6790\n",
            "Epoch 40/500\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.5048 - val_loss: 0.6529\n",
            "Epoch 41/500\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.4997 - val_loss: 0.6299\n",
            "Epoch 42/500\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.4964 - val_loss: 0.6144\n",
            "Epoch 43/500\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.5044 - val_loss: 0.5966\n",
            "Epoch 44/500\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.4904 - val_loss: 0.6613\n",
            "Epoch 45/500\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.4847 - val_loss: 0.6462\n",
            "Epoch 46/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.4789 - val_loss: 0.6207\n",
            "Epoch 47/500\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.4787 - val_loss: 0.6083\n",
            "Epoch 48/500\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.4788 - val_loss: 0.6259\n",
            "Epoch 49/500\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.4747 - val_loss: 0.5756\n",
            "Epoch 50/500\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.4785 - val_loss: 0.5834\n",
            "Epoch 51/500\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.4684 - val_loss: 0.5313\n",
            "Epoch 52/500\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.4617 - val_loss: 0.5850\n",
            "Epoch 53/500\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.4572 - val_loss: 0.5722\n",
            "Epoch 54/500\n",
            "45/45 [==============================] - 0s 198us/step - loss: 0.4538 - val_loss: 0.5916\n",
            "Epoch 55/500\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.4502 - val_loss: 0.5600\n",
            "Epoch 56/500\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.4493 - val_loss: 0.5833\n",
            "Epoch 57/500\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.4431 - val_loss: 0.6090\n",
            "Epoch 58/500\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.4395 - val_loss: 0.6116\n",
            "Epoch 59/500\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.4410 - val_loss: 0.6516\n",
            "Epoch 60/500\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.4407 - val_loss: 0.5980\n",
            "Epoch 61/500\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.4394 - val_loss: 0.5924\n",
            "Epoch 62/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.4311 - val_loss: 0.6281\n",
            "Epoch 63/500\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.4279 - val_loss: 0.5729\n",
            "Epoch 64/500\n",
            "45/45 [==============================] - 0s 336us/step - loss: 0.4251 - val_loss: 0.6037\n",
            "Epoch 65/500\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.4232 - val_loss: 0.5390\n",
            "Epoch 66/500\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.4208 - val_loss: 0.5299\n",
            "Epoch 67/500\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.4204 - val_loss: 0.5723\n",
            "Epoch 68/500\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.4124 - val_loss: 0.5330\n",
            "Epoch 69/500\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.4133 - val_loss: 0.5965\n",
            "Epoch 70/500\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.4081 - val_loss: 0.5722\n",
            "Epoch 71/500\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.4035 - val_loss: 0.5969\n",
            "Epoch 72/500\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.3982 - val_loss: 0.5665\n",
            "Epoch 73/500\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.3991 - val_loss: 0.5427\n",
            "Epoch 74/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.3982 - val_loss: 0.5214\n",
            "Epoch 75/500\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.3907 - val_loss: 0.5494\n",
            "Epoch 76/500\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.3864 - val_loss: 0.5473\n",
            "Epoch 77/500\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.3853 - val_loss: 0.5799\n",
            "Epoch 78/500\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.3834 - val_loss: 0.5577\n",
            "Epoch 79/500\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.3790 - val_loss: 0.5259\n",
            "Epoch 80/500\n",
            "45/45 [==============================] - 0s 295us/step - loss: 0.3758 - val_loss: 0.5517\n",
            "Epoch 81/500\n",
            "45/45 [==============================] - 0s 261us/step - loss: 0.3733 - val_loss: 0.5419\n",
            "Epoch 82/500\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.3759 - val_loss: 0.5680\n",
            "Epoch 83/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.3664 - val_loss: 0.5690\n",
            "Epoch 84/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.3641 - val_loss: 0.5356\n",
            "Epoch 85/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.3635 - val_loss: 0.5693\n",
            "Epoch 86/500\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.3583 - val_loss: 0.5571\n",
            "Epoch 87/500\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.3599 - val_loss: 0.5640\n",
            "Epoch 88/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.3545 - val_loss: 0.5064\n",
            "Epoch 89/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.3539 - val_loss: 0.5086\n",
            "Epoch 90/500\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.3470 - val_loss: 0.5426\n",
            "Epoch 91/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.3460 - val_loss: 0.5066\n",
            "Epoch 92/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.3447 - val_loss: 0.4867\n",
            "Epoch 93/500\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.3428 - val_loss: 0.4848\n",
            "Epoch 94/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.3405 - val_loss: 0.5168\n",
            "Epoch 95/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.3386 - val_loss: 0.5190\n",
            "Epoch 96/500\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.3332 - val_loss: 0.5741\n",
            "Epoch 97/500\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.3366 - val_loss: 0.5210\n",
            "Epoch 98/500\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.3275 - val_loss: 0.4938\n",
            "Epoch 99/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.3261 - val_loss: 0.4548\n",
            "Epoch 100/500\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.3257 - val_loss: 0.5010\n",
            "Epoch 101/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.3193 - val_loss: 0.4765\n",
            "Epoch 102/500\n",
            "45/45 [==============================] - 0s 300us/step - loss: 0.3234 - val_loss: 0.4662\n",
            "Epoch 103/500\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.3187 - val_loss: 0.4772\n",
            "Epoch 104/500\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.3132 - val_loss: 0.5009\n",
            "Epoch 105/500\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.3124 - val_loss: 0.5317\n",
            "Epoch 106/500\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.3115 - val_loss: 0.5491\n",
            "Epoch 107/500\n",
            "45/45 [==============================] - 0s 302us/step - loss: 0.3034 - val_loss: 0.5418\n",
            "Epoch 108/500\n",
            "45/45 [==============================] - 0s 283us/step - loss: 0.3043 - val_loss: 0.5608\n",
            "Epoch 109/500\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.3003 - val_loss: 0.5169\n",
            "Epoch 110/500\n",
            "45/45 [==============================] - 0s 265us/step - loss: 0.2977 - val_loss: 0.4737\n",
            "Epoch 111/500\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.2980 - val_loss: 0.5130\n",
            "Epoch 112/500\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.2944 - val_loss: 0.5322\n",
            "Epoch 113/500\n",
            "45/45 [==============================] - 0s 277us/step - loss: 0.2887 - val_loss: 0.5177\n",
            "Epoch 114/500\n",
            "45/45 [==============================] - 0s 299us/step - loss: 0.2892 - val_loss: 0.4954\n",
            "Epoch 115/500\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.2865 - val_loss: 0.4899\n",
            "Epoch 116/500\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.2821 - val_loss: 0.4755\n",
            "Epoch 117/500\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.2790 - val_loss: 0.4814\n",
            "Epoch 118/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.2773 - val_loss: 0.4971\n",
            "Epoch 119/500\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.2758 - val_loss: 0.4774\n",
            "Epoch 120/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.2725 - val_loss: 0.4829\n",
            "Epoch 121/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.2703 - val_loss: 0.4620\n",
            "Epoch 122/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.2669 - val_loss: 0.4670\n",
            "Epoch 123/500\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.2649 - val_loss: 0.4629\n",
            "Epoch 124/500\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.2650 - val_loss: 0.4367\n",
            "Epoch 125/500\n",
            "45/45 [==============================] - 0s 281us/step - loss: 0.2623 - val_loss: 0.4457\n",
            "Epoch 126/500\n",
            "45/45 [==============================] - 0s 288us/step - loss: 0.2591 - val_loss: 0.4513\n",
            "Epoch 127/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.2566 - val_loss: 0.4440\n",
            "Epoch 128/500\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.2551 - val_loss: 0.4635\n",
            "Epoch 129/500\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.2556 - val_loss: 0.4407\n",
            "Epoch 130/500\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.2529 - val_loss: 0.4172\n",
            "Epoch 131/500\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.2483 - val_loss: 0.4382\n",
            "Epoch 132/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.2500 - val_loss: 0.4748\n",
            "Epoch 133/500\n",
            "45/45 [==============================] - 0s 213us/step - loss: 0.2459 - val_loss: 0.4669\n",
            "Epoch 134/500\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.2450 - val_loss: 0.4594\n",
            "Epoch 135/500\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.2409 - val_loss: 0.4083\n",
            "Epoch 136/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.2383 - val_loss: 0.3849\n",
            "Epoch 137/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.2359 - val_loss: 0.3898\n",
            "Epoch 138/500\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.2359 - val_loss: 0.3972\n",
            "Epoch 139/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.2350 - val_loss: 0.4014\n",
            "Epoch 140/500\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.2286 - val_loss: 0.4053\n",
            "Epoch 141/500\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.2293 - val_loss: 0.4040\n",
            "Epoch 142/500\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.2257 - val_loss: 0.4181\n",
            "Epoch 143/500\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.2253 - val_loss: 0.4239\n",
            "Epoch 144/500\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.2220 - val_loss: 0.4508\n",
            "Epoch 145/500\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.2224 - val_loss: 0.3979\n",
            "Epoch 146/500\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.2178 - val_loss: 0.4086\n",
            "Epoch 147/500\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.2161 - val_loss: 0.3712\n",
            "Epoch 148/500\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.2130 - val_loss: 0.3806\n",
            "Epoch 149/500\n",
            "45/45 [==============================] - 0s 285us/step - loss: 0.2109 - val_loss: 0.3764\n",
            "Epoch 150/500\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.2093 - val_loss: 0.3815\n",
            "Epoch 151/500\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.2088 - val_loss: 0.3669\n",
            "Epoch 152/500\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.2065 - val_loss: 0.3811\n",
            "Epoch 153/500\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.2036 - val_loss: 0.3797\n",
            "Epoch 154/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.2024 - val_loss: 0.3836\n",
            "Epoch 155/500\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.2001 - val_loss: 0.3872\n",
            "Epoch 156/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.2001 - val_loss: 0.3763\n",
            "Epoch 157/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.1998 - val_loss: 0.3810\n",
            "Epoch 158/500\n",
            "45/45 [==============================] - 0s 196us/step - loss: 0.1969 - val_loss: 0.3497\n",
            "Epoch 159/500\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1944 - val_loss: 0.3605\n",
            "Epoch 160/500\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.1926 - val_loss: 0.3682\n",
            "Epoch 161/500\n",
            "45/45 [==============================] - 0s 199us/step - loss: 0.1908 - val_loss: 0.3818\n",
            "Epoch 162/500\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.1904 - val_loss: 0.3864\n",
            "Epoch 163/500\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.1888 - val_loss: 0.3438\n",
            "Epoch 164/500\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.1853 - val_loss: 0.3418\n",
            "Epoch 165/500\n",
            "45/45 [==============================] - 0s 259us/step - loss: 0.1844 - val_loss: 0.3725\n",
            "Epoch 166/500\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.1827 - val_loss: 0.3656\n",
            "Epoch 167/500\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.1803 - val_loss: 0.3976\n",
            "Epoch 168/500\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.1788 - val_loss: 0.3596\n",
            "Epoch 169/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.1785 - val_loss: 0.3504\n",
            "Epoch 170/500\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.1746 - val_loss: 0.3403\n",
            "Epoch 171/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.1727 - val_loss: 0.3390\n",
            "Epoch 172/500\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.1748 - val_loss: 0.3465\n",
            "Epoch 173/500\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.1729 - val_loss: 0.3617\n",
            "Epoch 174/500\n",
            "45/45 [==============================] - 0s 289us/step - loss: 0.1692 - val_loss: 0.3493\n",
            "Epoch 175/500\n",
            "45/45 [==============================] - 0s 305us/step - loss: 0.1686 - val_loss: 0.3367\n",
            "Epoch 176/500\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.1689 - val_loss: 0.3304\n",
            "Epoch 177/500\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.1655 - val_loss: 0.3221\n",
            "Epoch 178/500\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.1640 - val_loss: 0.3157\n",
            "Epoch 179/500\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.1605 - val_loss: 0.3124\n",
            "Epoch 180/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.1589 - val_loss: 0.3319\n",
            "Epoch 181/500\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.1592 - val_loss: 0.3246\n",
            "Epoch 182/500\n",
            "45/45 [==============================] - 0s 295us/step - loss: 0.1561 - val_loss: 0.3253\n",
            "Epoch 183/500\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1553 - val_loss: 0.3123\n",
            "Epoch 184/500\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1554 - val_loss: 0.3254\n",
            "Epoch 185/500\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.1514 - val_loss: 0.3118\n",
            "Epoch 186/500\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.1508 - val_loss: 0.2935\n",
            "Epoch 187/500\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.1523 - val_loss: 0.3028\n",
            "Epoch 188/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.1497 - val_loss: 0.3111\n",
            "Epoch 189/500\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.1475 - val_loss: 0.3047\n",
            "Epoch 190/500\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.1450 - val_loss: 0.2999\n",
            "Epoch 191/500\n",
            "45/45 [==============================] - 0s 301us/step - loss: 0.1436 - val_loss: 0.3156\n",
            "Epoch 192/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1453 - val_loss: 0.2973\n",
            "Epoch 193/500\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.1428 - val_loss: 0.2938\n",
            "Epoch 194/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.1416 - val_loss: 0.3130\n",
            "Epoch 195/500\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1402 - val_loss: 0.2935\n",
            "Epoch 196/500\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.1366 - val_loss: 0.2981\n",
            "Epoch 197/500\n",
            "45/45 [==============================] - 0s 260us/step - loss: 0.1408 - val_loss: 0.2938\n",
            "Epoch 198/500\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.1344 - val_loss: 0.2890\n",
            "Epoch 199/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.1346 - val_loss: 0.2995\n",
            "Epoch 200/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.1325 - val_loss: 0.3087\n",
            "Epoch 201/500\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.1308 - val_loss: 0.3037\n",
            "Epoch 202/500\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.1328 - val_loss: 0.2742\n",
            "Epoch 203/500\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.1281 - val_loss: 0.2936\n",
            "Epoch 204/500\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.1279 - val_loss: 0.2801\n",
            "Epoch 205/500\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.1257 - val_loss: 0.2703\n",
            "Epoch 206/500\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.1247 - val_loss: 0.2844\n",
            "Epoch 207/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.1229 - val_loss: 0.2921\n",
            "Epoch 208/500\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.1225 - val_loss: 0.2870\n",
            "Epoch 209/500\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.1222 - val_loss: 0.2772\n",
            "Epoch 210/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.1195 - val_loss: 0.2822\n",
            "Epoch 211/500\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.1199 - val_loss: 0.2527\n",
            "Epoch 212/500\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.1170 - val_loss: 0.2763\n",
            "Epoch 213/500\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.1169 - val_loss: 0.2706\n",
            "Epoch 214/500\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.1154 - val_loss: 0.2559\n",
            "Epoch 215/500\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.1143 - val_loss: 0.2445\n",
            "Epoch 216/500\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.1140 - val_loss: 0.2342\n",
            "Epoch 217/500\n",
            "45/45 [==============================] - 0s 372us/step - loss: 0.1127 - val_loss: 0.2518\n",
            "Epoch 218/500\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.1120 - val_loss: 0.2513\n",
            "Epoch 219/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.1115 - val_loss: 0.2559\n",
            "Epoch 220/500\n",
            "45/45 [==============================] - 0s 197us/step - loss: 0.1083 - val_loss: 0.2672\n",
            "Epoch 221/500\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.1075 - val_loss: 0.2557\n",
            "Epoch 222/500\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.1072 - val_loss: 0.2442\n",
            "Epoch 223/500\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.1064 - val_loss: 0.2472\n",
            "Epoch 224/500\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.1049 - val_loss: 0.2421\n",
            "Epoch 225/500\n",
            "45/45 [==============================] - 0s 192us/step - loss: 0.1036 - val_loss: 0.2482\n",
            "Epoch 226/500\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.1033 - val_loss: 0.2297\n",
            "Epoch 227/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.1020 - val_loss: 0.2513\n",
            "Epoch 228/500\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.1009 - val_loss: 0.2572\n",
            "Epoch 229/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0993 - val_loss: 0.2498\n",
            "Epoch 230/500\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0984 - val_loss: 0.2526\n",
            "Epoch 231/500\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0985 - val_loss: 0.2305\n",
            "Epoch 232/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0968 - val_loss: 0.2198\n",
            "Epoch 233/500\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0958 - val_loss: 0.2160\n",
            "Epoch 234/500\n",
            "45/45 [==============================] - 0s 276us/step - loss: 0.0958 - val_loss: 0.2215\n",
            "Epoch 235/500\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0950 - val_loss: 0.2376\n",
            "Epoch 236/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0933 - val_loss: 0.2424\n",
            "Epoch 237/500\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0924 - val_loss: 0.2140\n",
            "Epoch 238/500\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0907 - val_loss: 0.2125\n",
            "Epoch 239/500\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0897 - val_loss: 0.2183\n",
            "Epoch 240/500\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0900 - val_loss: 0.2188\n",
            "Epoch 241/500\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0896 - val_loss: 0.2273\n",
            "Epoch 242/500\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0880 - val_loss: 0.2072\n",
            "Epoch 243/500\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0873 - val_loss: 0.2066\n",
            "Epoch 244/500\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0865 - val_loss: 0.1925\n",
            "Epoch 245/500\n",
            "45/45 [==============================] - 0s 318us/step - loss: 0.0852 - val_loss: 0.2059\n",
            "Epoch 246/500\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0845 - val_loss: 0.2059\n",
            "Epoch 247/500\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0833 - val_loss: 0.2097\n",
            "Epoch 248/500\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0825 - val_loss: 0.2083\n",
            "Epoch 249/500\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0816 - val_loss: 0.2014\n",
            "Epoch 250/500\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0804 - val_loss: 0.1904\n",
            "Epoch 251/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0798 - val_loss: 0.2008\n",
            "Epoch 252/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0797 - val_loss: 0.2007\n",
            "Epoch 253/500\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0778 - val_loss: 0.1834\n",
            "Epoch 254/500\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0776 - val_loss: 0.1927\n",
            "Epoch 255/500\n",
            "45/45 [==============================] - 0s 217us/step - loss: 0.0772 - val_loss: 0.1977\n",
            "Epoch 256/500\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0754 - val_loss: 0.1958\n",
            "Epoch 257/500\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0752 - val_loss: 0.2052\n",
            "Epoch 258/500\n",
            "45/45 [==============================] - 0s 202us/step - loss: 0.0755 - val_loss: 0.1935\n",
            "Epoch 259/500\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0744 - val_loss: 0.1977\n",
            "Epoch 260/500\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0729 - val_loss: 0.1917\n",
            "Epoch 261/500\n",
            "45/45 [==============================] - 0s 214us/step - loss: 0.0731 - val_loss: 0.1937\n",
            "Epoch 262/500\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0717 - val_loss: 0.1934\n",
            "Epoch 263/500\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0709 - val_loss: 0.1636\n",
            "Epoch 264/500\n",
            "45/45 [==============================] - 0s 269us/step - loss: 0.0699 - val_loss: 0.1659\n",
            "Epoch 265/500\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0697 - val_loss: 0.1660\n",
            "Epoch 266/500\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0685 - val_loss: 0.1775\n",
            "Epoch 267/500\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0679 - val_loss: 0.1788\n",
            "Epoch 268/500\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0685 - val_loss: 0.1846\n",
            "Epoch 269/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0668 - val_loss: 0.1703\n",
            "Epoch 270/500\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0652 - val_loss: 0.1667\n",
            "Epoch 271/500\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0652 - val_loss: 0.1635\n",
            "Epoch 272/500\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0655 - val_loss: 0.1676\n",
            "Epoch 273/500\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0638 - val_loss: 0.1730\n",
            "Epoch 274/500\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0631 - val_loss: 0.1671\n",
            "Epoch 275/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0628 - val_loss: 0.1654\n",
            "Epoch 276/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0618 - val_loss: 0.1563\n",
            "Epoch 277/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0618 - val_loss: 0.1563\n",
            "Epoch 278/500\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0610 - val_loss: 0.1576\n",
            "Epoch 279/500\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0599 - val_loss: 0.1460\n",
            "Epoch 280/500\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0594 - val_loss: 0.1531\n",
            "Epoch 281/500\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0598 - val_loss: 0.1644\n",
            "Epoch 282/500\n",
            "45/45 [==============================] - 0s 209us/step - loss: 0.0581 - val_loss: 0.1646\n",
            "Epoch 283/500\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0570 - val_loss: 0.1558\n",
            "Epoch 284/500\n",
            "45/45 [==============================] - 0s 300us/step - loss: 0.0586 - val_loss: 0.1698\n",
            "Epoch 285/500\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.0570 - val_loss: 0.1661\n",
            "Epoch 286/500\n",
            "45/45 [==============================] - 0s 194us/step - loss: 0.0557 - val_loss: 0.1569\n",
            "Epoch 287/500\n",
            "45/45 [==============================] - 0s 295us/step - loss: 0.0548 - val_loss: 0.1554\n",
            "Epoch 288/500\n",
            "45/45 [==============================] - 0s 375us/step - loss: 0.0541 - val_loss: 0.1515\n",
            "Epoch 289/500\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0542 - val_loss: 0.1599\n",
            "Epoch 290/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0536 - val_loss: 0.1636\n",
            "Epoch 291/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0532 - val_loss: 0.1606\n",
            "Epoch 292/500\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0524 - val_loss: 0.1489\n",
            "Epoch 293/500\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0517 - val_loss: 0.1395\n",
            "Epoch 294/500\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0513 - val_loss: 0.1403\n",
            "Epoch 295/500\n",
            "45/45 [==============================] - 0s 262us/step - loss: 0.0504 - val_loss: 0.1445\n",
            "Epoch 296/500\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0500 - val_loss: 0.1470\n",
            "Epoch 297/500\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0499 - val_loss: 0.1389\n",
            "Epoch 298/500\n",
            "45/45 [==============================] - 0s 206us/step - loss: 0.0495 - val_loss: 0.1422\n",
            "Epoch 299/500\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0491 - val_loss: 0.1287\n",
            "Epoch 300/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0481 - val_loss: 0.1334\n",
            "Epoch 301/500\n",
            "45/45 [==============================] - 0s 295us/step - loss: 0.0473 - val_loss: 0.1371\n",
            "Epoch 302/500\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0473 - val_loss: 0.1348\n",
            "Epoch 303/500\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0465 - val_loss: 0.1373\n",
            "Epoch 304/500\n",
            "45/45 [==============================] - 0s 264us/step - loss: 0.0463 - val_loss: 0.1441\n",
            "Epoch 305/500\n",
            "45/45 [==============================] - 0s 337us/step - loss: 0.0466 - val_loss: 0.1410\n",
            "Epoch 306/500\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0450 - val_loss: 0.1372\n",
            "Epoch 307/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0446 - val_loss: 0.1401\n",
            "Epoch 308/500\n",
            "45/45 [==============================] - 0s 285us/step - loss: 0.0445 - val_loss: 0.1384\n",
            "Epoch 309/500\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0440 - val_loss: 0.1210\n",
            "Epoch 310/500\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0439 - val_loss: 0.1177\n",
            "Epoch 311/500\n",
            "45/45 [==============================] - 0s 229us/step - loss: 0.0433 - val_loss: 0.1218\n",
            "Epoch 312/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0428 - val_loss: 0.1194\n",
            "Epoch 313/500\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0419 - val_loss: 0.1109\n",
            "Epoch 314/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0419 - val_loss: 0.1175\n",
            "Epoch 315/500\n",
            "45/45 [==============================] - 0s 281us/step - loss: 0.0413 - val_loss: 0.1105\n",
            "Epoch 316/500\n",
            "45/45 [==============================] - 0s 319us/step - loss: 0.0411 - val_loss: 0.1044\n",
            "Epoch 317/500\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0404 - val_loss: 0.1129\n",
            "Epoch 318/500\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0402 - val_loss: 0.1149\n",
            "Epoch 319/500\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0398 - val_loss: 0.1068\n",
            "Epoch 320/500\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0392 - val_loss: 0.1131\n",
            "Epoch 321/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0385 - val_loss: 0.1078\n",
            "Epoch 322/500\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0384 - val_loss: 0.1092\n",
            "Epoch 323/500\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0382 - val_loss: 0.1064\n",
            "Epoch 324/500\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0375 - val_loss: 0.1045\n",
            "Epoch 325/500\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0371 - val_loss: 0.1044\n",
            "Epoch 326/500\n",
            "45/45 [==============================] - 0s 204us/step - loss: 0.0368 - val_loss: 0.1069\n",
            "Epoch 327/500\n",
            "45/45 [==============================] - 0s 200us/step - loss: 0.0362 - val_loss: 0.1012\n",
            "Epoch 328/500\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0362 - val_loss: 0.1004\n",
            "Epoch 329/500\n",
            "45/45 [==============================] - 0s 211us/step - loss: 0.0356 - val_loss: 0.0936\n",
            "Epoch 330/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0353 - val_loss: 0.0974\n",
            "Epoch 331/500\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0347 - val_loss: 0.0981\n",
            "Epoch 332/500\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0349 - val_loss: 0.1062\n",
            "Epoch 333/500\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0341 - val_loss: 0.1071\n",
            "Epoch 334/500\n",
            "45/45 [==============================] - 0s 288us/step - loss: 0.0342 - val_loss: 0.0997\n",
            "Epoch 335/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0332 - val_loss: 0.0980\n",
            "Epoch 336/500\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0327 - val_loss: 0.0956\n",
            "Epoch 337/500\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0326 - val_loss: 0.0945\n",
            "Epoch 338/500\n",
            "45/45 [==============================] - 0s 266us/step - loss: 0.0325 - val_loss: 0.0937\n",
            "Epoch 339/500\n",
            "45/45 [==============================] - 0s 272us/step - loss: 0.0324 - val_loss: 0.0872\n",
            "Epoch 340/500\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0317 - val_loss: 0.0895\n",
            "Epoch 341/500\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0313 - val_loss: 0.0944\n",
            "Epoch 342/500\n",
            "45/45 [==============================] - 0s 429us/step - loss: 0.0309 - val_loss: 0.0943\n",
            "Epoch 343/500\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0310 - val_loss: 0.0951\n",
            "Epoch 344/500\n",
            "45/45 [==============================] - 0s 223us/step - loss: 0.0307 - val_loss: 0.0996\n",
            "Epoch 345/500\n",
            "45/45 [==============================] - 0s 255us/step - loss: 0.0305 - val_loss: 0.0946\n",
            "Epoch 346/500\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0303 - val_loss: 0.0875\n",
            "Epoch 347/500\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0296 - val_loss: 0.0867\n",
            "Epoch 348/500\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0289 - val_loss: 0.0856\n",
            "Epoch 349/500\n",
            "45/45 [==============================] - 0s 271us/step - loss: 0.0291 - val_loss: 0.0872\n",
            "Epoch 350/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0287 - val_loss: 0.0838\n",
            "Epoch 351/500\n",
            "45/45 [==============================] - 0s 254us/step - loss: 0.0282 - val_loss: 0.0857\n",
            "Epoch 352/500\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0278 - val_loss: 0.0822\n",
            "Epoch 353/500\n",
            "45/45 [==============================] - 0s 193us/step - loss: 0.0276 - val_loss: 0.0861\n",
            "Epoch 354/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0273 - val_loss: 0.0835\n",
            "Epoch 355/500\n",
            "45/45 [==============================] - 0s 341us/step - loss: 0.0270 - val_loss: 0.0792\n",
            "Epoch 356/500\n",
            "45/45 [==============================] - 0s 219us/step - loss: 0.0266 - val_loss: 0.0832\n",
            "Epoch 357/500\n",
            "45/45 [==============================] - 0s 283us/step - loss: 0.0267 - val_loss: 0.0860\n",
            "Epoch 358/500\n",
            "45/45 [==============================] - 0s 267us/step - loss: 0.0264 - val_loss: 0.0752\n",
            "Epoch 359/500\n",
            "45/45 [==============================] - 0s 380us/step - loss: 0.0262 - val_loss: 0.0762\n",
            "Epoch 360/500\n",
            "45/45 [==============================] - 0s 256us/step - loss: 0.0260 - val_loss: 0.0783\n",
            "Epoch 361/500\n",
            "45/45 [==============================] - 0s 285us/step - loss: 0.0259 - val_loss: 0.0815\n",
            "Epoch 362/500\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0251 - val_loss: 0.0813\n",
            "Epoch 363/500\n",
            "45/45 [==============================] - 0s 257us/step - loss: 0.0248 - val_loss: 0.0824\n",
            "Epoch 364/500\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0252 - val_loss: 0.0757\n",
            "Epoch 365/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0246 - val_loss: 0.0747\n",
            "Epoch 366/500\n",
            "45/45 [==============================] - 0s 203us/step - loss: 0.0245 - val_loss: 0.0802\n",
            "Epoch 367/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0241 - val_loss: 0.0765\n",
            "Epoch 368/500\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0236 - val_loss: 0.0729\n",
            "Epoch 369/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0237 - val_loss: 0.0715\n",
            "Epoch 370/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0232 - val_loss: 0.0677\n",
            "Epoch 371/500\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0230 - val_loss: 0.0694\n",
            "Epoch 372/500\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0229 - val_loss: 0.0661\n",
            "Epoch 373/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0226 - val_loss: 0.0643\n",
            "Epoch 374/500\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0222 - val_loss: 0.0671\n",
            "Epoch 375/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0221 - val_loss: 0.0697\n",
            "Epoch 376/500\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0218 - val_loss: 0.0685\n",
            "Epoch 377/500\n",
            "45/45 [==============================] - 0s 335us/step - loss: 0.0216 - val_loss: 0.0705\n",
            "Epoch 378/500\n",
            "45/45 [==============================] - 0s 443us/step - loss: 0.0216 - val_loss: 0.0659\n",
            "Epoch 379/500\n",
            "45/45 [==============================] - 0s 298us/step - loss: 0.0213 - val_loss: 0.0646\n",
            "Epoch 380/500\n",
            "45/45 [==============================] - 0s 280us/step - loss: 0.0214 - val_loss: 0.0652\n",
            "Epoch 381/500\n",
            "45/45 [==============================] - 0s 284us/step - loss: 0.0208 - val_loss: 0.0631\n",
            "Epoch 382/500\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0206 - val_loss: 0.0670\n",
            "Epoch 383/500\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0205 - val_loss: 0.0696\n",
            "Epoch 384/500\n",
            "45/45 [==============================] - 0s 319us/step - loss: 0.0207 - val_loss: 0.0678\n",
            "Epoch 385/500\n",
            "45/45 [==============================] - 0s 305us/step - loss: 0.0199 - val_loss: 0.0642\n",
            "Epoch 386/500\n",
            "45/45 [==============================] - 0s 191us/step - loss: 0.0198 - val_loss: 0.0637\n",
            "Epoch 387/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0198 - val_loss: 0.0661\n",
            "Epoch 388/500\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0199 - val_loss: 0.0614\n",
            "Epoch 389/500\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0192 - val_loss: 0.0643\n",
            "Epoch 390/500\n",
            "45/45 [==============================] - 0s 283us/step - loss: 0.0196 - val_loss: 0.0567\n",
            "Epoch 391/500\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0190 - val_loss: 0.0540\n",
            "Epoch 392/500\n",
            "45/45 [==============================] - 0s 365us/step - loss: 0.0187 - val_loss: 0.0577\n",
            "Epoch 393/500\n",
            "45/45 [==============================] - 0s 182us/step - loss: 0.0187 - val_loss: 0.0540\n",
            "Epoch 394/500\n",
            "45/45 [==============================] - 0s 274us/step - loss: 0.0183 - val_loss: 0.0580\n",
            "Epoch 395/500\n",
            "45/45 [==============================] - 0s 245us/step - loss: 0.0181 - val_loss: 0.0560\n",
            "Epoch 396/500\n",
            "45/45 [==============================] - 0s 306us/step - loss: 0.0180 - val_loss: 0.0593\n",
            "Epoch 397/500\n",
            "45/45 [==============================] - 0s 341us/step - loss: 0.0183 - val_loss: 0.0535\n",
            "Epoch 398/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0182 - val_loss: 0.0530\n",
            "Epoch 399/500\n",
            "45/45 [==============================] - 0s 309us/step - loss: 0.0176 - val_loss: 0.0542\n",
            "Epoch 400/500\n",
            "45/45 [==============================] - 0s 253us/step - loss: 0.0176 - val_loss: 0.0532\n",
            "Epoch 401/500\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0172 - val_loss: 0.0575\n",
            "Epoch 402/500\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0169 - val_loss: 0.0559\n",
            "Epoch 403/500\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0168 - val_loss: 0.0549\n",
            "Epoch 404/500\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0169 - val_loss: 0.0509\n",
            "Epoch 405/500\n",
            "45/45 [==============================] - 0s 248us/step - loss: 0.0165 - val_loss: 0.0508\n",
            "Epoch 406/500\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0163 - val_loss: 0.0507\n",
            "Epoch 407/500\n",
            "45/45 [==============================] - 0s 178us/step - loss: 0.0161 - val_loss: 0.0509\n",
            "Epoch 408/500\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0163 - val_loss: 0.0546\n",
            "Epoch 409/500\n",
            "45/45 [==============================] - 0s 185us/step - loss: 0.0158 - val_loss: 0.0511\n",
            "Epoch 410/500\n",
            "45/45 [==============================] - 0s 227us/step - loss: 0.0157 - val_loss: 0.0519\n",
            "Epoch 411/500\n",
            "45/45 [==============================] - 0s 351us/step - loss: 0.0161 - val_loss: 0.0541\n",
            "Epoch 412/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0158 - val_loss: 0.0504\n",
            "Epoch 413/500\n",
            "45/45 [==============================] - 0s 207us/step - loss: 0.0154 - val_loss: 0.0506\n",
            "Epoch 414/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0154 - val_loss: 0.0491\n",
            "Epoch 415/500\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0151 - val_loss: 0.0472\n",
            "Epoch 416/500\n",
            "45/45 [==============================] - 0s 181us/step - loss: 0.0151 - val_loss: 0.0468\n",
            "Epoch 417/500\n",
            "45/45 [==============================] - 0s 359us/step - loss: 0.0149 - val_loss: 0.0509\n",
            "Epoch 418/500\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0149 - val_loss: 0.0536\n",
            "Epoch 419/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0147 - val_loss: 0.0499\n",
            "Epoch 420/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0145 - val_loss: 0.0496\n",
            "Epoch 421/500\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0142 - val_loss: 0.0474\n",
            "Epoch 422/500\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0143 - val_loss: 0.0472\n",
            "Epoch 423/500\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0140 - val_loss: 0.0465\n",
            "Epoch 424/500\n",
            "45/45 [==============================] - 0s 276us/step - loss: 0.0139 - val_loss: 0.0480\n",
            "Epoch 425/500\n",
            "45/45 [==============================] - 0s 218us/step - loss: 0.0137 - val_loss: 0.0470\n",
            "Epoch 426/500\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0137 - val_loss: 0.0432\n",
            "Epoch 427/500\n",
            "45/45 [==============================] - 0s 326us/step - loss: 0.0136 - val_loss: 0.0403\n",
            "Epoch 428/500\n",
            "45/45 [==============================] - 0s 237us/step - loss: 0.0135 - val_loss: 0.0444\n",
            "Epoch 429/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0134 - val_loss: 0.0455\n",
            "Epoch 430/500\n",
            "45/45 [==============================] - 0s 224us/step - loss: 0.0135 - val_loss: 0.0459\n",
            "Epoch 431/500\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0133 - val_loss: 0.0445\n",
            "Epoch 432/500\n",
            "45/45 [==============================] - 0s 208us/step - loss: 0.0129 - val_loss: 0.0429\n",
            "Epoch 433/500\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0129 - val_loss: 0.0456\n",
            "Epoch 434/500\n",
            "45/45 [==============================] - 0s 205us/step - loss: 0.0129 - val_loss: 0.0428\n",
            "Epoch 435/500\n",
            "45/45 [==============================] - 0s 317us/step - loss: 0.0128 - val_loss: 0.0395\n",
            "Epoch 436/500\n",
            "45/45 [==============================] - 0s 243us/step - loss: 0.0126 - val_loss: 0.0385\n",
            "Epoch 437/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0126 - val_loss: 0.0381\n",
            "Epoch 438/500\n",
            "45/45 [==============================] - 0s 306us/step - loss: 0.0125 - val_loss: 0.0368\n",
            "Epoch 439/500\n",
            "45/45 [==============================] - 0s 275us/step - loss: 0.0126 - val_loss: 0.0396\n",
            "Epoch 440/500\n",
            "45/45 [==============================] - 0s 263us/step - loss: 0.0123 - val_loss: 0.0390\n",
            "Epoch 441/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0122 - val_loss: 0.0387\n",
            "Epoch 442/500\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0121 - val_loss: 0.0355\n",
            "Epoch 443/500\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0123 - val_loss: 0.0357\n",
            "Epoch 444/500\n",
            "45/45 [==============================] - 0s 252us/step - loss: 0.0119 - val_loss: 0.0359\n",
            "Epoch 445/500\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0118 - val_loss: 0.0341\n",
            "Epoch 446/500\n",
            "45/45 [==============================] - 0s 212us/step - loss: 0.0117 - val_loss: 0.0384\n",
            "Epoch 447/500\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0115 - val_loss: 0.0386\n",
            "Epoch 448/500\n",
            "45/45 [==============================] - 0s 222us/step - loss: 0.0114 - val_loss: 0.0362\n",
            "Epoch 449/500\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0115 - val_loss: 0.0358\n",
            "Epoch 450/500\n",
            "45/45 [==============================] - 0s 268us/step - loss: 0.0112 - val_loss: 0.0345\n",
            "Epoch 451/500\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0113 - val_loss: 0.0357\n",
            "Epoch 452/500\n",
            "45/45 [==============================] - 0s 236us/step - loss: 0.0111 - val_loss: 0.0353\n",
            "Epoch 453/500\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0110 - val_loss: 0.0354\n",
            "Epoch 454/500\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0110 - val_loss: 0.0332\n",
            "Epoch 455/500\n",
            "45/45 [==============================] - 0s 238us/step - loss: 0.0109 - val_loss: 0.0335\n",
            "Epoch 456/500\n",
            "45/45 [==============================] - 0s 220us/step - loss: 0.0108 - val_loss: 0.0339\n",
            "Epoch 457/500\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0108 - val_loss: 0.0347\n",
            "Epoch 458/500\n",
            "45/45 [==============================] - 0s 327us/step - loss: 0.0107 - val_loss: 0.0342\n",
            "Epoch 459/500\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0106 - val_loss: 0.0315\n",
            "Epoch 460/500\n",
            "45/45 [==============================] - 0s 258us/step - loss: 0.0104 - val_loss: 0.0345\n",
            "Epoch 461/500\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0106 - val_loss: 0.0352\n",
            "Epoch 462/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0103 - val_loss: 0.0343\n",
            "Epoch 463/500\n",
            "45/45 [==============================] - 0s 240us/step - loss: 0.0103 - val_loss: 0.0349\n",
            "Epoch 464/500\n",
            "45/45 [==============================] - 0s 216us/step - loss: 0.0102 - val_loss: 0.0332\n",
            "Epoch 465/500\n",
            "45/45 [==============================] - 0s 226us/step - loss: 0.0102 - val_loss: 0.0315\n",
            "Epoch 466/500\n",
            "45/45 [==============================] - 0s 225us/step - loss: 0.0101 - val_loss: 0.0323\n",
            "Epoch 467/500\n",
            "45/45 [==============================] - 0s 233us/step - loss: 0.0100 - val_loss: 0.0319\n",
            "Epoch 468/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0099 - val_loss: 0.0327\n",
            "Epoch 469/500\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0098 - val_loss: 0.0331\n",
            "Epoch 470/500\n",
            "45/45 [==============================] - 0s 210us/step - loss: 0.0097 - val_loss: 0.0324\n",
            "Epoch 471/500\n",
            "45/45 [==============================] - 0s 250us/step - loss: 0.0098 - val_loss: 0.0327\n",
            "Epoch 472/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0096 - val_loss: 0.0315\n",
            "Epoch 473/500\n",
            "45/45 [==============================] - 0s 291us/step - loss: 0.0096 - val_loss: 0.0313\n",
            "Epoch 474/500\n",
            "45/45 [==============================] - 0s 285us/step - loss: 0.0095 - val_loss: 0.0334\n",
            "Epoch 475/500\n",
            "45/45 [==============================] - 0s 251us/step - loss: 0.0094 - val_loss: 0.0313\n",
            "Epoch 476/500\n",
            "45/45 [==============================] - 0s 249us/step - loss: 0.0094 - val_loss: 0.0314\n",
            "Epoch 477/500\n",
            "45/45 [==============================] - 0s 228us/step - loss: 0.0094 - val_loss: 0.0304\n",
            "Epoch 478/500\n",
            "45/45 [==============================] - 0s 302us/step - loss: 0.0092 - val_loss: 0.0299\n",
            "Epoch 479/500\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0092 - val_loss: 0.0301\n",
            "Epoch 480/500\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0091 - val_loss: 0.0296\n",
            "Epoch 481/500\n",
            "45/45 [==============================] - 0s 242us/step - loss: 0.0092 - val_loss: 0.0278\n",
            "Epoch 482/500\n",
            "45/45 [==============================] - 0s 244us/step - loss: 0.0090 - val_loss: 0.0293\n",
            "Epoch 483/500\n",
            "45/45 [==============================] - 0s 230us/step - loss: 0.0090 - val_loss: 0.0298\n",
            "Epoch 484/500\n",
            "45/45 [==============================] - 0s 221us/step - loss: 0.0089 - val_loss: 0.0281\n",
            "Epoch 485/500\n",
            "45/45 [==============================] - 0s 239us/step - loss: 0.0090 - val_loss: 0.0271\n",
            "Epoch 486/500\n",
            "45/45 [==============================] - 0s 280us/step - loss: 0.0088 - val_loss: 0.0279\n",
            "Epoch 487/500\n",
            "45/45 [==============================] - 0s 273us/step - loss: 0.0088 - val_loss: 0.0279\n",
            "Epoch 488/500\n",
            "45/45 [==============================] - 0s 289us/step - loss: 0.0089 - val_loss: 0.0251\n",
            "Epoch 489/500\n",
            "45/45 [==============================] - 0s 296us/step - loss: 0.0087 - val_loss: 0.0239\n",
            "Epoch 490/500\n",
            "45/45 [==============================] - 0s 234us/step - loss: 0.0086 - val_loss: 0.0248\n",
            "Epoch 491/500\n",
            "45/45 [==============================] - 0s 235us/step - loss: 0.0086 - val_loss: 0.0246\n",
            "Epoch 492/500\n",
            "45/45 [==============================] - 0s 241us/step - loss: 0.0085 - val_loss: 0.0240\n",
            "Epoch 493/500\n",
            "45/45 [==============================] - 0s 231us/step - loss: 0.0086 - val_loss: 0.0237\n",
            "Epoch 494/500\n",
            "45/45 [==============================] - 0s 247us/step - loss: 0.0084 - val_loss: 0.0257\n",
            "Epoch 495/500\n",
            "45/45 [==============================] - 0s 201us/step - loss: 0.0084 - val_loss: 0.0239\n",
            "Epoch 496/500\n",
            "45/45 [==============================] - 0s 246us/step - loss: 0.0083 - val_loss: 0.0221\n",
            "Epoch 497/500\n",
            "45/45 [==============================] - 0s 232us/step - loss: 0.0083 - val_loss: 0.0232\n",
            "Epoch 498/500\n",
            "45/45 [==============================] - 0s 215us/step - loss: 0.0082 - val_loss: 0.0245\n",
            "Epoch 499/500\n",
            "45/45 [==============================] - 0s 306us/step - loss: 0.0082 - val_loss: 0.0244\n",
            "Epoch 500/500\n",
            "45/45 [==============================] - 0s 270us/step - loss: 0.0082 - val_loss: 0.0241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJFuqfgIjlCa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "88a022db-f350-42ba-e6ce-d7016b36d0d4"
      },
      "source": [
        "loss = history.history['loss'] # 訓練用データの誤差\n",
        "vloss = history.history['val_loss'] # 検証用データの誤差\n",
        "\n",
        "plt.plot(np.arange(len(loss)), loss)\n",
        "plt.plot(np.arange(len(vloss)), vloss)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzgK9Mcb43P8D+9jE15yespEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJlmStCMjtQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0577fb03-f219-4a4f-c0ce-eb78b47587ab"
      },
      "source": [
        "plt.plot(x, model.predict(x))\n",
        "plt.plot(x, t)\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncFoIlFLKw2khUEopD6eFQCmlPNz/A9AwG48fOWVoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFojipB1GQTp",
        "colab_type": "text"
      },
      "source": [
        "# RNN実装\n",
        "\n",
        "## 訓練用データ作成\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fxpUTaRj0Yg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "bba2ecc9-b598-4826-f565-26f1eb2f29b8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_data = np.linspace(-5*np.pi, 5*np.pi)\n",
        "sin_data = np.sin(x_data) + 0.1*np.random.randn(len(x_data)) # sin関数にノイズを加える\n",
        "\n",
        "plt.plot(x_data, sin_data)\n",
        "plt.show()\n",
        "\n",
        "n_rnn = 10 # 時系列の数\n",
        "n_sample = len(x_data)-n_rnn # サンプル数\n",
        "x = np.zeros((n_sample, n_rnn)) # 入力数\n",
        "t = np.zeros((n_sample, n_rnn)) # 正解\n",
        "\n",
        "for i in range(0, n_sample):\n",
        "  x[i] = sin_data[i:i+n_rnn]\n",
        "  t[i] = sin_data[i+1:i+n_rnn+1] # 時系列を入力よりも一つ後にずらす、これが正解のデータ\n",
        "\n",
        "x = x.reshape(n_sample, n_rnn, 1) # KerasによるRNNは入力を（サンプル数、時系列の数、入力層のニューロン数）にする\n",
        "print(x.shape)\n",
        "t = t.reshape(n_sample, n_rnn, 1) # 入力と同じ形状\n",
        "print(t.shape)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40, 10, 1)\n",
            "(40, 10, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAgEPYII+AKBQNAjiIAvEAgEPcL/D2QaxS3gSFFsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuDvTFumGowv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c24f847b-b1d8-48ba-f291-0b3a8ca76748"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN\n",
        "\n",
        "batch_size = 8 # バッチサイズ\n",
        "n_in = 1 # 入力層のニューロン数\n",
        "n_mid = 20 # 中間層のニューロン数\n",
        "n_out = 1 # 出力層のニューロン数\n",
        "\n",
        "model = Sequential()\n",
        "# SimpleRNN層の追加。return_sequenceをTrueにすると、時系列の全てのRNN層が出力を返す。\n",
        "# return_sequenceをTrueをFalseにすると、最後のRNN層のみが出力を返す。\n",
        "model.add(SimpleRNN(n_mid, input_shape=(n_rnn, n_in), return_sequences=True))\n",
        "model.add(Dense(n_out, activation=\"linear\"))\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")  # 誤差は二乗誤差、最適化アルゴリズムはSGD\n",
        "print(model.summary())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_2 (SimpleRNN)     (None, 10, 20)            440       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10, 1)             21        \n",
            "=================================================================\n",
            "Total params: 461\n",
            "Trainable params: 461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF6QlEwvJg0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae497cd5-c8ba-4a42-d27b-b8ebf5d801c3"
      },
      "source": [
        "# 学習\n",
        "history = model.fit(x, t, epochs=100, batch_size=batch_size, validation_split=0.1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 36 samples, validate on 4 samples\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2591 - val_loss: 0.1851\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 588us/step - loss: 0.1952 - val_loss: 0.1560\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 536us/step - loss: 0.1687 - val_loss: 0.1405\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 536us/step - loss: 0.1544 - val_loss: 0.1313\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 552us/step - loss: 0.1442 - val_loss: 0.1295\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 508us/step - loss: 0.1355 - val_loss: 0.1238\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 491us/step - loss: 0.1288 - val_loss: 0.1212\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 561us/step - loss: 0.1224 - val_loss: 0.1163\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 455us/step - loss: 0.1172 - val_loss: 0.1106\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 504us/step - loss: 0.1117 - val_loss: 0.1046\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 449us/step - loss: 0.1071 - val_loss: 0.1034\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 528us/step - loss: 0.1034 - val_loss: 0.1017\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 553us/step - loss: 0.0993 - val_loss: 0.0990\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 605us/step - loss: 0.0959 - val_loss: 0.0937\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 582us/step - loss: 0.0931 - val_loss: 0.0924\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 480us/step - loss: 0.0905 - val_loss: 0.0905\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 504us/step - loss: 0.0878 - val_loss: 0.0888\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 529us/step - loss: 0.0850 - val_loss: 0.0854\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 500us/step - loss: 0.0827 - val_loss: 0.0825\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 525us/step - loss: 0.0805 - val_loss: 0.0792\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 513us/step - loss: 0.0791 - val_loss: 0.0808\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 547us/step - loss: 0.0769 - val_loss: 0.0811\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 562us/step - loss: 0.0751 - val_loss: 0.0805\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 689us/step - loss: 0.0735 - val_loss: 0.0761\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 597us/step - loss: 0.0720 - val_loss: 0.0742\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 849us/step - loss: 0.0704 - val_loss: 0.0740\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 461us/step - loss: 0.0690 - val_loss: 0.0728\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 461us/step - loss: 0.0678 - val_loss: 0.0714\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 508us/step - loss: 0.0665 - val_loss: 0.0713\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 538us/step - loss: 0.0653 - val_loss: 0.0703\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 539us/step - loss: 0.0642 - val_loss: 0.0682\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 553us/step - loss: 0.0634 - val_loss: 0.0678\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 834us/step - loss: 0.0623 - val_loss: 0.0676\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 482us/step - loss: 0.0614 - val_loss: 0.0672\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 517us/step - loss: 0.0605 - val_loss: 0.0659\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 529us/step - loss: 0.0594 - val_loss: 0.0656\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 517us/step - loss: 0.0586 - val_loss: 0.0657\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 577us/step - loss: 0.0579 - val_loss: 0.0629\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 467us/step - loss: 0.0571 - val_loss: 0.0617\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 461us/step - loss: 0.0565 - val_loss: 0.0614\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 462us/step - loss: 0.0559 - val_loss: 0.0615\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 437us/step - loss: 0.0551 - val_loss: 0.0624\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 465us/step - loss: 0.0543 - val_loss: 0.0609\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 476us/step - loss: 0.0539 - val_loss: 0.0614\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 493us/step - loss: 0.0530 - val_loss: 0.0605\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 466us/step - loss: 0.0525 - val_loss: 0.0600\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 466us/step - loss: 0.0521 - val_loss: 0.0590\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 479us/step - loss: 0.0516 - val_loss: 0.0599\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 466us/step - loss: 0.0509 - val_loss: 0.0574\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 622us/step - loss: 0.0506 - val_loss: 0.0583\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 457us/step - loss: 0.0500 - val_loss: 0.0574\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 474us/step - loss: 0.0496 - val_loss: 0.0581\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 525us/step - loss: 0.0491 - val_loss: 0.0576\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 510us/step - loss: 0.0486 - val_loss: 0.0569\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 537us/step - loss: 0.0484 - val_loss: 0.0557\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 626us/step - loss: 0.0481 - val_loss: 0.0563\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 588us/step - loss: 0.0475 - val_loss: 0.0563\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 555us/step - loss: 0.0471 - val_loss: 0.0564\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 550us/step - loss: 0.0469 - val_loss: 0.0550\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 538us/step - loss: 0.0467 - val_loss: 0.0550\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 527us/step - loss: 0.0463 - val_loss: 0.0535\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 495us/step - loss: 0.0459 - val_loss: 0.0539\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 494us/step - loss: 0.0456 - val_loss: 0.0542\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 463us/step - loss: 0.0454 - val_loss: 0.0543\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 506us/step - loss: 0.0451 - val_loss: 0.0538\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 470us/step - loss: 0.0449 - val_loss: 0.0538\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 500us/step - loss: 0.0446 - val_loss: 0.0531\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 675us/step - loss: 0.0443 - val_loss: 0.0530\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 559us/step - loss: 0.0441 - val_loss: 0.0529\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 581us/step - loss: 0.0439 - val_loss: 0.0525\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 490us/step - loss: 0.0436 - val_loss: 0.0527\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 546us/step - loss: 0.0434 - val_loss: 0.0525\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 537us/step - loss: 0.0434 - val_loss: 0.0522\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 536us/step - loss: 0.0430 - val_loss: 0.0514\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 591us/step - loss: 0.0429 - val_loss: 0.0518\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 559us/step - loss: 0.0427 - val_loss: 0.0513\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 577us/step - loss: 0.0426 - val_loss: 0.0519\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 616us/step - loss: 0.0424 - val_loss: 0.0525\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 615us/step - loss: 0.0423 - val_loss: 0.0516\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 573us/step - loss: 0.0421 - val_loss: 0.0518\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 676us/step - loss: 0.0419 - val_loss: 0.0515\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 663us/step - loss: 0.0417 - val_loss: 0.0509\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 513us/step - loss: 0.0416 - val_loss: 0.0510\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 558us/step - loss: 0.0415 - val_loss: 0.0521\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 504us/step - loss: 0.0414 - val_loss: 0.0514\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 573us/step - loss: 0.0413 - val_loss: 0.0513\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 500us/step - loss: 0.0411 - val_loss: 0.0502\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 554us/step - loss: 0.0410 - val_loss: 0.0506\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 642us/step - loss: 0.0411 - val_loss: 0.0503\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 605us/step - loss: 0.0410 - val_loss: 0.0497\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 666us/step - loss: 0.0407 - val_loss: 0.0500\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 454us/step - loss: 0.0407 - val_loss: 0.0498\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 662us/step - loss: 0.0406 - val_loss: 0.0493\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 554us/step - loss: 0.0405 - val_loss: 0.0487\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 611us/step - loss: 0.0403 - val_loss: 0.0494\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 524us/step - loss: 0.0402 - val_loss: 0.0493\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 549us/step - loss: 0.0401 - val_loss: 0.0497\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 536us/step - loss: 0.0401 - val_loss: 0.0501\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 651us/step - loss: 0.0399 - val_loss: 0.0499\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 599us/step - loss: 0.0399 - val_loss: 0.0499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZON0QB49Jxy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3df0f3bb-b6ec-4af2-a994-b6a5b84b06c6"
      },
      "source": [
        "# 誤差の推移を確認\n",
        "loss = history.history['loss']\n",
        "vloss = history.history['val_loss']\n",
        "\n",
        "plt.plot(np.arange(len(loss)), loss)\n",
        "plt.plot(np.arange(len(vloss)), vloss)\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOQW9iIjPKehFRHxOQS8i4nP/H/r7JFVaQq/8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l44pnRuiKEfw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7f952687-4a7d-4286-e0c5-718d4cc5e259"
      },
      "source": [
        "# 予測\n",
        "\n",
        "predicted = x[0].reshape(-1) # 最初の入力。reshape(-1)で一次元のベクトルにする\n",
        "for i in range(0, n_sample):\n",
        "  y = model.predict(predicted[-n_rnn:].reshape(1, n_rnn, 1)) # 直近のデータを取り出してreshapeして予測に渡す\n",
        "  predicted = np.append(predicted, y[0][n_rnn-1][0]) # 出力の最後の結果をpredictedに追加する。\n",
        "plt.plot(np.arange(len(sin_data)), sin_data, label=\"Training data\")\n",
        "plt.plot(np.arange(len(predicted)), predicted, label=\"Predicted\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlubQw2IL8Cm",
        "colab_type": "text"
      },
      "source": [
        "時系列xが進むにつれて乖離が生じている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIj-d3JCKuC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}